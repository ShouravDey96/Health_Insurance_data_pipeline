{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1a4753a-0f02-40a7-bbf0-875bdc98cb8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"__S3_Access_Key__\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", \"__S3_Secret_Key__\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "375a7588-17ca-4577-91b4-b8d55b8efbf0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### df_dis = disease\n",
    "##### df_grp = group\n",
    "##### df_gs = grpsubgrp\n",
    "##### df_hp = hospital\n",
    "##### df_pr = patient_records\n",
    "##### df_sg = subgroup\n",
    "##### df_sb = subcriber\n",
    "##### df_cl = claims\n",
    "\n",
    "df4.write.parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e19529bc-5c88-4b36-805e-17f945f3fd40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+\n|SubGrpID| Disease_ID|        Disease_name|\n+--------+-----------+--------------------+\n|    S101|     110001|            Beriberi|\n|    S101|     110002|              Scurvy|\n|    S101|     110003|              Goitre|\n|    S101|     110004|        Osteoporosis|\n|    S101|     110005|             Rickets|\n|    S101|     110006|             Anaemia|\n|    S102|     110007|           Fractures|\n|    S102|     110008|        Heart Attack|\n|    S102|     110009|               Burns|\n|    S102|     110010|             Choking|\n|    S102|     110011|              Stroke|\n|    S102|     110012|      Food Poisoning|\n|    S103|     110013|              Asthma|\n|    S103|     110014|            Glaucoma|\n|    S103|     110015|            Diabetes|\n|    S103|     110016|             Amnesia|\n|    S103|     110017|         Parasomnias|\n|    S103|     110018|Neurocognitive di...|\n|    S104|     110019|             Vertigo|\n|    S104|     110020|          Lymphedema|\n+--------+-----------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_dis = spark.read.options(inferSchema = 'True', header = 'True').csv(\"s3://sbdtestbuck/capstone_prj/raw_data/disease/disease.csv\")\n",
    "\n",
    "df_dis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "624ab04d-b0ba-4f76-b57d-1440cf2234fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-------+------+--------------------+--------+---------+----+\n|Country|premium_written|zipcode|Grp_Id|            Grp_Name|Grp_Type|     city|year|\n+-------+---------------+-------+------+--------------------+--------+---------+----+\n|  India|          72000| 482018|GRP101|Life Insurance Co...|   Govt.|   Mumbai|1956|\n|  India|          45000| 482049|GRP102|HDFC Standard Lif...| Private|   Mumbai|2000|\n|  India|          64000| 482030|GRP103|Max Life Insuranc...| Private|    Delhi|2000|\n|  India|          59000| 482028|GRP104|ICICI Prudential ...| Private|   Mumbai|2000|\n|  India|          37000| 482014|GRP105|Kotak Mahindra Li...| Private|   Mumbai|2001|\n|  India|          89000| 482011|GRP106|Aditya Birla Sun ...| Private|   Mumbai|2000|\n|  India|          70000| 482006|GRP107|TATA AIG Life Ins...| Private|   Mumbai|2001|\n|  India|          52000| 482034|GRP108|SBI Life Insuranc...| Private|   Mumbai|2001|\n|  India|          78000| 482032|GRP109|Exide Life Insura...| Private|Bangalore|2001|\n|  India|          48000| 482015|GRP110|Bajaj Allianz Lif...| Private|     Pune|2001|\n|  India|          57000| 482011|GRP111|PNB MetLife India...| Private|   Mumbai|2001|\n|  India|          57000| 482022|GRP112|Reliance Nippon L...| Private|   Mumbai|2001|\n|  India|          64000| 482009|GRP113|Aviva Life Insura...| Private| Gurugram|2002|\n|  India|          33000| 482043|GRP114|Sahara India Life...| Private|  Lucknow|2004|\n|  India|          79000| 482036|GRP115|Shriram Life Insu...| Private|Hyderabad|2005|\n|  India|          32000| 482002|GRP116|Bharti AXA Life I...| Private|   Mumbai|2008|\n|  India|          59000| 482017|GRP117|Future Generali I...| Private|   Mumbai|2007|\n|  India|          97000| 482023|GRP118|IDBI Federal Life...| Private|   Mumbai|2008|\n|  India|          47000| 482046|GRP119|Canara HSBC Orien...| Private| Gurugram|2008|\n|  India|          50000| 482017|GRP120|Aegon Life Insura...| Private|   Mumbai|2008|\n+-------+---------------+-------+------+--------------------+--------+---------+----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_grp = spark.read.options(inferSchema = 'True', header = 'True').csv(\"s3://sbdtestbuck/capstone_prj/raw_data/group/group.csv\")\n",
    "\n",
    "df_grp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e683bb4-c26e-4306-969b-b0d344a71052",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_grp.write.csv(\"s3://sbdtestbuck/capstone_prj/cleaned_data/group.csv\")\n",
    "# df_grp.write.parquet(\"s3://sbdtestbuck/capstone_prj/cleaned_data/group.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0fb38508-debc-49bf-bfc8-3cd37967f699",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8344714c-f066-4d48-805d-38effb1660f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# duplicate_rows = df.exceptAll(df.dropDuplicates()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e65779b9-3fe2-443c-99a5-f8111cd864c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n|SubGrp_ID|Grp_Id|\n+---------+------+\n|     S101|GRP101|\n|     S101|GRP105|\n|     S102|GRP110|\n|     S102|GRP150|\n|     S102|GRP136|\n|     S103|GRP122|\n|     S103|GRP108|\n|     S103|GRP138|\n|     S103|GRP148|\n|     S104|GRP103|\n|     S104|GRP113|\n|     S104|GRP123|\n|     S104|GRP133|\n|     S104|GRP143|\n|     S105|GRP153|\n|     S105|GRP104|\n|     S105|GRP114|\n|     S105|GRP124|\n|     S106|GRP117|\n|     S106|GRP127|\n+---------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_gs = spark.read.options(inferSchema = 'True', header = 'True').csv(\"s3://sbdtestbuck/capstone_prj/raw_data/grpsubgrp/grpsubgrp.csv\")\n",
    "\n",
    "df_gs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e73dabf-c5bd-4cdd-9a9e-fb652e54e7f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+-----------+-------+\n|Hospital_id|       Hospital_name|      city|      state|country|\n+-----------+--------------------+----------+-----------+-------+\n|      H1000|All India Institu...| New Delhi|        NaN|  India|\n|      H1001|Medanta The Medicity|   Gurgaon|    Haryana|  India|\n|      H1002|The Christian Med...|   Vellore| Tamil Nadu|  India|\n|      H1003|PGIMER - Postgrad...|Chandigarh|    Haryana|  India|\n|      H1004|Apollo Hospital -...|   Chennai| Tamil Nadu|  India|\n|      H1005|P. D. Hinduja Nat...|    Mumbai|Maharashtra|  India|\n|      H1006|Breach Candy Hosp...|    Mumbai|Maharashtra|  India|\n|      H1007|Fortis Flt. Lt. R...| New Delhi|        NaN|  India|\n|      H1008|King Edward Memor...|    Mumbai|Maharashtra|  India|\n|      H1009|Indraprastha Apol...|     Delhi|        NaN|  India|\n|      H1010|Lilavati Hospital...|    Mumbai|Maharashtra|  India|\n|      H1011|Sir Ganga Ram Hos...|     Delhi|        NaN|  India|\n|      H1012|Bombay Hospital &...|    Mumbai|Maharashtra|  India|\n|      H1013|Apollo Health Cit...| Hyderabad|  Telangana|  India|\n|      H1014|Fortis Hiranandan...|    Mumbai|Maharashtra|  India|\n|      H1015|Fortis Hospital M...|    Mumbai|Maharashtra|  India|\n|      H1016|Jaslok Hospital a...|    Mumbai|Maharashtra|  India|\n|      H1017|   Manipal Hospitals| Bengaluru|  Karnataka|  India|\n|      H1018|Yashoda Hospital ...| Hyderabad|  Telangana|  India|\n|      H1019|Apollo Hospitals ...| Bengaluru|  Karnataka|  India|\n+-----------+--------------------+----------+-----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "df_hp = spark.read.options(inferSchema = 'True', header = 'True').csv(\"s3://sbdtestbuck/capstone_prj/raw_data/hospital/hospital.csv\")\n",
    "\n",
    "df_hp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bd42c5a-b73f-45db-ac53-f1e1bb35c026",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_hp.write.csv(\"s3://sbdtestbuck/capstone_prj/cleaned_data/hospital.csv\")\n",
    "# df_hp.write.parquet(\"s3://sbdtestbuck/capstone_prj/cleaned_data/hospital.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4d2fd0e-df2e-42a6-b8c3-822a0ad60560",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------+------------------+--------------+----------------+--------------------+-----------+\n|Patient_id|Patient_name|patient_gender|patient_birth_date| patient_phone|    disease_name|                city|hospital_id|\n+----------+------------+--------------+------------------+--------------+----------------+--------------------+-----------+\n|    187158|      Harbir|        Female|        1924-06-30|+91 0112009318|    Galactosemia|            Rourkela|      H1001|\n|    112766|    Brahmdev|        Female|        1948-12-20|+91 1727749552|  Bladder cancer|        Tiruvottiyur|      H1016|\n|    199252|     Ujjawal|          Male|        1980-04-16|+91 8547451606|   Kidney cancer|           Berhampur|      H1009|\n|    133424|     Ballari|        Female|        1969-09-25|+91 0106026841|         Suicide|        Bihar Sharif|      H1017|\n|    172579|     Devnath|        Female|        1946-05-01|+91 1868774631|    Food allergy|         Bidhannagar|      H1019|\n|    171320|       Atasi|          Male|        1967-10-02|+91 9747336855|        Whiplash|            Amravati|      H1013|\n|    107794|      Manish|          Male|        1967-06-06|+91 4354294043|      Sunbathing|              Panvel|      H1004|\n|    130339|       Aakar|        Female|        1925-03-05|+91 2777633911|Drug consumption|        Bihar Sharif|      H1000|\n|    110377|     Gurudas|          Male|        1945-05-06|+91 1232859381|          Dengue|           Kamarhati|      H1001|\n|    149367|        NULL|          Male|        1925-06-12|+91 1780763280|    Head banging|           Bangalore|      H1013|\n|    156168|        NULL|          Male|        1976-02-03|+91 5586075345| Fanconi anaemia|              Rajkot|      H1004|\n|    114241|        NULL|        Female|        1955-01-22|+91 4146391938|   Breast cancer|           Ghaziabad|      H1015|\n|    146382|  Dharmadaas|          Male|        1964-04-29|+91 6345482027|         Anthrax|Bhalswa Jahangir Pur|      H1019|\n|    132748|    Brahmvir|          Male|        1991-11-11|+91 7316972612| Cystic fibrosis|              Ambala|      H1018|\n|    167340|        NULL|        Female|        1981-01-25|+91 2960004518|    Galactosemia|Surendranagar Dud...|      H1003|\n|    135184|     Bhagvan|        Female|        1966-07-24|+91 0297693485|          Dengue|          Bhimavaram|      H1018|\n|    179662|   Amritkala|        Female|        1933-11-20|+91 0537157280|        Smallpox|              Meerut|      H1018|\n|    184479|      Bandhu|          Male|        1996-10-15|+91 0695289163|  Pollen allergy|           Chinsurah|      H1010|\n|    156988|  Bhagavaana|        Female|        1935-09-16|+91 6071745855|   Breast cancer|        Shahjahanpur|      H1012|\n|    132870|        NULL|        Female|        1924-11-09|+91 8906694405|        Glaucoma|            Jabalpur|      H1017|\n+----------+------------+--------------+------------------+--------------+----------------+--------------------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_pr = spark.read.options(inferSchema = 'True', header = 'True').csv(\"s3://sbdtestbuck/capstone_prj/raw_data/patient_records/Patient_records.csv\")\n",
    "\n",
    "df_pr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b677aa0c-890a-488a-a22f-0943a04c9308",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+---------------+\n|SubGrp_id|        SubGrp_Name|Monthly_Premium|\n+---------+-------------------+---------------+\n|     S101|Deficiency Diseases|           3000|\n|     S102|           Accident|           1000|\n|     S103|         Physiology|           2000|\n|     S104|            Therapy|           1500|\n|     S105|          Allergies|           2300|\n|     S106|     Self inflicted|           1200|\n|     S107|             Cancer|           3200|\n|     S108| Infectious disease|           1500|\n|     S109|         Hereditary|           2000|\n|     S110|              Viral|           1000|\n+---------+-------------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_sg = spark.read.options(inferSchema = 'True', header = 'True').csv(\"s3://sbdtestbuck/capstone_prj/raw_data/subgroup/subgroup.csv\")\n",
    "\n",
    "df_sg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dc95a41-414b-4ca1-9eb3-1a9a34471c64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_sg.write.csv(\"s3://sbdtestbuck/capstone_prj/cleaned_data/subgroup.csv\")\n",
    "# df_sg.write.parquet(\"s3://sbdtestbuck/capstone_prj/cleaned_data/subgroup.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcf45b0f-6978-4fe1-b4da-ac6a8f54c409",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+-----------------+----------+------+--------------+-------+--------------------+--------+---------+--------+----------+----------+\n|   sub _id|first_name|  last_name|           Street|Birth_date|Gender|         Phone|Country|                City|Zip Code|Subgrp_id|Elig_ind|  eff_date| term_date|\n+----------+----------+-----------+-----------------+----------+------+--------------+-------+--------------------+--------+---------+--------+----------+----------+\n|SUBID10000|    Harbir|Vishwakarma|       Baria Marg|1924-06-30|Female|+91 0112009318|  India|            Rourkela|  767058|     S107|       Y|1944-06-30|1954-01-14|\n|SUBID10001|  Brahmdev|     Sonkar|        Lala Marg|1948-12-20|Female|+91 1727749552|  India|        Tiruvottiyur|   34639|     S105|       Y|1968-12-20|1970-05-16|\n|SUBID10002|   Ujjawal|       Devi|      Mammen Zila|1980-04-16|  Male|+91 8547451606|  India|           Berhampur|  914455|     S106|       N|2000-04-16|2008-05-04|\n|SUBID10003|   Ballari|     Mishra|       Sahni Zila|1969-09-25|Female|+91 0106026841|  India|        Bihar Sharif|   91481|     S104|       N|1989-09-25|1995-06-05|\n|SUBID10004|   Devnath|  Srivastav|       Magar Zila|1946-05-01|Female|+91 1868774631|  India|         Bidhannagar|  531742|     S110|       N|1966-05-01|1970-12-09|\n|SUBID10005|     Atasi|       Seth|     Khatri Nagar|1967-10-02|  Male|+91 9747336855|  India|            Amravati|  229062|     S104|       Y|1987-10-02|1995-02-13|\n| SUBID1006|    Manish|     Maurya|Swaminathan Chowk|1967-06-06|  Male|+91 4354294043|  India|              Panvel|  438733|     S109|    NULL|1987-06-06|1995-03-21|\n|SUBID10007|     Aakar|      Yadav|            Swamy|1925-03-05|Female|+91 2777633911|  India|        Bihar Sharif|  535907|     S104|       N|1945-03-05|1946-11-07|\n|SUBID10008|   Gurudas|      Gupta|      Sarin Nagar|1945-05-06|  Male|+91 1232859381|  India|           Kamarhati|  933226|     S103|       Y|1965-05-06|1970-09-16|\n|SUBID10009|      NULL|      Gupta|    Thakur Circle|1925-06-12|  Male|+91 1780763280|  India|           Bangalore|  957469|     S105|       Y|1945-06-12|1953-08-30|\n| SUBID1010|      NULL|     Divedi|          Dhillon|1976-02-03|  Male|+91 5586075345|  India|              Rajkot|  911319|     S102|       Y|1996-02-03|2002-01-27|\n|SUBID10011|      NULL|Vishwakarma|      Rajagopalan|1955-01-22|Female|+91 4146391938|  India|           Ghaziabad|  337042|     S106|       N|1975-01-22|1978-11-02|\n|SUBID10012|Dharmadaas|     Tiwari|             Rama|1964-04-29|  Male|+91 6345482027|  India|Bhalswa Jahangir Pur|  430793|     S103|       N|1984-04-29|1988-02-07|\n|SUBID10013|  Brahmvir|        Rai|        Shah Path|1991-11-11|  Male|+91 7316972612|  India|              Ambala|  249898|     S106|       N|2011-11-11|2020-05-23|\n|SUBID10014|      NULL|  Srivastav|     Chandra Path|1981-01-25|Female|+91 2960004518|  India|Surendranagar Dud...|  111966|     S102|       N|2001-01-25|2005-07-13|\n|SUBID10015|   Bhagvan|  Srivastav|            Edwin|1966-07-24|Female|+91 0297693485|  India|          Bhimavaram|  436513|     S105|       Y|1986-07-24|1988-02-04|\n|SUBID10016| Amritkala|  Srivastav|        Guha Path|1933-11-20|Female|+91 0537157280|  India|              Meerut|  863467|     S106|       Y|1953-11-20|1955-07-29|\n|SUBID10017|    Bandhu|       Seth|        Varughese|1996-10-15|  Male|+91 0695289163|  India|           Chinsurah|  136713|     S108|       N|2016-10-15|2018-06-08|\n|SUBID10018|Bhagavaana|      Kumar|    Kulkarni Zila|1935-09-16|Female|+91 6071745855|  India|        Shahjahanpur|  597276|     S101|       N|1955-09-16|1958-05-31|\n|SUBID10019|      NULL|     Maurya|     Sharaf Nagar|1924-11-09|Female|+91 8906694405|  India|            Jabalpur|  958538|     S104|       N|1944-11-09|1951-10-14|\n+----------+----------+-----------+-----------------+----------+------+--------------+-------+--------------------+--------+---------+--------+----------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_sb = spark.read.options(inferSchema = 'True', header = 'True').csv(\"s3://sbdtestbuck/capstone_prj/raw_data/subscriber/subscriber.csv\")\n",
    "\n",
    "df_sb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "984d0245-06bc-49b7-ae1d-e92c0d3e197d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|Claim_Or_Rejected|    SUB_ID|claim_amount|claim_date|claim_id|      claim_type|    disease_name|patient_id|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|                N| SUBID1000|       79874|1949-03-14|       0| claims of value|    Galactosemia|    187158|\n|              NaN|SUBID10001|      151142|1970-03-16|       1|claims of policy|  Bladder cancer|    112766|\n|              NaN|SUBID10002|       59924|2008-02-03|       2| claims of value|   Kidney cancer|    199252|\n|              NaN|SUBID10003|      143120|1995-02-08|       3|  claims of fact|         Suicide|    133424|\n|                Y|SUBID10004|      168634|1967-05-23|       4| claims of value|    Food allergy|    172579|\n|              NaN|SUBID10005|       64840|1991-10-04|       5|claims of policy|        Whiplash|    171320|\n|                N| SUBID1006|       26800|1991-03-26|       6|  claims of fact|      Sunbathing|    107794|\n|              NaN|SUBID10007|      177186|1946-09-05|       7| claims of value|Drug consumption|    130339|\n|                N|SUBID10008|      141123|1966-06-20|       8|  claims of fact|          Dengue|    110377|\n|                N|SUBID10009|       88540|1945-12-29|       9| claims of value|    Head banging|    149367|\n|                N| SUBID1010|       29150|1999-01-25|      10| claims of value| Fanconi anaemia|    156168|\n|                Y|SUBID10011|       40897|1975-02-08|      11| claims of value|   Breast cancer|    114241|\n|              NaN|SUBID10012|       75983|1985-02-12|      12| claims of value|         Anthrax|    146382|\n|              NaN|SUBID10013|      192340|2014-07-30|      13|  claims of fact| Cystic fibrosis|    132748|\n|                N|SUBID10014|      118628|2003-12-18|      14| claims of value|    Galactosemia|    167340|\n|                Y|SUBID10015|      100224|1986-08-02|      15| claims of value|          Dengue|    135184|\n|                N|SUBID10016|       42860|1955-01-20|      16| claims of value|        Smallpox|    179662|\n|                N|SUBID10017|      161786|2017-06-01|      17|claims of policy|  Pollen allergy|    184479|\n|              NaN|SUBID10018|       66129|1956-01-04|      18|  claims of fact|   Breast cancer|    156988|\n|              NaN|SUBID10019|      182552|1948-07-26|      19| claims of value|        Glaucoma|    132870|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_cl = spark.read.options(inferSchema = 'True', header = 'True').json(\"s3://sbdtestbuck/capstone_prj/raw_data/claims/claims.json\")\n",
    "\n",
    "df_cl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97d53ae6-dbb5-444e-9541-91332f867a77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Cleaning Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67bf011f-a2e8-48a1-aa67-9c6fb9a2b09c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------+------------------+--------------+-----------------+--------------------+-----------+\n|Patient_id|Patient_name|patient_gender|patient_birth_date| patient_phone|     disease_name|                city|hospital_id|\n+----------+------------+--------------+------------------+--------------+-----------------+--------------------+-----------+\n|    149367|        NULL|          Male|        1925-06-12|+91 1780763280|     Head banging|           Bangalore|      H1013|\n|    156168|        NULL|          Male|        1976-02-03|+91 5586075345|  Fanconi anaemia|              Rajkot|      H1004|\n|    114241|        NULL|        Female|        1955-01-22|+91 4146391938|    Breast cancer|           Ghaziabad|      H1015|\n|    167340|        NULL|        Female|        1981-01-25|+91 2960004518|     Galactosemia|Surendranagar Dud...|      H1003|\n|    132870|        NULL|        Female|        1924-11-09|+91 8906694405|         Glaucoma|            Jabalpur|      H1017|\n|    117945|        NULL|          Male|        1955-12-24|+91 2416747182|         Glaucoma|          Karimnagar|      H1009|\n|    197503|        NULL|        Female|        1968-07-02|+91 2599794460|           Stroke|             Gwalior|      H1009|\n|    146555|        NULL|          Male|        1948-11-10|+91 8390195092|  Phenylketonuria|            Vadodara|      H1007|\n|    199114|        NULL|        Female|        1955-04-07|+91 7434031446|  Phenylketonuria|          Vijayawada|      H1017|\n|    156223|        NULL|        Female|        1930-11-25|          NULL|  Fanconi anaemia|            Agartala|      H1012|\n|    196369|        NULL|          Male|        1931-02-04|+91 2973105946|          Choking|            Shivpuri|      H1017|\n|    194166|        NULL|          Male|        1946-10-17|+91 9887324437|Colorectal cancer|           Baranagar|      H1015|\n|    180709|        NULL|          Male|        1988-06-27|+91 6877897646|          Anthrax|                Pali|      H1017|\n|    164524|        NULL|        Female|        1966-09-25|+91 6477918745|     Mold allergy|           Kharagpur|      H1015|\n|    156364|        NULL|          Male|        1994-01-13|+91 8444537013|          Cholera|            Panihati|      H1019|\n|    105686|        NULL|          Male|        1930-09-01|+91 7061843400|        Hepatitis|            Kolhapur|      H1008|\n|    114252|        NULL|        Female|        1927-02-26|+91 4984346995|         Diabetes|           Ambarnath|      H1014|\n+----------+------------+--------------+------------------+--------------+-----------------+--------------------+-----------+\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Check for null\n",
    "from pyspark.sql.functions import col \n",
    "# rows_with_null = df_pr.filter(df_pr.isNull())\n",
    "# rows_with_null.show()\n",
    "\n",
    "# Fetch and display rows with null values in any column\n",
    "rows_with_null = df_pr.filter(\n",
    "    col(\"Patient_id\").isNull()|\n",
    "    col(\"Patient_Name\").isNull()|\n",
    "    col(\"patient_gender\").isNull()|\n",
    "    col(\"patient_birth_date\").isNull()|\n",
    "    col(\"disease_name\").isNull()|\n",
    "    col(\"city\").isNull()|\n",
    "    col(\"hospital_id\").isNull()\n",
    ")\n",
    "\n",
    "rows_with_null.show()\n",
    "rows_with_null.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0f60037-ccc2-405e-b9ac-5023094d2d25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count total Null Values for each column\n",
    "rows_with_null.count()\n",
    "\n",
    "# only Patient_Name has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e05777b1-7d09-4127-b8b2-a9d8a708cc12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------+------------------+--------------+----------------+--------------------+-----------+\n|Patient_id|Patient_name|patient_gender|patient_birth_date| patient_phone|    disease_name|                city|hospital_id|\n+----------+------------+--------------+------------------+--------------+----------------+--------------------+-----------+\n|    187158|      Harbir|        Female|        1924-06-30|+91 0112009318|    Galactosemia|            Rourkela|      H1001|\n|    112766|    Brahmdev|        Female|        1948-12-20|+91 1727749552|  Bladder cancer|        Tiruvottiyur|      H1016|\n|    199252|     Ujjawal|          Male|        1980-04-16|+91 8547451606|   Kidney cancer|           Berhampur|      H1009|\n|    133424|     Ballari|        Female|        1969-09-25|+91 0106026841|         Suicide|        Bihar Sharif|      H1017|\n|    172579|     Devnath|        Female|        1946-05-01|+91 1868774631|    Food allergy|         Bidhannagar|      H1019|\n|    171320|       Atasi|          Male|        1967-10-02|+91 9747336855|        Whiplash|            Amravati|      H1013|\n|    107794|      Manish|          Male|        1967-06-06|+91 4354294043|      Sunbathing|              Panvel|      H1004|\n|    130339|       Aakar|        Female|        1925-03-05|+91 2777633911|Drug consumption|        Bihar Sharif|      H1000|\n|    110377|     Gurudas|          Male|        1945-05-06|+91 1232859381|          Dengue|           Kamarhati|      H1001|\n|    149367|          NA|          Male|        1925-06-12|+91 1780763280|    Head banging|           Bangalore|      H1013|\n|    156168|          NA|          Male|        1976-02-03|+91 5586075345| Fanconi anaemia|              Rajkot|      H1004|\n|    114241|          NA|        Female|        1955-01-22|+91 4146391938|   Breast cancer|           Ghaziabad|      H1015|\n|    146382|  Dharmadaas|          Male|        1964-04-29|+91 6345482027|         Anthrax|Bhalswa Jahangir Pur|      H1019|\n|    132748|    Brahmvir|          Male|        1991-11-11|+91 7316972612| Cystic fibrosis|              Ambala|      H1018|\n|    167340|          NA|        Female|        1981-01-25|+91 2960004518|    Galactosemia|Surendranagar Dud...|      H1003|\n|    135184|     Bhagvan|        Female|        1966-07-24|+91 0297693485|          Dengue|          Bhimavaram|      H1018|\n|    179662|   Amritkala|        Female|        1933-11-20|+91 0537157280|        Smallpox|              Meerut|      H1018|\n|    184479|      Bandhu|          Male|        1996-10-15|+91 0695289163|  Pollen allergy|           Chinsurah|      H1010|\n|    156988|  Bhagavaana|        Female|        1935-09-16|+91 6071745855|   Breast cancer|        Shahjahanpur|      H1012|\n|    132870|          NA|        Female|        1924-11-09|+91 8906694405|        Glaucoma|            Jabalpur|      H1017|\n+----------+------------+--------------+------------------+--------------+----------------+--------------------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Replace the null values for specific columns by NA\n",
    "\n",
    "columns_to_fillna = [\"Patient_name\"]\n",
    "\n",
    "for col_name in columns_to_fillna:\n",
    "    df_pr = df_pr.fillna(\"NA\", subset=[col_name])\n",
    "\n",
    "df_pr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e342673-9b2c-4f28-8ed6-7ff2e3b03d81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------+------------------+-------------+------------+----+-----------+\n|Patient_id|Patient_name|patient_gender|patient_birth_date|patient_phone|disease_name|city|hospital_id|\n+----------+------------+--------------+------------------+-------------+------------+----+-----------+\n+----------+------------+--------------+------------------+-------------+------------+----+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# df_pr.count()\n",
    "# Fetch and display rows with null values in any column\n",
    "rows_with_null = df_pr.filter(\n",
    "    col(\"Patient_id\").isNull()|\n",
    "    col(\"Patient_Name\").isNull()|\n",
    "    col(\"patient_gender\").isNull()|\n",
    "    col(\"patient_birth_date\").isNull()|\n",
    "    col(\"disease_name\").isNull()|\n",
    "    col(\"city\").isNull()|\n",
    "    col(\"hospital_id\").isNull()\n",
    ")\n",
    "\n",
    "rows_with_null.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cccce2b-3e13-4b54-b573-1e9be752bb96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------+------------------+-------------+------------+----+-----------+---------------+\n|Patient_id|Patient_name|patient_gender|patient_birth_date|patient_phone|disease_name|city|hospital_id|duplicate_count|\n+----------+------------+--------------+------------------+-------------+------------+----+-----------+---------------+\n+----------+------------+--------------+------------------+-------------+------------+----+-----------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Create a window specification to identify duplicates\n",
    "window_spec = Window.partitionBy(df_pr.columns).orderBy(\"Patient_id\")\n",
    "\n",
    "# Add a count column to identify duplicates\n",
    "df_duplicates = df_pr.withColumn(\"duplicate_count\", F.count(\"*\").over(window_spec))\n",
    "\n",
    "# Filter rows with duplicate_count > 1\n",
    "duplicate_rows = df_duplicates.filter(\"duplicate_count > 1\")\n",
    "\n",
    "# Display rows with duplicates\n",
    "duplicate_rows.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20214874-f4e8-45ba-b376-b8457175d528",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-----+\n|Patient_id|patient_gender|count|\n+----------+--------------+-----+\n+----------+--------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# CHeck if there are any duplicate records\n",
    "\n",
    "df_pr.groupby('Patient_id','patient_gender') \\\n",
    "    .count() \\\n",
    "    .filter(F.col('count') > 1) \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f62c5d37-f618-43f0-9034-0129377081f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bf9d97f-0662-4576-ae94-7e105797b9ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop Duplicates if exists\n",
    "# No duplicates exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cf7e6be-5a1c-4e28-b280-909e938aed20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_pr.write.csv(\"s3://sbdtestbuck/capstone_prj/cleaned_data/patient_records.csv\")\n",
    "# df_pr.write.parquet(\"s3://sbdtestbuck/capstone_prj/cleaned_data/patient_records.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f10c2297-dc21-4c7a-8e70-32bc61784a59",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Cleaning Subscriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bc9a11d-75e9-4911-8112-63f2f9a5bdf4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+-----------------+----------+------+--------------+-------+--------------------+--------+---------+--------+----------+----------+\n|   sub _id|first_name|  last_name|           Street|Birth_date|Gender|         Phone|Country|                City|Zip Code|Subgrp_id|Elig_ind|  eff_date| term_date|\n+----------+----------+-----------+-----------------+----------+------+--------------+-------+--------------------+--------+---------+--------+----------+----------+\n|SUBID10000|    Harbir|Vishwakarma|       Baria Marg|1924-06-30|Female|+91 0112009318|  India|            Rourkela|  767058|     S107|       Y|1944-06-30|1954-01-14|\n|SUBID10001|  Brahmdev|     Sonkar|        Lala Marg|1948-12-20|Female|+91 1727749552|  India|        Tiruvottiyur|   34639|     S105|       Y|1968-12-20|1970-05-16|\n|SUBID10002|   Ujjawal|       Devi|      Mammen Zila|1980-04-16|  Male|+91 8547451606|  India|           Berhampur|  914455|     S106|       N|2000-04-16|2008-05-04|\n|SUBID10003|   Ballari|     Mishra|       Sahni Zila|1969-09-25|Female|+91 0106026841|  India|        Bihar Sharif|   91481|     S104|       N|1989-09-25|1995-06-05|\n|SUBID10004|   Devnath|  Srivastav|       Magar Zila|1946-05-01|Female|+91 1868774631|  India|         Bidhannagar|  531742|     S110|       N|1966-05-01|1970-12-09|\n|SUBID10005|     Atasi|       Seth|     Khatri Nagar|1967-10-02|  Male|+91 9747336855|  India|            Amravati|  229062|     S104|       Y|1987-10-02|1995-02-13|\n| SUBID1006|    Manish|     Maurya|Swaminathan Chowk|1967-06-06|  Male|+91 4354294043|  India|              Panvel|  438733|     S109|    NULL|1987-06-06|1995-03-21|\n|SUBID10007|     Aakar|      Yadav|            Swamy|1925-03-05|Female|+91 2777633911|  India|        Bihar Sharif|  535907|     S104|       N|1945-03-05|1946-11-07|\n|SUBID10008|   Gurudas|      Gupta|      Sarin Nagar|1945-05-06|  Male|+91 1232859381|  India|           Kamarhati|  933226|     S103|       Y|1965-05-06|1970-09-16|\n|SUBID10009|      NULL|      Gupta|    Thakur Circle|1925-06-12|  Male|+91 1780763280|  India|           Bangalore|  957469|     S105|       Y|1945-06-12|1953-08-30|\n| SUBID1010|      NULL|     Divedi|          Dhillon|1976-02-03|  Male|+91 5586075345|  India|              Rajkot|  911319|     S102|       Y|1996-02-03|2002-01-27|\n|SUBID10011|      NULL|Vishwakarma|      Rajagopalan|1955-01-22|Female|+91 4146391938|  India|           Ghaziabad|  337042|     S106|       N|1975-01-22|1978-11-02|\n|SUBID10012|Dharmadaas|     Tiwari|             Rama|1964-04-29|  Male|+91 6345482027|  India|Bhalswa Jahangir Pur|  430793|     S103|       N|1984-04-29|1988-02-07|\n|SUBID10013|  Brahmvir|        Rai|        Shah Path|1991-11-11|  Male|+91 7316972612|  India|              Ambala|  249898|     S106|       N|2011-11-11|2020-05-23|\n|SUBID10014|      NULL|  Srivastav|     Chandra Path|1981-01-25|Female|+91 2960004518|  India|Surendranagar Dud...|  111966|     S102|       N|2001-01-25|2005-07-13|\n|SUBID10015|   Bhagvan|  Srivastav|            Edwin|1966-07-24|Female|+91 0297693485|  India|          Bhimavaram|  436513|     S105|       Y|1986-07-24|1988-02-04|\n|SUBID10016| Amritkala|  Srivastav|        Guha Path|1933-11-20|Female|+91 0537157280|  India|              Meerut|  863467|     S106|       Y|1953-11-20|1955-07-29|\n|SUBID10017|    Bandhu|       Seth|        Varughese|1996-10-15|  Male|+91 0695289163|  India|           Chinsurah|  136713|     S108|       N|2016-10-15|2018-06-08|\n|SUBID10018|Bhagavaana|      Kumar|    Kulkarni Zila|1935-09-16|Female|+91 6071745855|  India|        Shahjahanpur|  597276|     S101|       N|1955-09-16|1958-05-31|\n|SUBID10019|      NULL|     Maurya|     Sharaf Nagar|1924-11-09|Female|+91 8906694405|  India|            Jabalpur|  958538|     S104|       N|1944-11-09|1951-10-14|\n+----------+----------+-----------+-----------------+----------+------+--------------+-------+--------------------+--------+---------+--------+----------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# check if there are null values in dataset\n",
    "df_sb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78ad1360-b474-44ce-986c-8907a6ff10ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+-----------------+----------+------+--------------+-------+--------------------+--------+---------+--------+----------+----------+\n|   sub _id|first_name|  last_name|           Street|Birth_date|Gender|         Phone|Country|                City|Zip Code|Subgrp_id|Elig_ind|  eff_date| term_date|\n+----------+----------+-----------+-----------------+----------+------+--------------+-------+--------------------+--------+---------+--------+----------+----------+\n| SUBID1006|    Manish|     Maurya|Swaminathan Chowk|1967-06-06|  Male|+91 4354294043|  India|              Panvel|  438733|     S109|    NULL|1987-06-06|1995-03-21|\n|SUBID10009|      NULL|      Gupta|    Thakur Circle|1925-06-12|  Male|+91 1780763280|  India|           Bangalore|  957469|     S105|       Y|1945-06-12|1953-08-30|\n| SUBID1010|      NULL|     Divedi|          Dhillon|1976-02-03|  Male|+91 5586075345|  India|              Rajkot|  911319|     S102|       Y|1996-02-03|2002-01-27|\n|SUBID10011|      NULL|Vishwakarma|      Rajagopalan|1955-01-22|Female|+91 4146391938|  India|           Ghaziabad|  337042|     S106|       N|1975-01-22|1978-11-02|\n|SUBID10014|      NULL|  Srivastav|     Chandra Path|1981-01-25|Female|+91 2960004518|  India|Surendranagar Dud...|  111966|     S102|       N|2001-01-25|2005-07-13|\n|SUBID10019|      NULL|     Maurya|     Sharaf Nagar|1924-11-09|Female|+91 8906694405|  India|            Jabalpur|  958538|     S104|       N|1944-11-09|1951-10-14|\n|SUBID10022|   Prakash|        Rao|           Sachar|1923-09-15|Female|+91 9268324471|  India|            Kottayam|  180680|     NULL|       N|1943-09-15|1948-10-19|\n|SUBID10025|      NULL|     Tiwari|        Sha Chowk|1955-12-24|  Male|+91 2416747182|  India|          Karimnagar|  567762|     S106|       N|1975-12-24|1983-02-03|\n| SUBID1032|      NULL|       Seth|     Sandhu Chowk|1968-07-02|Female|+91 2599794460|  India|             Gwalior|  611826|     S110|       N|1988-07-02|1991-03-14|\n| SUBID1036|   Upasana|     Thakur|        Vasa Ganj|1927-10-03|Female|          NULL|  India|              Ratlam|  326733|     S108|       N|1947-10-03|1951-02-20|\n| SUBID1037|      NULL|     Rajput|      Shere Chowk|1948-11-10|  Male|+91 8390195092|  India|            Vadodara|  877443|     S101|       Y|1968-11-10|1973-12-25|\n| SUBID1038|      NULL|     Thakur|   Rastogi Street|1955-04-07|Female|+91 7434031446|  India|          Vijayawada|  438940|     S104|    NULL|1975-04-07|1982-01-25|\n| SUBID1041|      NULL|     Rajput|       Sinha Path|1930-11-25|Female|          NULL|  India|            Agartala|  303503|     S110|       Y|1950-11-25|1957-09-14|\n| SUBID1047|      NULL|        Rai|      Sagar Chowk|1931-02-04|  Male|+91 2973105946|  India|            Shivpuri|  794170|     S109|       Y|1951-02-04|1955-07-14|\n|SUBID10049|   Paridhi|      Yadav|        Sant Path|1959-03-27|Female|+91 2139280879|  India|            Jabalpur|  883754|     NULL|       N|1979-03-27|1985-06-01|\n|SUBID10051|      NULL|     Rajput|    Chauhan Chowk|1946-10-17|  Male|+91 9887324437|  India|           Baranagar|  765234|     S103|       Y|1966-10-17|1969-06-26|\n|SUBID10053|      NULL|     Sonkar|      Shetty Marg|1988-06-27|  Male|+91 6877897646|  India|                Pali|  383290|     S102|       Y|2008-06-27|2016-10-30|\n|SUBID10061|      NULL|     Rajput|       Anand Path|1966-09-25|Female|+91 6477918745|  India|           Kharagpur|  934938|     S103|    NULL|1986-09-25|1991-06-03|\n|SUBID10064|      NULL|     Pandey|      Mangat Path|1994-01-13|  Male|+91 8444537013|  India|            Panihati|  643791|     S110|       N|2014-01-13|2019-02-24|\n|SUBID10066|      NULL|       Seth|   Chaudhuri Marg|1930-09-01|  Male|+91 7061843400|  India|            Kolhapur|  597470|     S102|       N|1950-09-01|1957-12-01|\n+----------+----------+-----------+-----------------+----------+------+--------------+-------+--------------------+--------+---------+--------+----------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Count the total Null values for each column\n",
    "# Fetch and display rows with null values in any column\n",
    "rows_with_null_sb = df_sb.filter(\n",
    "    col(\"sub _id\").isNull()|\n",
    "    col(\"first_name\").isNull()|\n",
    "    col(\"last_name\").isNull()|\n",
    "    col(\"Street\").isNull()|\n",
    "    col(\"Birth_date\").isNull()|\n",
    "    col(\"Gender\").isNull()|\n",
    "    col(\"Phone\").isNull()|\n",
    "    col(\"Country\").isNull()|\n",
    "    col(\"City\").isNull()|\n",
    "    col(\"Zip Code\").isNull()|\n",
    "    col(\"subgrp_id\").isNull()|\n",
    "    col(\"Elig_ind\").isNull()|\n",
    "    col(\"Gender\").isNull()|\n",
    "    col(\"eff_date\").isNull()|\n",
    "    col(\"term_date\").isNull())\n",
    "    \n",
    "rows_with_null_sb.show()\n",
    "\n",
    "#33 rows contains NULL\n",
    "# COLUMNS WITH NULL: first_name, Phone, Subgrp_id, Elig_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7994dd9-1a03-427c-a0be-a2c01e48b0c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_null_sb.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3444a91a-b7cd-4ad1-a6aa-4f3bc4506a85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# And then replace the null values for specific columns by NA \n",
    "# COLUMNS WITH NULL: first_name, Phone, Subgrp_id, Elig_ind\n",
    "\n",
    "columns_to_fillna = [\"first_name\",\"Phone\",\"Subgrp_id\",\"Elig_ind\"]\n",
    "\n",
    "for col_name in columns_to_fillna:\n",
    "    df_sb = df_sb.fillna(\"NA\", subset=[col_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "036a60b1-09ec-4d17-8d02-6c107f98807b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+----------+------+-----+-------+----+--------+---------+--------+--------+---------+\n|sub _id|first_name|last_name|Street|Birth_date|Gender|Phone|Country|City|Zip Code|Subgrp_id|Elig_ind|eff_date|term_date|\n+-------+----------+---------+------+----------+------+-----+-------+----+--------+---------+--------+--------+---------+\n+-------+----------+---------+------+----------+------+-----+-------+----+--------+---------+--------+--------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# Checking NULL again\n",
    "\n",
    "rows_with_null_sb = df_sb.filter(\n",
    "    col(\"sub _id\").isNull()|\n",
    "    col(\"first_name\").isNull()|\n",
    "    col(\"last_name\").isNull()|\n",
    "    col(\"Street\").isNull()|\n",
    "    col(\"Birth_date\").isNull()|\n",
    "    col(\"Gender\").isNull()|\n",
    "    col(\"Phone\").isNull()|\n",
    "    col(\"Country\").isNull()|\n",
    "    col(\"City\").isNull()|\n",
    "    col(\"Zip Code\").isNull()|\n",
    "    col(\"subgrp_id\").isNull()|\n",
    "    col(\"Elig_ind\").isNull()|\n",
    "    col(\"Gender\").isNull()|\n",
    "    col(\"eff_date\").isNull()|\n",
    "    col(\"term_date\").isNull())\n",
    "    \n",
    "rows_with_null_sb.show()\n",
    "\n",
    "# All NULL dealth with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5811d527-101e-43f2-adcb-fc8cb472ed3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+\n|last_name|Birth_date|count|\n+---------+----------+-----+\n+---------+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Check the If three are duplicates records\n",
    "\n",
    "duplicate_rows = df_sb.groupBy('last_name','Birth_date').count().filter('count > 1')\n",
    "duplicate_rows.show()\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10ddc851-f634-4faf-98dd-26e076082fc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n",
       "\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n",
       "\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       },
       "metadata": {
        "errorSummary": "[UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "UNRESOLVED_USING_COLUMN_FOR_JOIN",
        "sqlState": "42703",
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\n",
    "\n",
    "df_with_duplicates = df_sb.join(duplicate_rows, ['first_name', 'last_name'], 'inner')\n",
    "df_with_duplicates.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3818720d-6ca9-470c-85cb-ab22e12ccba9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n",
       "\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n",
       "\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "UNRESOLVED_USING_COLUMN_FOR_JOIN",
        "sqlState": "42703",
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If there are duplicates then drop duplicates\n",
    "# No significant duplicates found\n",
    "\n",
    "df_sb.count()\n",
    "# df_sb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd87cf34-f727-404e-b5f3-f8584ca42d2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n",
       "\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n",
       "\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "UNRESOLVED_USING_COLUMN_FOR_JOIN",
        "sqlState": "42703",
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_sb.write.csv(\"s3://sbdtestbuck/capstone_prj/cleaned_data/subscriber.csv\")\n",
    "# df_sb.write.parquet(\"s3://sbdtestbuck/capstone_prj/cleaned_data/subscriber.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c1de77c-db3c-404c-9478-6483be0a922e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Cleaning Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18591160-7d88-4f8c-8a82-a5c37c9280c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|Claim_Or_Rejected|    SUB_ID|claim_amount|claim_date|claim_id|      claim_type|    disease_name|patient_id|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|                N| SUBID1000|       79874|1949-03-14|       0| claims of value|    Galactosemia|    187158|\n|              NaN|SUBID10001|      151142|1970-03-16|       1|claims of policy|  Bladder cancer|    112766|\n|              NaN|SUBID10002|       59924|2008-02-03|       2| claims of value|   Kidney cancer|    199252|\n|              NaN|SUBID10003|      143120|1995-02-08|       3|  claims of fact|         Suicide|    133424|\n|                Y|SUBID10004|      168634|1967-05-23|       4| claims of value|    Food allergy|    172579|\n|              NaN|SUBID10005|       64840|1991-10-04|       5|claims of policy|        Whiplash|    171320|\n|                N| SUBID1006|       26800|1991-03-26|       6|  claims of fact|      Sunbathing|    107794|\n|              NaN|SUBID10007|      177186|1946-09-05|       7| claims of value|Drug consumption|    130339|\n|                N|SUBID10008|      141123|1966-06-20|       8|  claims of fact|          Dengue|    110377|\n|                N|SUBID10009|       88540|1945-12-29|       9| claims of value|    Head banging|    149367|\n|                N| SUBID1010|       29150|1999-01-25|      10| claims of value| Fanconi anaemia|    156168|\n|                Y|SUBID10011|       40897|1975-02-08|      11| claims of value|   Breast cancer|    114241|\n|              NaN|SUBID10012|       75983|1985-02-12|      12| claims of value|         Anthrax|    146382|\n|              NaN|SUBID10013|      192340|2014-07-30|      13|  claims of fact| Cystic fibrosis|    132748|\n|                N|SUBID10014|      118628|2003-12-18|      14| claims of value|    Galactosemia|    167340|\n|                Y|SUBID10015|      100224|1986-08-02|      15| claims of value|          Dengue|    135184|\n|                N|SUBID10016|       42860|1955-01-20|      16| claims of value|        Smallpox|    179662|\n|                N|SUBID10017|      161786|2017-06-01|      17|claims of policy|  Pollen allergy|    184479|\n|              NaN|SUBID10018|       66129|1956-01-04|      18|  claims of fact|   Breast cancer|    156988|\n|              NaN|SUBID10019|      182552|1948-07-26|      19| claims of value|        Glaucoma|    132870|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_cl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67dfe08a-464b-454e-804e-717b3d269a48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+------------+----------+--------+----------+------------+----------+\n|Claim_Or_Rejected|SUB_ID|claim_amount|claim_date|claim_id|claim_type|disease_name|patient_id|\n+-----------------+------+------------+----------+--------+----------+------------+----------+\n+-----------------+------+------------+----------+--------+----------+------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Checking for NULL\n",
    "\n",
    "\n",
    "rows_with_null_cl = df_cl.filter(\n",
    "    col(\"Claim_Or_Rejected\").isNull()|\n",
    "    col(\"claim_amount\").isNull()|\n",
    "    col(\"claim_date\").isNull()|\n",
    "    col(\"claim_type\").isNull()|\n",
    "    col(\"claim_type\").isNull()|\n",
    "    col(\"disease_name\").isNull()|\n",
    "    col(\"patient_id\").isNull())\n",
    "\n",
    "    \n",
    "rows_with_null_cl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0698e5e-7410-4842-aede-d7403bb2b2cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n|Claim_Or_Rejected|count|\n+-----------------+-----+\n|                Y|   18|\n|                N|   22|\n|              NaN|   30|\n+-----------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# It seems only the first column contains some NaN values\n",
    "\n",
    "# Count the occurrences of each unique value in the 'Claim_Or_Rejected' column\n",
    "claim_rejected_counts = df_cl.groupBy('Claim_Or_Rejected').count()\n",
    "\n",
    "# Show the result\n",
    "claim_rejected_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e13d3806-21b5-4ee0-a451-4e17f1b840ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|Claim_Or_Rejected|    SUB_ID|claim_amount|claim_date|claim_id|      claim_type|    disease_name|patient_id|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|                N| SUBID1000|       79874|1949-03-14|       0| claims of value|    Galactosemia|    187158|\n|               NA|SUBID10001|      151142|1970-03-16|       1|claims of policy|  Bladder cancer|    112766|\n|               NA|SUBID10002|       59924|2008-02-03|       2| claims of value|   Kidney cancer|    199252|\n|               NA|SUBID10003|      143120|1995-02-08|       3|  claims of fact|         Suicide|    133424|\n|                Y|SUBID10004|      168634|1967-05-23|       4| claims of value|    Food allergy|    172579|\n|               NA|SUBID10005|       64840|1991-10-04|       5|claims of policy|        Whiplash|    171320|\n|                N| SUBID1006|       26800|1991-03-26|       6|  claims of fact|      Sunbathing|    107794|\n|               NA|SUBID10007|      177186|1946-09-05|       7| claims of value|Drug consumption|    130339|\n|                N|SUBID10008|      141123|1966-06-20|       8|  claims of fact|          Dengue|    110377|\n|                N|SUBID10009|       88540|1945-12-29|       9| claims of value|    Head banging|    149367|\n|                N| SUBID1010|       29150|1999-01-25|      10| claims of value| Fanconi anaemia|    156168|\n|                Y|SUBID10011|       40897|1975-02-08|      11| claims of value|   Breast cancer|    114241|\n|               NA|SUBID10012|       75983|1985-02-12|      12| claims of value|         Anthrax|    146382|\n|               NA|SUBID10013|      192340|2014-07-30|      13|  claims of fact| Cystic fibrosis|    132748|\n|                N|SUBID10014|      118628|2003-12-18|      14| claims of value|    Galactosemia|    167340|\n|                Y|SUBID10015|      100224|1986-08-02|      15| claims of value|          Dengue|    135184|\n|                N|SUBID10016|       42860|1955-01-20|      16| claims of value|        Smallpox|    179662|\n|                N|SUBID10017|      161786|2017-06-01|      17|claims of policy|  Pollen allergy|    184479|\n|               NA|SUBID10018|       66129|1956-01-04|      18|  claims of fact|   Breast cancer|    156988|\n|               NA|SUBID10019|      182552|1948-07-26|      19| claims of value|        Glaucoma|    132870|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Replace NaN values with 'NA' in the 'Claim_Or_Rejected' column\n",
    "df_cl_filled = df_cl.withColumn('Claim_Or_Rejected', F.when(F.col('Claim_Or_Rejected') == 'NaN', 'NA').otherwise(F.col('Claim_Or_Rejected')))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_cl_filled.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86b6ba98-31d3-4600-a099-64b875fc2d0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cl_filled.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9530b6c-b747-42aa-9d57-7f0c1b195fdd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n|    disease_name|count|\n+----------------+-----+\n|             Flu|    2|\n|  Bladder cancer|    2|\n| Fanconi anaemia|    2|\n|      Lymphedema|    2|\n|    Mold allergy|    2|\n|        Diabetes|    2|\n|         Cholera|    2|\n|          Stroke|    2|\n|     Pet allergy|    3|\n|         Anthrax|    3|\n|         Malaria|    2|\n|    Galactosemia|    3|\n|          Scurvy|    2|\n|         Choking|    2|\n|   Rett Syndrome|    2|\n|        Glaucoma|    3|\n| Phenylketonuria|    3|\n|          Asthma|    2|\n|         Measles|    2|\n|Drug consumption|    2|\n+----------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "duplicated_rows_cl = df_cl_filled.groupBy('disease_name').count().filter('count > 1')\n",
    "duplicated_rows_cl.show()\n",
    "\n",
    "# 'Claim_Or_Rejected','SUB_ID','claim_amount','claim_date','claim_id','claim_type','disease_name',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac1ebad6-8351-4312-90e1-dc3f36cee16a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----+\n|SUB_ID|claim_type|count|\n+------+----------+-----+\n+------+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "duplicated_rows_cl = df_cl_filled.groupBy('SUB_ID','claim_type').count().filter('count > 1')\n",
    "duplicated_rows_cl.show()\n",
    "\n",
    "# 'Claim_Or_Rejected','SUB_ID','claim_amount','claim_date','claim_id','claim_type','disease_name',\n",
    "\n",
    "# Seems like df_cl_filled is clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef4e6358-330e-4672-b66a-5ebeca3c7d42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|Claim_Or_Rejected|    SUB_ID|claim_amount|claim_date|claim_id|      claim_type|    disease_name|patient_id|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|                N| SUBID1000|       79874|1949-03-14|       0| claims of value|    Galactosemia|    187158|\n|               NA|SUBID10001|      151142|1970-03-16|       1|claims of policy|  Bladder cancer|    112766|\n|               NA|SUBID10002|       59924|2008-02-03|       2| claims of value|   Kidney cancer|    199252|\n|               NA|SUBID10003|      143120|1995-02-08|       3|  claims of fact|         Suicide|    133424|\n|                Y|SUBID10004|      168634|1967-05-23|       4| claims of value|    Food allergy|    172579|\n|               NA|SUBID10005|       64840|1991-10-04|       5|claims of policy|        Whiplash|    171320|\n|                N| SUBID1006|       26800|1991-03-26|       6|  claims of fact|      Sunbathing|    107794|\n|               NA|SUBID10007|      177186|1946-09-05|       7| claims of value|Drug consumption|    130339|\n|                N|SUBID10008|      141123|1966-06-20|       8|  claims of fact|          Dengue|    110377|\n|                N|SUBID10009|       88540|1945-12-29|       9| claims of value|    Head banging|    149367|\n|                N| SUBID1010|       29150|1999-01-25|      10| claims of value| Fanconi anaemia|    156168|\n|                Y|SUBID10011|       40897|1975-02-08|      11| claims of value|   Breast cancer|    114241|\n|               NA|SUBID10012|       75983|1985-02-12|      12| claims of value|         Anthrax|    146382|\n|               NA|SUBID10013|      192340|2014-07-30|      13|  claims of fact| Cystic fibrosis|    132748|\n|                N|SUBID10014|      118628|2003-12-18|      14| claims of value|    Galactosemia|    167340|\n|                Y|SUBID10015|      100224|1986-08-02|      15| claims of value|          Dengue|    135184|\n|                N|SUBID10016|       42860|1955-01-20|      16| claims of value|        Smallpox|    179662|\n|                N|SUBID10017|      161786|2017-06-01|      17|claims of policy|  Pollen allergy|    184479|\n|               NA|SUBID10018|       66129|1956-01-04|      18|  claims of fact|   Breast cancer|    156988|\n|               NA|SUBID10019|      182552|1948-07-26|      19| claims of value|        Glaucoma|    132870|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_cl_filled.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b136d25-8d2c-40de-a6b1-f4ceab1a212f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|Claim_Or_Rejected|    SUB_ID|claim_amount|claim_date|claim_id|      claim_type|    disease_name|patient_id|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|                N| SUBID1000|       79874|1949-03-14|       0| claims of value|    Galactosemia|    187158|\n|               NA|SUBID10001|      151142|1970-03-16|       1|claims of policy|  Bladder cancer|    112766|\n|               NA|SUBID10002|       59924|2008-02-03|       2| claims of value|   Kidney cancer|    199252|\n|               NA|SUBID10003|      143120|1995-02-08|       3|  claims of fact|         Suicide|    133424|\n|                Y|SUBID10004|      168634|1967-05-23|       4| claims of value|    Food allergy|    172579|\n|               NA|SUBID10005|       64840|1991-10-04|       5|claims of policy|        Whiplash|    171320|\n|                N| SUBID1006|       26800|1991-03-26|       6|  claims of fact|      Sunbathing|    107794|\n|               NA|SUBID10007|      177186|1946-09-05|       7| claims of value|Drug consumption|    130339|\n|                N|SUBID10008|      141123|1966-06-20|       8|  claims of fact|          Dengue|    110377|\n|                N|SUBID10009|       88540|1945-12-29|       9| claims of value|    Head banging|    149367|\n|                N| SUBID1010|       29150|1999-01-25|      10| claims of value| Fanconi anaemia|    156168|\n|                Y|SUBID10011|       40897|1975-02-08|      11| claims of value|   Breast cancer|    114241|\n|               NA|SUBID10012|       75983|1985-02-12|      12| claims of value|         Anthrax|    146382|\n|               NA|SUBID10013|      192340|2014-07-30|      13|  claims of fact| Cystic fibrosis|    132748|\n|                N|SUBID10014|      118628|2003-12-18|      14| claims of value|    Galactosemia|    167340|\n|                Y|SUBID10015|      100224|1986-08-02|      15| claims of value|          Dengue|    135184|\n|                N|SUBID10016|       42860|1955-01-20|      16| claims of value|        Smallpox|    179662|\n|                N|SUBID10017|      161786|2017-06-01|      17|claims of policy|  Pollen allergy|    184479|\n|               NA|SUBID10018|       66129|1956-01-04|      18|  claims of fact|   Breast cancer|    156988|\n|               NA|SUBID10019|      182552|1948-07-26|      19| claims of value|        Glaucoma|    132870|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_cl = df_cl_filled\n",
    "\n",
    "df_cl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f578b75f-4b84-41c4-bcb9-c392f45410fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n",
       "\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n",
       "\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "UNRESOLVED_USING_COLUMN_FOR_JOIN",
        "sqlState": "42703",
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_cl_filled.write.csv(\"s3://sbdtestbuck/capstone_prj/cleaned_data/claims.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a43d4608-e448-4a56-a77c-38cb2a5bdbfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n",
       "\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n",
       "\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "UNRESOLVED_USING_COLUMN_FOR_JOIN",
        "sqlState": "42703",
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_cl_filled.write.parquet(\"s3://sbdtestbuck/capstone_prj/cleaned_data/claims.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "691bdd32-7426-4436-8363-8ece41d2f8ed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Cleaning Group_Subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14df0a8f-1b38-4447-81f1-c00e05489278",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n|SubGrp_ID|Grp_Id|\n+---------+------+\n|     S101|GRP101|\n|     S101|GRP105|\n|     S102|GRP110|\n|     S102|GRP150|\n|     S102|GRP136|\n|     S103|GRP122|\n|     S103|GRP108|\n|     S103|GRP138|\n|     S103|GRP148|\n|     S104|GRP103|\n|     S104|GRP113|\n|     S104|GRP123|\n|     S104|GRP133|\n|     S104|GRP143|\n|     S105|GRP153|\n|     S105|GRP104|\n|     S105|GRP114|\n|     S105|GRP124|\n|     S106|GRP117|\n|     S106|GRP127|\n+---------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_gs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c318f29-1e46-4e48-bdac-c18678df0d06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n|SubGrp_ID|Grp_Id|\n+---------+------+\n+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "rows_with_null_gs = df_gs.filter(\n",
    "    col('SubGrp_ID').isNull()|\n",
    "    col('Grp_Id').isNull()\n",
    ")\n",
    "\n",
    "rows_with_null_gs.show()\n",
    "\n",
    "###### --->>>> No null value exists. Most likely there are duplicates here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b3e78f8-f3fb-4025-9b2f-b039d5704142",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n|Grp_Id|count|\n+------+-----+\n|GRP104|    2|\n|GRP147|    2|\n|GRP143|    2|\n+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "\n",
    "dupli_df_gs = df_gs.groupBy('Grp_Id').count().filter('count>1')\n",
    "dupli_df_gs.show()\n",
    "\n",
    "# 'SubGrp_ID','Grp_Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6158811-096f-4bef-ab56-cc9e1f872979",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n|SubGrp_Id|count|\n+---------+-----+\n|     S105|    4|\n|     S102|    3|\n|     S106|    5|\n|     S104|    5|\n|     S107|    4|\n|     S110|    3|\n|     S101|    2|\n|     S108|    3|\n|     S109|    5|\n|     S103|    4|\n+---------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "\n",
    "dupli_df_gs = df_gs.groupBy('SubGrp_Id').count().filter('count>1')\n",
    "dupli_df_gs.show()\n",
    "\n",
    "# 'SubGrp_ID','Grp_Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d48fd0dc-b0e8-4bce-bc4f-06fff78e9e18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----+\n|SubGrp_Id|Grp_Id|count|\n+---------+------+-----+\n+---------+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "\n",
    "dupli_df_gs = df_gs.groupBy('SubGrp_Id','Grp_Id').count().filter('count>1')\n",
    "dupli_df_gs.show()\n",
    "\n",
    "# 'SubGrp_ID','Grp_Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fad78adf-2b52-4dff-bf65-15704d29ebd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n",
       "\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n",
       "\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "UNRESOLVED_USING_COLUMN_FOR_JOIN",
        "sqlState": "42703",
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Seems like group subgroup is clean too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faadab9d-1936-4cce-9d4a-f2e8e1e28612",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n",
       "\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n",
       "\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "UNRESOLVED_USING_COLUMN_FOR_JOIN",
        "sqlState": "42703",
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_gs.write.csv(\"s3://sbdtestbuck/capstone_prj/cleaned_data/grpsubgrp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "399c3bde-c805-4cf6-8343-6befb3c21c95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n",
       "\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n",
       "\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n",
       "\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "UNRESOLVED_USING_COLUMN_FOR_JOIN",
        "sqlState": "42703",
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-2351375194672867>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# innerjoining the duplicated column suspected with the main dataframe without manipulating the dataframe\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m df_with_duplicates \u001B[38;5;241m=\u001B[39m df_sb\u001B[38;5;241m.\u001B[39mjoin(duplicate_rows, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m df_with_duplicates\u001B[38;5;241m.\u001B[39mshow()\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2958\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n\u001B[1;32m   2956\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n\u001B[1;32m   2957\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 2958\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2959\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `first_name` cannot be resolved on the right side of the join. The right-side columns: [`Birth_date`, `count`, `last_name`]. SQLSTATE: 42703"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_gs.write.parquet(\"s3://sbdtestbuck/capstone_prj/cleaned_data/grpsubgrp.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7688812-7a02-489e-9bb1-90e2f821441f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_cl.createOrReplaceTempView(\"claims_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5b1db1d-1846-46d4-8ae7-b8ad9cee4142",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Claim_Or_Rejected</th><th>SUB_ID</th><th>claim_amount</th><th>claim_date</th><th>claim_id</th><th>claim_type</th><th>disease_name</th><th>patient_id</th></tr></thead><tbody><tr><td>N</td><td>SUBID1000</td><td>79874</td><td>1949-03-14</td><td>0</td><td>claims of value</td><td>Galactosemia</td><td>187158</td></tr><tr><td>NA</td><td>SUBID10001</td><td>151142</td><td>1970-03-16</td><td>1</td><td>claims of policy</td><td>Bladder cancer</td><td>112766</td></tr><tr><td>NA</td><td>SUBID10002</td><td>59924</td><td>2008-02-03</td><td>2</td><td>claims of value</td><td>Kidney cancer</td><td>199252</td></tr><tr><td>NA</td><td>SUBID10003</td><td>143120</td><td>1995-02-08</td><td>3</td><td>claims of fact</td><td>Suicide</td><td>133424</td></tr><tr><td>Y</td><td>SUBID10004</td><td>168634</td><td>1967-05-23</td><td>4</td><td>claims of value</td><td>Food allergy</td><td>172579</td></tr><tr><td>NA</td><td>SUBID10005</td><td>64840</td><td>1991-10-04</td><td>5</td><td>claims of policy</td><td>Whiplash</td><td>171320</td></tr><tr><td>N</td><td>SUBID1006</td><td>26800</td><td>1991-03-26</td><td>6</td><td>claims of fact</td><td>Sunbathing</td><td>107794</td></tr><tr><td>NA</td><td>SUBID10007</td><td>177186</td><td>1946-09-05</td><td>7</td><td>claims of value</td><td>Drug consumption</td><td>130339</td></tr><tr><td>N</td><td>SUBID10008</td><td>141123</td><td>1966-06-20</td><td>8</td><td>claims of fact</td><td>Dengue</td><td>110377</td></tr><tr><td>N</td><td>SUBID10009</td><td>88540</td><td>1945-12-29</td><td>9</td><td>claims of value</td><td>Head banging</td><td>149367</td></tr><tr><td>N</td><td>SUBID1010</td><td>29150</td><td>1999-01-25</td><td>10</td><td>claims of value</td><td>Fanconi anaemia</td><td>156168</td></tr><tr><td>Y</td><td>SUBID10011</td><td>40897</td><td>1975-02-08</td><td>11</td><td>claims of value</td><td>Breast cancer</td><td>114241</td></tr><tr><td>NA</td><td>SUBID10012</td><td>75983</td><td>1985-02-12</td><td>12</td><td>claims of value</td><td>Anthrax</td><td>146382</td></tr><tr><td>NA</td><td>SUBID10013</td><td>192340</td><td>2014-07-30</td><td>13</td><td>claims of fact</td><td>Cystic fibrosis</td><td>132748</td></tr><tr><td>N</td><td>SUBID10014</td><td>118628</td><td>2003-12-18</td><td>14</td><td>claims of value</td><td>Galactosemia</td><td>167340</td></tr><tr><td>Y</td><td>SUBID10015</td><td>100224</td><td>1986-08-02</td><td>15</td><td>claims of value</td><td>Dengue</td><td>135184</td></tr><tr><td>N</td><td>SUBID10016</td><td>42860</td><td>1955-01-20</td><td>16</td><td>claims of value</td><td>Smallpox</td><td>179662</td></tr><tr><td>N</td><td>SUBID10017</td><td>161786</td><td>2017-06-01</td><td>17</td><td>claims of policy</td><td>Pollen allergy</td><td>184479</td></tr><tr><td>NA</td><td>SUBID10018</td><td>66129</td><td>1956-01-04</td><td>18</td><td>claims of fact</td><td>Breast cancer</td><td>156988</td></tr><tr><td>NA</td><td>SUBID10019</td><td>182552</td><td>1948-07-26</td><td>19</td><td>claims of value</td><td>Glaucoma</td><td>132870</td></tr><tr><td>Y</td><td>SUBID1020</td><td>105982</td><td>1984-04-10</td><td>20</td><td>claims of value</td><td>Pet allergy</td><td>148137</td></tr><tr><td>NA</td><td>SUBID1021</td><td>55761</td><td>1953-06-24</td><td>21</td><td>claims of fact</td><td>Rett Syndrome</td><td>113280</td></tr><tr><td>Y</td><td>SUBID10022</td><td>34771</td><td>1948-05-23</td><td>22</td><td>claims of value</td><td>Flu</td><td>134184</td></tr><tr><td>N</td><td>SUBID10023</td><td>83642</td><td>1945-03-15</td><td>23</td><td>claims of value</td><td>Cholera</td><td>122592</td></tr><tr><td>NA</td><td>SUBID10024</td><td>49129</td><td>2013-08-04</td><td>24</td><td>claims of policy</td><td>Scurvy</td><td>154439</td></tr><tr><td>N</td><td>SUBID10025</td><td>36524</td><td>1976-08-24</td><td>25</td><td>claims of fact</td><td>Glaucoma</td><td>117945</td></tr><tr><td>NA</td><td>SUBID10026</td><td>192381</td><td>1966-08-30</td><td>26</td><td>claims of value</td><td>Measles</td><td>189996</td></tr><tr><td>N</td><td>SUBID10027</td><td>188520</td><td>2008-08-26</td><td>27</td><td>claims of fact</td><td>Scurvy</td><td>146540</td></tr><tr><td>N</td><td>SUBID10028</td><td>122806</td><td>1958-08-05</td><td>28</td><td>claims of policy</td><td>Flu</td><td>156434</td></tr><tr><td>NA</td><td>SUBID10029</td><td>81651</td><td>2008-02-01</td><td>29</td><td>claims of fact</td><td>Pet allergy</td><td>197352</td></tr><tr><td>NA</td><td>SUBID1030</td><td>19899</td><td>1976-09-08</td><td>30</td><td>claims of fact</td><td>Lymphedema</td><td>138778</td></tr><tr><td>N</td><td>SUBID10031</td><td>42968</td><td>1976-01-25</td><td>31</td><td>claims of fact</td><td>Alcohol consumption</td><td>162665</td></tr><tr><td>N</td><td>SUBID1032</td><td>191267</td><td>1988-12-18</td><td>32</td><td>claims of policy</td><td>Stroke</td><td>197503</td></tr><tr><td>NA</td><td>SUBID10033</td><td>161199</td><td>2019-11-17</td><td>33</td><td>claims of value</td><td>Galactosemia</td><td>113476</td></tr><tr><td>N</td><td>SUBID1034</td><td>26221</td><td>2008-08-10</td><td>34</td><td>claims of fact</td><td>Vertigo</td><td>195876</td></tr><tr><td>Y</td><td>SUBID10035</td><td>28542</td><td>1973-03-25</td><td>35</td><td>claims of value</td><td>Measles</td><td>150189</td></tr><tr><td>NA</td><td>SUBID1036</td><td>62985</td><td>1948-09-27</td><td>36</td><td>claims of policy</td><td>Heart Attack</td><td>138861</td></tr><tr><td>NA</td><td>SUBID1037</td><td>19596</td><td>1972-10-11</td><td>37</td><td>claims of policy</td><td>Phenylketonuria</td><td>146555</td></tr><tr><td>Y</td><td>SUBID1038</td><td>25171</td><td>1979-03-11</td><td>38</td><td>claims of fact</td><td>Phenylketonuria</td><td>199114</td></tr><tr><td>NA</td><td>SUBID10039</td><td>108526</td><td>1960-05-09</td><td>39</td><td>claims of fact</td><td>Head banging</td><td>105758</td></tr><tr><td>Y</td><td>SUBID10040</td><td>116937</td><td>1998-09-26</td><td>40</td><td>claims of value</td><td>Choking</td><td>109251</td></tr><tr><td>NA</td><td>SUBID1041</td><td>118452</td><td>1955-10-11</td><td>41</td><td>claims of fact</td><td>Fanconi anaemia</td><td>156223</td></tr><tr><td>NA</td><td>SUBID10042</td><td>188727</td><td>1989-10-28</td><td>42</td><td>claims of fact</td><td>Stroke</td><td>108576</td></tr><tr><td>N</td><td>SUBID1043</td><td>186502</td><td>1962-09-18</td><td>43</td><td>claims of value</td><td>Anaemia</td><td>132947</td></tr><tr><td>Y</td><td>SUBID1044</td><td>173600</td><td>1959-10-19</td><td>44</td><td>claims of policy</td><td>Diabetes</td><td>148674</td></tr><tr><td>Y</td><td>SUBID1045</td><td>160739</td><td>1952-07-29</td><td>45</td><td>claims of policy</td><td>Lymphedema</td><td>133107</td></tr><tr><td>N</td><td>SUBID10046</td><td>25957</td><td>2003-11-29</td><td>46</td><td>claims of fact</td><td>Phenylketonuria</td><td>193137</td></tr><tr><td>NA</td><td>SUBID1047</td><td>164159</td><td>1953-06-07</td><td>47</td><td>claims of value</td><td>Choking</td><td>196369</td></tr><tr><td>Y</td><td>SUBID10048</td><td>125727</td><td>1947-04-11</td><td>48</td><td>claims of value</td><td>Asthma</td><td>109342</td></tr><tr><td>NA</td><td>SUBID10049</td><td>159815</td><td>1983-06-20</td><td>49</td><td>claims of fact</td><td>Bladder cancer</td><td>121783</td></tr><tr><td>NA</td><td>SUBID10050</td><td>156557</td><td>1972-06-19</td><td>50</td><td>claims of policy</td><td>Lung cancer</td><td>197441</td></tr><tr><td>N</td><td>SUBID10051</td><td>193801</td><td>1969-02-01</td><td>51</td><td>claims of value</td><td>Colorectal cancer</td><td>194166</td></tr><tr><td>N</td><td>SUBID10052</td><td>130339</td><td>1959-07-22</td><td>52</td><td>claims of policy</td><td>Food Poisoning</td><td>110690</td></tr><tr><td>Y</td><td>SUBID10053</td><td>87588</td><td>2008-10-17</td><td>53</td><td>claims of fact</td><td>Anthrax</td><td>180709</td></tr><tr><td>NA</td><td>SUBID10054</td><td>27404</td><td>1965-01-09</td><td>54</td><td>claims of policy</td><td>Mold allergy</td><td>119268</td></tr><tr><td>Y</td><td>SUBID10055</td><td>44986</td><td>2007-06-22</td><td>55</td><td>claims of policy</td><td>Beriberi</td><td>163148</td></tr><tr><td>NA</td><td>SUBID10056</td><td>124734</td><td>1974-12-21</td><td>56</td><td>claims of fact</td><td>Malaria</td><td>118913</td></tr><tr><td>Y</td><td>SUBID10057</td><td>161497</td><td>1974-12-28</td><td>57</td><td>claims of policy</td><td>Asthma</td><td>167423</td></tr><tr><td>Y</td><td>SUBID1058</td><td>20770</td><td>1967-08-28</td><td>58</td><td>claims of policy</td><td>Fractures</td><td>141703</td></tr><tr><td>NA</td><td>SUBID10059</td><td>171729</td><td>1983-08-26</td><td>59</td><td>claims of policy</td><td>Malaria</td><td>173518</td></tr><tr><td>NA</td><td>SUBID10060</td><td>139755</td><td>2004-01-20</td><td>60</td><td>claims of policy</td><td>Anthrax</td><td>140394</td></tr><tr><td>NA</td><td>SUBID10061</td><td>74276</td><td>1991-03-16</td><td>61</td><td>claims of fact</td><td>Mold allergy</td><td>164524</td></tr><tr><td>Y</td><td>SUBID1062</td><td>71703</td><td>1945-10-24</td><td>62</td><td>claims of value</td><td>Head banging</td><td>198182</td></tr><tr><td>Y</td><td>SUBID1063</td><td>158255</td><td>2014-01-10</td><td>63</td><td>claims of policy</td><td>Drug consumption</td><td>115143</td></tr><tr><td>N</td><td>SUBID10064</td><td>154594</td><td>2015-07-08</td><td>64</td><td>claims of policy</td><td>Cholera</td><td>156364</td></tr><tr><td>Y</td><td>SUBID1065</td><td>81980</td><td>1969-05-31</td><td>65</td><td>claims of policy</td><td>Glaucoma</td><td>191132</td></tr><tr><td>N</td><td>SUBID10066</td><td>13667</td><td>1957-09-12</td><td>66</td><td>claims of fact</td><td>Hepatitis</td><td>105686</td></tr><tr><td>N</td><td>SUBID1067</td><td>109433</td><td>1944-12-25</td><td>67</td><td>claims of value</td><td>Rett Syndrome</td><td>160140</td></tr><tr><td>NA</td><td>SUBID10068</td><td>152901</td><td>1948-02-13</td><td>68</td><td>claims of policy</td><td>Diabetes</td><td>114252</td></tr><tr><td>NA</td><td>SUBID10069</td><td>99313</td><td>1994-08-25</td><td>69</td><td>claims of fact</td><td>Pet allergy</td><td>188365</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "N",
         "SUBID1000",
         "79874",
         "1949-03-14",
         0,
         "claims of value",
         "Galactosemia",
         187158
        ],
        [
         "NA",
         "SUBID10001",
         "151142",
         "1970-03-16",
         1,
         "claims of policy",
         "Bladder cancer",
         112766
        ],
        [
         "NA",
         "SUBID10002",
         "59924",
         "2008-02-03",
         2,
         "claims of value",
         "Kidney cancer",
         199252
        ],
        [
         "NA",
         "SUBID10003",
         "143120",
         "1995-02-08",
         3,
         "claims of fact",
         "Suicide",
         133424
        ],
        [
         "Y",
         "SUBID10004",
         "168634",
         "1967-05-23",
         4,
         "claims of value",
         "Food allergy",
         172579
        ],
        [
         "NA",
         "SUBID10005",
         "64840",
         "1991-10-04",
         5,
         "claims of policy",
         "Whiplash",
         171320
        ],
        [
         "N",
         "SUBID1006",
         "26800",
         "1991-03-26",
         6,
         "claims of fact",
         "Sunbathing",
         107794
        ],
        [
         "NA",
         "SUBID10007",
         "177186",
         "1946-09-05",
         7,
         "claims of value",
         "Drug consumption",
         130339
        ],
        [
         "N",
         "SUBID10008",
         "141123",
         "1966-06-20",
         8,
         "claims of fact",
         "Dengue",
         110377
        ],
        [
         "N",
         "SUBID10009",
         "88540",
         "1945-12-29",
         9,
         "claims of value",
         "Head banging",
         149367
        ],
        [
         "N",
         "SUBID1010",
         "29150",
         "1999-01-25",
         10,
         "claims of value",
         "Fanconi anaemia",
         156168
        ],
        [
         "Y",
         "SUBID10011",
         "40897",
         "1975-02-08",
         11,
         "claims of value",
         "Breast cancer",
         114241
        ],
        [
         "NA",
         "SUBID10012",
         "75983",
         "1985-02-12",
         12,
         "claims of value",
         "Anthrax",
         146382
        ],
        [
         "NA",
         "SUBID10013",
         "192340",
         "2014-07-30",
         13,
         "claims of fact",
         "Cystic fibrosis",
         132748
        ],
        [
         "N",
         "SUBID10014",
         "118628",
         "2003-12-18",
         14,
         "claims of value",
         "Galactosemia",
         167340
        ],
        [
         "Y",
         "SUBID10015",
         "100224",
         "1986-08-02",
         15,
         "claims of value",
         "Dengue",
         135184
        ],
        [
         "N",
         "SUBID10016",
         "42860",
         "1955-01-20",
         16,
         "claims of value",
         "Smallpox",
         179662
        ],
        [
         "N",
         "SUBID10017",
         "161786",
         "2017-06-01",
         17,
         "claims of policy",
         "Pollen allergy",
         184479
        ],
        [
         "NA",
         "SUBID10018",
         "66129",
         "1956-01-04",
         18,
         "claims of fact",
         "Breast cancer",
         156988
        ],
        [
         "NA",
         "SUBID10019",
         "182552",
         "1948-07-26",
         19,
         "claims of value",
         "Glaucoma",
         132870
        ],
        [
         "Y",
         "SUBID1020",
         "105982",
         "1984-04-10",
         20,
         "claims of value",
         "Pet allergy",
         148137
        ],
        [
         "NA",
         "SUBID1021",
         "55761",
         "1953-06-24",
         21,
         "claims of fact",
         "Rett Syndrome",
         113280
        ],
        [
         "Y",
         "SUBID10022",
         "34771",
         "1948-05-23",
         22,
         "claims of value",
         "Flu",
         134184
        ],
        [
         "N",
         "SUBID10023",
         "83642",
         "1945-03-15",
         23,
         "claims of value",
         "Cholera",
         122592
        ],
        [
         "NA",
         "SUBID10024",
         "49129",
         "2013-08-04",
         24,
         "claims of policy",
         "Scurvy",
         154439
        ],
        [
         "N",
         "SUBID10025",
         "36524",
         "1976-08-24",
         25,
         "claims of fact",
         "Glaucoma",
         117945
        ],
        [
         "NA",
         "SUBID10026",
         "192381",
         "1966-08-30",
         26,
         "claims of value",
         "Measles",
         189996
        ],
        [
         "N",
         "SUBID10027",
         "188520",
         "2008-08-26",
         27,
         "claims of fact",
         "Scurvy",
         146540
        ],
        [
         "N",
         "SUBID10028",
         "122806",
         "1958-08-05",
         28,
         "claims of policy",
         "Flu",
         156434
        ],
        [
         "NA",
         "SUBID10029",
         "81651",
         "2008-02-01",
         29,
         "claims of fact",
         "Pet allergy",
         197352
        ],
        [
         "NA",
         "SUBID1030",
         "19899",
         "1976-09-08",
         30,
         "claims of fact",
         "Lymphedema",
         138778
        ],
        [
         "N",
         "SUBID10031",
         "42968",
         "1976-01-25",
         31,
         "claims of fact",
         "Alcohol consumption",
         162665
        ],
        [
         "N",
         "SUBID1032",
         "191267",
         "1988-12-18",
         32,
         "claims of policy",
         "Stroke",
         197503
        ],
        [
         "NA",
         "SUBID10033",
         "161199",
         "2019-11-17",
         33,
         "claims of value",
         "Galactosemia",
         113476
        ],
        [
         "N",
         "SUBID1034",
         "26221",
         "2008-08-10",
         34,
         "claims of fact",
         "Vertigo",
         195876
        ],
        [
         "Y",
         "SUBID10035",
         "28542",
         "1973-03-25",
         35,
         "claims of value",
         "Measles",
         150189
        ],
        [
         "NA",
         "SUBID1036",
         "62985",
         "1948-09-27",
         36,
         "claims of policy",
         "Heart Attack",
         138861
        ],
        [
         "NA",
         "SUBID1037",
         "19596",
         "1972-10-11",
         37,
         "claims of policy",
         "Phenylketonuria",
         146555
        ],
        [
         "Y",
         "SUBID1038",
         "25171",
         "1979-03-11",
         38,
         "claims of fact",
         "Phenylketonuria",
         199114
        ],
        [
         "NA",
         "SUBID10039",
         "108526",
         "1960-05-09",
         39,
         "claims of fact",
         "Head banging",
         105758
        ],
        [
         "Y",
         "SUBID10040",
         "116937",
         "1998-09-26",
         40,
         "claims of value",
         "Choking",
         109251
        ],
        [
         "NA",
         "SUBID1041",
         "118452",
         "1955-10-11",
         41,
         "claims of fact",
         "Fanconi anaemia",
         156223
        ],
        [
         "NA",
         "SUBID10042",
         "188727",
         "1989-10-28",
         42,
         "claims of fact",
         "Stroke",
         108576
        ],
        [
         "N",
         "SUBID1043",
         "186502",
         "1962-09-18",
         43,
         "claims of value",
         "Anaemia",
         132947
        ],
        [
         "Y",
         "SUBID1044",
         "173600",
         "1959-10-19",
         44,
         "claims of policy",
         "Diabetes",
         148674
        ],
        [
         "Y",
         "SUBID1045",
         "160739",
         "1952-07-29",
         45,
         "claims of policy",
         "Lymphedema",
         133107
        ],
        [
         "N",
         "SUBID10046",
         "25957",
         "2003-11-29",
         46,
         "claims of fact",
         "Phenylketonuria",
         193137
        ],
        [
         "NA",
         "SUBID1047",
         "164159",
         "1953-06-07",
         47,
         "claims of value",
         "Choking",
         196369
        ],
        [
         "Y",
         "SUBID10048",
         "125727",
         "1947-04-11",
         48,
         "claims of value",
         "Asthma",
         109342
        ],
        [
         "NA",
         "SUBID10049",
         "159815",
         "1983-06-20",
         49,
         "claims of fact",
         "Bladder cancer",
         121783
        ],
        [
         "NA",
         "SUBID10050",
         "156557",
         "1972-06-19",
         50,
         "claims of policy",
         "Lung cancer",
         197441
        ],
        [
         "N",
         "SUBID10051",
         "193801",
         "1969-02-01",
         51,
         "claims of value",
         "Colorectal cancer",
         194166
        ],
        [
         "N",
         "SUBID10052",
         "130339",
         "1959-07-22",
         52,
         "claims of policy",
         "Food Poisoning",
         110690
        ],
        [
         "Y",
         "SUBID10053",
         "87588",
         "2008-10-17",
         53,
         "claims of fact",
         "Anthrax",
         180709
        ],
        [
         "NA",
         "SUBID10054",
         "27404",
         "1965-01-09",
         54,
         "claims of policy",
         "Mold allergy",
         119268
        ],
        [
         "Y",
         "SUBID10055",
         "44986",
         "2007-06-22",
         55,
         "claims of policy",
         "Beriberi",
         163148
        ],
        [
         "NA",
         "SUBID10056",
         "124734",
         "1974-12-21",
         56,
         "claims of fact",
         "Malaria",
         118913
        ],
        [
         "Y",
         "SUBID10057",
         "161497",
         "1974-12-28",
         57,
         "claims of policy",
         "Asthma",
         167423
        ],
        [
         "Y",
         "SUBID1058",
         "20770",
         "1967-08-28",
         58,
         "claims of policy",
         "Fractures",
         141703
        ],
        [
         "NA",
         "SUBID10059",
         "171729",
         "1983-08-26",
         59,
         "claims of policy",
         "Malaria",
         173518
        ],
        [
         "NA",
         "SUBID10060",
         "139755",
         "2004-01-20",
         60,
         "claims of policy",
         "Anthrax",
         140394
        ],
        [
         "NA",
         "SUBID10061",
         "74276",
         "1991-03-16",
         61,
         "claims of fact",
         "Mold allergy",
         164524
        ],
        [
         "Y",
         "SUBID1062",
         "71703",
         "1945-10-24",
         62,
         "claims of value",
         "Head banging",
         198182
        ],
        [
         "Y",
         "SUBID1063",
         "158255",
         "2014-01-10",
         63,
         "claims of policy",
         "Drug consumption",
         115143
        ],
        [
         "N",
         "SUBID10064",
         "154594",
         "2015-07-08",
         64,
         "claims of policy",
         "Cholera",
         156364
        ],
        [
         "Y",
         "SUBID1065",
         "81980",
         "1969-05-31",
         65,
         "claims of policy",
         "Glaucoma",
         191132
        ],
        [
         "N",
         "SUBID10066",
         "13667",
         "1957-09-12",
         66,
         "claims of fact",
         "Hepatitis",
         105686
        ],
        [
         "N",
         "SUBID1067",
         "109433",
         "1944-12-25",
         67,
         "claims of value",
         "Rett Syndrome",
         160140
        ],
        [
         "NA",
         "SUBID10068",
         "152901",
         "1948-02-13",
         68,
         "claims of policy",
         "Diabetes",
         114252
        ],
        [
         "NA",
         "SUBID10069",
         "99313",
         "1994-08-25",
         69,
         "claims of fact",
         "Pet allergy",
         188365
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 48
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Claim_Or_Rejected",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "SUB_ID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "claim_amount",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "claim_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "claim_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "claim_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "disease_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "patient_id",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from claims_table;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "613d8a95-d8e2-4726-937d-f5aed6b8f624",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 1\tWhich disease has a maximum number of claims.\n",
    "Disease table, claims table, joins on disease_name,\n",
    "count the number of claim_id where disease_name is same in both tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a883790d-a2a3-4140-872e-6ce3e7091dea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_dis.createOrReplaceTempView(\"disease_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43a9ea1e-d7dd-4a4d-9994-690e025fd9c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Disease_name</th><th>claim_count</th></tr></thead><tbody><tr><td>Pet allergy</td><td>3</td></tr><tr><td>Phenylketonuria</td><td>3</td></tr><tr><td>Anthrax</td><td>3</td></tr><tr><td>Galactosemia</td><td>3</td></tr><tr><td>Glaucoma</td><td>3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Pet allergy",
         3
        ],
        [
         "Phenylketonuria",
         3
        ],
        [
         "Anthrax",
         3
        ],
        [
         "Galactosemia",
         3
        ],
        [
         "Glaucoma",
         3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 73
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Disease_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "claim_count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "    SELECT\n",
    "        dt.Disease_name,\n",
    "        COUNT(ct.claim_id) AS claim_count\n",
    "    FROM\n",
    "        claims_table ct\n",
    "    JOIN\n",
    "        disease_table dt\n",
    "    ON\n",
    "        ct.disease_name = dt.Disease_name\n",
    "    GROUP BY\n",
    "        dt.Disease_name\n",
    "    ORDER BY\n",
    "        claim_count DESC\n",
    "    LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae4424a6-c0b4-43e1-b4df-5ff0a59c2067",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+\n|   Disease_name|claim_count|\n+---------------+-----------+\n|    Pet allergy|          3|\n|Phenylketonuria|          3|\n|        Anthrax|          3|\n|   Galactosemia|          3|\n|       Glaucoma|          3|\n+---------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "dis_max_cl =_sqldf\n",
    "\n",
    "dis_max_cl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f751dc88-dbf4-4683-bb3c-664503d70524",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"__S3_Access_Key__\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", \"__S3_Secret_Key__\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "232e43c9-c6b4-4256-abbd-e0828bc756dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_dmc= dis_max_cl.write.format(\"redshift\")..option(\"dbtable\", \"capstone.dis_max_cl\").option(\"url\", \"_jdbc_connector\").option(\"user\", \"UserID\").option(\"aws_iam_role\", \"-arn_key-\").option(\"tempdir\",\"s3a://sbdtestbuck/tempdir/\").option(\"password\", \"_Password _ Please_\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f07e562-6eaa-40e0-9450-dfa70ea76f31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad3194ec-ae0c-4e68-97b8-5b3aa2b9d03e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88f0a4ca-b8d5-451e-add2-6c03d593e20e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e0a49b5-cb4b-42d9-b633-54c080bd4599",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 2 Find those Subscribers having age less than 30 and they subscribe any subgroup\n",
    "Subscriber table, Birth_date (calculation and < 30) Subgrp_id\n",
    "Subgroup table, SubGrp_id\n",
    "Joins on SubGrp_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "120c0cd8-8f45-46cb-a014-82cb633cd5ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sb.createOrReplaceTempView(\"subscriber_table\")\n",
    "df_sg.createOrReplaceTempView(\"subgrp_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "262a906f-f5cb-4550-a1da-1399be310679",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>sub _id</th><th>first_name</th><th>last_name</th><th>Street</th><th>Birth_date</th><th>Gender</th><th>Phone</th><th>Country</th><th>City</th><th>Zip Code</th><th>Subgrp_id</th><th>Elig_ind</th><th>eff_date</th><th>term_date</th></tr></thead><tbody><tr><td>SUBID10000</td><td>Harbir</td><td>Vishwakarma</td><td>Baria Marg</td><td>1924-06-30</td><td>Female</td><td>+91 0112009318</td><td>India</td><td>Rourkela</td><td>767058</td><td>S107</td><td>Y</td><td>1944-06-30</td><td>1954-01-14</td></tr><tr><td>SUBID10001</td><td>Brahmdev</td><td>Sonkar</td><td>Lala Marg</td><td>1948-12-20</td><td>Female</td><td>+91 1727749552</td><td>India</td><td>Tiruvottiyur</td><td>34639</td><td>S105</td><td>Y</td><td>1968-12-20</td><td>1970-05-16</td></tr><tr><td>SUBID10002</td><td>Ujjawal</td><td>Devi</td><td>Mammen Zila</td><td>1980-04-16</td><td>Male</td><td>+91 8547451606</td><td>India</td><td>Berhampur</td><td>914455</td><td>S106</td><td>N</td><td>2000-04-16</td><td>2008-05-04</td></tr><tr><td>SUBID10003</td><td>Ballari</td><td>Mishra</td><td>Sahni Zila</td><td>1969-09-25</td><td>Female</td><td>+91 0106026841</td><td>India</td><td>Bihar Sharif</td><td>91481</td><td>S104</td><td>N</td><td>1989-09-25</td><td>1995-06-05</td></tr><tr><td>SUBID10004</td><td>Devnath</td><td>Srivastav</td><td>Magar Zila</td><td>1946-05-01</td><td>Female</td><td>+91 1868774631</td><td>India</td><td>Bidhannagar</td><td>531742</td><td>S110</td><td>N</td><td>1966-05-01</td><td>1970-12-09</td></tr><tr><td>SUBID10005</td><td>Atasi</td><td>Seth</td><td>Khatri Nagar</td><td>1967-10-02</td><td>Male</td><td>+91 9747336855</td><td>India</td><td>Amravati</td><td>229062</td><td>S104</td><td>Y</td><td>1987-10-02</td><td>1995-02-13</td></tr><tr><td>SUBID1006</td><td>Manish</td><td>Maurya</td><td>Swaminathan Chowk</td><td>1967-06-06</td><td>Male</td><td>+91 4354294043</td><td>India</td><td>Panvel</td><td>438733</td><td>S109</td><td>NA</td><td>1987-06-06</td><td>1995-03-21</td></tr><tr><td>SUBID10007</td><td>Aakar</td><td>Yadav</td><td>Swamy</td><td>1925-03-05</td><td>Female</td><td>+91 2777633911</td><td>India</td><td>Bihar Sharif</td><td>535907</td><td>S104</td><td>N</td><td>1945-03-05</td><td>1946-11-07</td></tr><tr><td>SUBID10008</td><td>Gurudas</td><td>Gupta</td><td>Sarin Nagar</td><td>1945-05-06</td><td>Male</td><td>+91 1232859381</td><td>India</td><td>Kamarhati</td><td>933226</td><td>S103</td><td>Y</td><td>1965-05-06</td><td>1970-09-16</td></tr><tr><td>SUBID10009</td><td>NA</td><td>Gupta</td><td>Thakur Circle</td><td>1925-06-12</td><td>Male</td><td>+91 1780763280</td><td>India</td><td>Bangalore</td><td>957469</td><td>S105</td><td>Y</td><td>1945-06-12</td><td>1953-08-30</td></tr><tr><td>SUBID1010</td><td>NA</td><td>Divedi</td><td>Dhillon</td><td>1976-02-03</td><td>Male</td><td>+91 5586075345</td><td>India</td><td>Rajkot</td><td>911319</td><td>S102</td><td>Y</td><td>1996-02-03</td><td>2002-01-27</td></tr><tr><td>SUBID10011</td><td>NA</td><td>Vishwakarma</td><td>Rajagopalan</td><td>1955-01-22</td><td>Female</td><td>+91 4146391938</td><td>India</td><td>Ghaziabad</td><td>337042</td><td>S106</td><td>N</td><td>1975-01-22</td><td>1978-11-02</td></tr><tr><td>SUBID10012</td><td>Dharmadaas</td><td>Tiwari</td><td>Rama</td><td>1964-04-29</td><td>Male</td><td>+91 6345482027</td><td>India</td><td>Bhalswa Jahangir Pur</td><td>430793</td><td>S103</td><td>N</td><td>1984-04-29</td><td>1988-02-07</td></tr><tr><td>SUBID10013</td><td>Brahmvir</td><td>Rai</td><td>Shah Path</td><td>1991-11-11</td><td>Male</td><td>+91 7316972612</td><td>India</td><td>Ambala</td><td>249898</td><td>S106</td><td>N</td><td>2011-11-11</td><td>2020-05-23</td></tr><tr><td>SUBID10014</td><td>NA</td><td>Srivastav</td><td>Chandra Path</td><td>1981-01-25</td><td>Female</td><td>+91 2960004518</td><td>India</td><td>Surendranagar Dudhrej</td><td>111966</td><td>S102</td><td>N</td><td>2001-01-25</td><td>2005-07-13</td></tr><tr><td>SUBID10015</td><td>Bhagvan</td><td>Srivastav</td><td>Edwin</td><td>1966-07-24</td><td>Female</td><td>+91 0297693485</td><td>India</td><td>Bhimavaram</td><td>436513</td><td>S105</td><td>Y</td><td>1986-07-24</td><td>1988-02-04</td></tr><tr><td>SUBID10016</td><td>Amritkala</td><td>Srivastav</td><td>Guha Path</td><td>1933-11-20</td><td>Female</td><td>+91 0537157280</td><td>India</td><td>Meerut</td><td>863467</td><td>S106</td><td>Y</td><td>1953-11-20</td><td>1955-07-29</td></tr><tr><td>SUBID10017</td><td>Bandhu</td><td>Seth</td><td>Varughese</td><td>1996-10-15</td><td>Male</td><td>+91 0695289163</td><td>India</td><td>Chinsurah</td><td>136713</td><td>S108</td><td>N</td><td>2016-10-15</td><td>2018-06-08</td></tr><tr><td>SUBID10018</td><td>Bhagavaana</td><td>Kumar</td><td>Kulkarni Zila</td><td>1935-09-16</td><td>Female</td><td>+91 6071745855</td><td>India</td><td>Shahjahanpur</td><td>597276</td><td>S101</td><td>N</td><td>1955-09-16</td><td>1958-05-31</td></tr><tr><td>SUBID10019</td><td>NA</td><td>Maurya</td><td>Sharaf Nagar</td><td>1924-11-09</td><td>Female</td><td>+91 8906694405</td><td>India</td><td>Jabalpur</td><td>958538</td><td>S104</td><td>N</td><td>1944-11-09</td><td>1951-10-14</td></tr><tr><td>SUBID1020</td><td>Umang</td><td>Srivastav</td><td>Balay Chowk</td><td>1963-07-14</td><td>Female</td><td>+91 9485838770</td><td>India</td><td>Haridwar</td><td>181692</td><td>S109</td><td>Y</td><td>1983-07-14</td><td>1986-01-15</td></tr><tr><td>SUBID1021</td><td>Darsana</td><td>Yadav</td><td>Upadhyay Zila</td><td>1932-05-29</td><td>Male</td><td>+91 7676311811</td><td>India</td><td>Dibrugarh</td><td>187414</td><td>S109</td><td>Y</td><td>1952-05-29</td><td>1953-10-14</td></tr><tr><td>SUBID10022</td><td>Prakash</td><td>Rao</td><td>Sachar</td><td>1923-09-15</td><td>Female</td><td>+91 9268324471</td><td>India</td><td>Kottayam</td><td>180680</td><td>NA</td><td>N</td><td>1943-09-15</td><td>1948-10-19</td></tr><tr><td>SUBID10023</td><td>Vaijayanti</td><td>Pratap</td><td>Khalsa Nagar</td><td>1920-11-13</td><td>Male</td><td>+91 9358851649</td><td>India</td><td>Mira-Bhayandar</td><td>419190</td><td>S102</td><td>Y</td><td>1940-11-13</td><td>1946-03-10</td></tr><tr><td>SUBID10024</td><td>Menakshi</td><td>Seth</td><td>Wable Street</td><td>1987-03-06</td><td>Male</td><td>+91 0531676556</td><td>India</td><td>Kamarhati</td><td>882577</td><td>S107</td><td>N</td><td>2007-03-06</td><td>2014-02-25</td></tr><tr><td>SUBID10025</td><td>NA</td><td>Tiwari</td><td>Sha Chowk</td><td>1955-12-24</td><td>Male</td><td>+91 2416747182</td><td>India</td><td>Karimnagar</td><td>567762</td><td>S106</td><td>N</td><td>1975-12-24</td><td>1983-02-03</td></tr><tr><td>SUBID10026</td><td>Ekant</td><td>Sonkar</td><td>Walla Road</td><td>1943-08-13</td><td>Male</td><td>+91 7686951174</td><td>India</td><td>Berhampore</td><td>948589</td><td>S110</td><td>Y</td><td>1963-08-13</td><td>1967-05-29</td></tr><tr><td>SUBID10027</td><td>Chancharik</td><td>Pandey</td><td>Karan Ganj</td><td>1983-09-05</td><td>Male</td><td>+91 5309364825</td><td>India</td><td>Chapra</td><td>154667</td><td>S109</td><td>N</td><td>2003-09-05</td><td>2011-06-12</td></tr><tr><td>SUBID10028</td><td>Pushti</td><td>Pandit</td><td>Deol Path</td><td>1935-10-15</td><td>Female</td><td>+91 7093722203</td><td>India</td><td>Morbi</td><td>284168</td><td>S106</td><td>N</td><td>1955-10-15</td><td>1959-06-04</td></tr><tr><td>SUBID10029</td><td>Swati</td><td>Seth</td><td>Kant Marg</td><td>1987-12-11</td><td>Female</td><td>+91 1028477510</td><td>India</td><td>Amravati</td><td>932221</td><td>S102</td><td>N</td><td>2007-12-11</td><td>2011-10-17</td></tr><tr><td>SUBID1030</td><td>Upasana</td><td>Pandey</td><td>Seth Chowk</td><td>1956-06-01</td><td>Male</td><td>+91 0548234943</td><td>India</td><td>Hyderabad</td><td>234823</td><td>S102</td><td>N</td><td>1976-06-01</td><td>1981-02-14</td></tr><tr><td>SUBID10031</td><td>Kanhaiya</td><td>Lal</td><td>Savant Nagar</td><td>1954-10-19</td><td>Female</td><td>+91 0788738026</td><td>India</td><td>Mysore</td><td>638433</td><td>S104</td><td>Y</td><td>1974-10-19</td><td>1977-01-03</td></tr><tr><td>SUBID1032</td><td>NA</td><td>Seth</td><td>Sandhu Chowk</td><td>1968-07-02</td><td>Female</td><td>+91 2599794460</td><td>India</td><td>Gwalior</td><td>611826</td><td>S110</td><td>N</td><td>1988-07-02</td><td>1991-03-14</td></tr><tr><td>SUBID10033</td><td>Gensho</td><td>Srivastav</td><td>Korpal Ganj</td><td>1992-06-06</td><td>Male</td><td>+91 4834040556</td><td>India</td><td>Ludhiana</td><td>835018</td><td>S101</td><td>N</td><td>2012-06-06</td><td>2022-01-09</td></tr><tr><td>SUBID1034</td><td>Gopal</td><td>Das</td><td>Saini</td><td>1986-05-14</td><td>Male</td><td>+91 1181471524</td><td>India</td><td>Raebareli</td><td>176221</td><td>S101</td><td>N</td><td>2006-05-14</td><td>2011-04-08</td></tr><tr><td>SUBID10035</td><td>Dheeman</td><td>Tiwari</td><td>Dube Marg</td><td>1945-05-04</td><td>Male</td><td>+91 8239321466</td><td>India</td><td>Mysore</td><td>811970</td><td>S101</td><td>Y</td><td>1965-05-04</td><td>1973-11-13</td></tr><tr><td>SUBID1036</td><td>Upasana</td><td>Thakur</td><td>Vasa Ganj</td><td>1927-10-03</td><td>Female</td><td>NA</td><td>India</td><td>Ratlam</td><td>326733</td><td>S108</td><td>N</td><td>1947-10-03</td><td>1951-02-20</td></tr><tr><td>SUBID1037</td><td>NA</td><td>Rajput</td><td>Shere Chowk</td><td>1948-11-10</td><td>Male</td><td>+91 8390195092</td><td>India</td><td>Vadodara</td><td>877443</td><td>S101</td><td>Y</td><td>1968-11-10</td><td>1973-12-25</td></tr><tr><td>SUBID1038</td><td>NA</td><td>Thakur</td><td>Rastogi Street</td><td>1955-04-07</td><td>Female</td><td>+91 7434031446</td><td>India</td><td>Vijayawada</td><td>438940</td><td>S104</td><td>NA</td><td>1975-04-07</td><td>1982-01-25</td></tr><tr><td>SUBID10039</td><td>Madhubala</td><td>Yadav</td><td>Sangha Marg</td><td>1937-01-11</td><td>Male</td><td>+91 8498685882</td><td>India</td><td>Jaunpur</td><td>624102</td><td>S104</td><td>Y</td><td>1957-01-11</td><td>1965-10-09</td></tr><tr><td>SUBID10040</td><td>Anjushree</td><td>Pandey</td><td>Vora Ganj</td><td>1976-07-04</td><td>Male</td><td>+91 5322869455</td><td>India</td><td>Ghaziabad</td><td>782221</td><td>S105</td><td>N</td><td>1996-07-04</td><td>1999-02-17</td></tr><tr><td>SUBID1041</td><td>NA</td><td>Rajput</td><td>Sinha Path</td><td>1930-11-25</td><td>Female</td><td>NA</td><td>India</td><td>Agartala</td><td>303503</td><td>S110</td><td>Y</td><td>1950-11-25</td><td>1957-09-14</td></tr><tr><td>SUBID10042</td><td>Chakrika</td><td>Sonkar</td><td>Bansal Circle</td><td>1964-08-05</td><td>Male</td><td>+91 8185162879</td><td>India</td><td>Ranchi</td><td>503290</td><td>S108</td><td>Y</td><td>1984-08-05</td><td>1992-09-09</td></tr><tr><td>SUBID1043</td><td>Saroj</td><td>Pandit</td><td>Sathe Zila</td><td>1942-08-26</td><td>Female</td><td>+91 5690408243</td><td>India</td><td>Muzaffarpur</td><td>130486</td><td>S103</td><td>Y</td><td>1962-08-26</td><td>1964-08-29</td></tr><tr><td>SUBID1044</td><td>Ayushmati</td><td>Vishwakarma</td><td>Balakrishnan Street</td><td>1932-09-20</td><td>Male</td><td>+91 3683223970</td><td>India</td><td>Satna</td><td>131247</td><td>S108</td><td>N</td><td>1952-09-20</td><td>1961-01-24</td></tr><tr><td>SUBID1045</td><td>Drashti</td><td>Divedi</td><td>Wadhwa</td><td>1926-07-03</td><td>Male</td><td>+91 9447269993</td><td>India</td><td>Saharsa</td><td>581568</td><td>S104</td><td>Y</td><td>1946-07-03</td><td>1952-11-27</td></tr><tr><td>SUBID10046</td><td>Aayushmaan</td><td>Maurya</td><td>Johal Nagar</td><td>1983-11-14</td><td>Female</td><td>+91 4464709769</td><td>India</td><td>Mehsana</td><td>987281</td><td>S104</td><td>Y</td><td>2003-11-14</td><td>2012-10-22</td></tr><tr><td>SUBID1047</td><td>NA</td><td>Rai</td><td>Sagar Chowk</td><td>1931-02-04</td><td>Male</td><td>+91 2973105946</td><td>India</td><td>Shivpuri</td><td>794170</td><td>S109</td><td>Y</td><td>1951-02-04</td><td>1955-07-14</td></tr><tr><td>SUBID10048</td><td>Chitranjan</td><td>Mishra</td><td>Madan Nagar</td><td>1925-09-09</td><td>Female</td><td>+91 5176024720</td><td>India</td><td>Morbi</td><td>945697</td><td>S108</td><td>N</td><td>1945-09-09</td><td>1952-06-21</td></tr><tr><td>SUBID10049</td><td>Paridhi</td><td>Yadav</td><td>Sant Path</td><td>1959-03-27</td><td>Female</td><td>+91 2139280879</td><td>India</td><td>Jabalpur</td><td>883754</td><td>NA</td><td>N</td><td>1979-03-27</td><td>1985-06-01</td></tr><tr><td>SUBID10050</td><td>Deependu</td><td>Gupta</td><td>Banik Ganj</td><td>1952-02-13</td><td>Female</td><td>+91 5674176644</td><td>India</td><td>Bareilly</td><td>417855</td><td>S102</td><td>Y</td><td>1972-02-13</td><td>1976-08-23</td></tr><tr><td>SUBID10051</td><td>NA</td><td>Rajput</td><td>Chauhan Chowk</td><td>1946-10-17</td><td>Male</td><td>+91 9887324437</td><td>India</td><td>Baranagar</td><td>765234</td><td>S103</td><td>Y</td><td>1966-10-17</td><td>1969-06-26</td></tr><tr><td>SUBID10052</td><td>Laksman</td><td>Rao</td><td>Sood Marg</td><td>1939-05-26</td><td>Female</td><td>+91 4504120828</td><td>India</td><td>Ahmednagar</td><td>117923</td><td>S101</td><td>Y</td><td>1959-05-26</td><td>1960-11-07</td></tr><tr><td>SUBID10053</td><td>NA</td><td>Sonkar</td><td>Shetty Marg</td><td>1988-06-27</td><td>Male</td><td>+91 6877897646</td><td>India</td><td>Pali</td><td>383290</td><td>S102</td><td>Y</td><td>2008-06-27</td><td>2016-10-30</td></tr><tr><td>SUBID10054</td><td>Shivakari</td><td>Pratap</td><td>Dugar Road</td><td>1944-11-02</td><td>Female</td><td>+91 3740484063</td><td>India</td><td>Hapur</td><td>28202</td><td>S104</td><td>N</td><td>1964-11-02</td><td>1967-06-15</td></tr><tr><td>SUBID10055</td><td>Madhu</td><td>Thakur</td><td>Sule Marg</td><td>1984-10-23</td><td>Male</td><td>+91 8367885507</td><td>India</td><td>Udaipur</td><td>565423</td><td>S107</td><td>N</td><td>2004-10-23</td><td>2008-07-10</td></tr><tr><td>SUBID10056</td><td>Chanak</td><td>Gupta</td><td>Shetty Nagar</td><td>1954-08-27</td><td>Male</td><td>+91 5093121123</td><td>India</td><td>Jalandhar</td><td>602989</td><td>S105</td><td>N</td><td>1974-08-27</td><td>1982-06-15</td></tr><tr><td>SUBID10057</td><td>Chittesh</td><td>Pandey</td><td>Mangal Chowk</td><td>1949-10-17</td><td>Male</td><td>+91 1378163498</td><td>India</td><td>Thoothukudi</td><td>666415</td><td>S109</td><td>Y</td><td>1969-10-17</td><td>1975-10-08</td></tr><tr><td>SUBID1058</td><td>Nawal</td><td>Rajput</td><td>Deol Nagar</td><td>1940-01-22</td><td>Male</td><td>+91 1885105576</td><td>India</td><td>Bhopal</td><td>791168</td><td>S106</td><td>N</td><td>1960-01-22</td><td>1969-04-18</td></tr><tr><td>SUBID10059</td><td>Gajabahu</td><td>Singh</td><td>Kara</td><td>1959-03-15</td><td>Male</td><td>+91 1207869436</td><td>India</td><td>Udupi</td><td>637221</td><td>S101</td><td>Y</td><td>1979-03-15</td><td>1986-07-05</td></tr><tr><td>SUBID10060</td><td>Jitesh</td><td>Vishwakarma</td><td>Gopal Path</td><td>1983-02-03</td><td>Male</td><td>+91 6515468035</td><td>India</td><td>Karimnagar</td><td>124564</td><td>S110</td><td>Y</td><td>2003-02-03</td><td>2008-04-30</td></tr><tr><td>SUBID10061</td><td>NA</td><td>Rajput</td><td>Anand Path</td><td>1966-09-25</td><td>Female</td><td>+91 6477918745</td><td>India</td><td>Kharagpur</td><td>934938</td><td>S103</td><td>NA</td><td>1986-09-25</td><td>1991-06-03</td></tr><tr><td>SUBID1062</td><td>Lalit</td><td>Mishra</td><td>Comar Street</td><td>1924-02-15</td><td>Female</td><td>+91 4647833992</td><td>India</td><td>Tinsukia</td><td>963770</td><td>S103</td><td>N</td><td>1944-02-15</td><td>1947-09-28</td></tr><tr><td>SUBID1063</td><td>Anshuk</td><td>Srivastav</td><td>Sridhar Path</td><td>1991-06-17</td><td>Male</td><td>+91 9764690642</td><td>India</td><td>Uluberia</td><td>270985</td><td>S105</td><td>N</td><td>2011-06-17</td><td>2014-07-11</td></tr><tr><td>SUBID10064</td><td>NA</td><td>Pandey</td><td>Mangat Path</td><td>1994-01-13</td><td>Male</td><td>+91 8444537013</td><td>India</td><td>Panihati</td><td>643791</td><td>S110</td><td>N</td><td>2014-01-13</td><td>2019-02-24</td></tr><tr><td>SUBID1065</td><td>Dipesh</td><td>Mishra</td><td>Char Path</td><td>1949-04-01</td><td>Female</td><td>+91 5851958964</td><td>India</td><td>Kochi</td><td>31269</td><td>S103</td><td>Y</td><td>1969-04-01</td><td>1970-06-02</td></tr><tr><td>SUBID10066</td><td>NA</td><td>Seth</td><td>Chaudhuri Marg</td><td>1930-09-01</td><td>Male</td><td>+91 7061843400</td><td>India</td><td>Kolhapur</td><td>597470</td><td>S102</td><td>N</td><td>1950-09-01</td><td>1957-12-01</td></tr><tr><td>SUBID1067</td><td>Kishan</td><td>Rao</td><td>Badal Nagar</td><td>1923-05-12</td><td>Male</td><td>+91 9067652693</td><td>India</td><td>Srikakulam</td><td>703899</td><td>S110</td><td>Y</td><td>1943-05-12</td><td>1946-09-20</td></tr><tr><td>SUBID10068</td><td>NA</td><td>Mishra</td><td>Bath Nagar</td><td>1927-02-26</td><td>Female</td><td>+91 4984346995</td><td>India</td><td>Ambarnath</td><td>766224</td><td>S110</td><td>N</td><td>1947-02-26</td><td>1948-03-30</td></tr><tr><td>SUBID10069</td><td>Bhageeratha</td><td>Srivastav</td><td>Das Ganj</td><td>1973-03-21</td><td>Male</td><td>+91 0590662722</td><td>India</td><td>Sonipat</td><td>695316</td><td>S103</td><td>Y</td><td>1993-03-21</td><td>1997-08-01</td></tr><tr><td>SUBID10070</td><td>Balaaditya</td><td>Gupta</td><td>Varty Road</td><td>1923-11-02</td><td>Male</td><td>+91 3871269153</td><td>India</td><td>Hajipur</td><td>3526</td><td>S109</td><td>N</td><td>1943-11-02</td><td>1952-09-24</td></tr><tr><td>SUBID10071</td><td>NA</td><td>Rai</td><td>Choudhury Chowk</td><td>1941-12-26</td><td>Female</td><td>+91 9287216619</td><td>India</td><td>Vellore</td><td>239532</td><td>S101</td><td>N</td><td>1961-12-26</td><td>1969-02-23</td></tr><tr><td>SUBID10072</td><td>Gopal</td><td>Srivastav</td><td>Desai Street</td><td>1936-03-11</td><td>Female</td><td>+91 3791210190</td><td>India</td><td>Bidhannagar</td><td>761800</td><td>S103</td><td>Y</td><td>1956-03-11</td><td>1964-07-28</td></tr><tr><td>SUBID1073</td><td>Virender</td><td>Maurrya</td><td>Chakrabarti</td><td>1936-10-27</td><td>Male</td><td>+91 7734026802</td><td>India</td><td>Bhusawal</td><td>374302</td><td>S104</td><td>N</td><td>1956-10-27</td><td>1961-04-27</td></tr><tr><td>SUBID10074</td><td>NA</td><td>Singh</td><td>Kalla Path</td><td>1963-11-21</td><td>Male</td><td>+91 7881749363</td><td>India</td><td>Bokaro</td><td>866319</td><td>S105</td><td>Y</td><td>1983-11-21</td><td>1985-09-29</td></tr><tr><td>SUBID10075</td><td>NA</td><td>Singh</td><td>Iyengar Nagar</td><td>1956-01-29</td><td>Male</td><td>+91 6891482136</td><td>India</td><td>Navi Mumbai</td><td>836175</td><td>S107</td><td>N</td><td>1976-01-29</td><td>1979-05-25</td></tr><tr><td>SUBID10076</td><td>Mamta</td><td>Tiwari</td><td>Batra</td><td>1964-12-21</td><td>Female</td><td>+91 5559521919</td><td>India</td><td>Secunderabad</td><td>123181</td><td>S104</td><td>N</td><td>1984-12-21</td><td>1987-01-08</td></tr><tr><td>SUBID10077</td><td>Girija</td><td>Maurrya</td><td>Iyengar Road</td><td>1933-04-25</td><td>Male</td><td>+91 1811765039</td><td>India</td><td>Jaipur</td><td>204379</td><td>S105</td><td>N</td><td>1953-04-25</td><td>1963-04-18</td></tr><tr><td>SUBID10078</td><td>Aaraadhana</td><td>Rao</td><td>Raval Nagar</td><td>1980-02-07</td><td>Male</td><td>+91 2432610572</td><td>India</td><td>Jhansi</td><td>429941</td><td>S108</td><td>N</td><td>2000-02-07</td><td>2005-02-06</td></tr><tr><td>SUBID10079</td><td>Shahnawaz</td><td>Mishra</td><td>Agate Path</td><td>1971-06-24</td><td>Female</td><td>+91 4117017589</td><td>India</td><td>Rampur</td><td>528893</td><td>S102</td><td>Y</td><td>1991-06-24</td><td>2000-09-13</td></tr><tr><td>SUBID10080</td><td>Tej</td><td>Sonkar</td><td>Sarraf Chowk</td><td>1942-06-11</td><td>Male</td><td>+91 3450311029</td><td>India</td><td>Haridwar</td><td>506221</td><td>S105</td><td>Y</td><td>1962-06-11</td><td>1964-10-14</td></tr><tr><td>SUBID10081</td><td>Mansi</td><td>Divedi</td><td>Bhattacharyya Road</td><td>1947-03-20</td><td>Female</td><td>+91 1135113927</td><td>India</td><td>Hosur</td><td>995152</td><td>S105</td><td>Y</td><td>1967-03-20</td><td>1971-07-25</td></tr><tr><td>SUBID10082</td><td>Girika</td><td>Thakur</td><td>Sinha Zila</td><td>1968-11-03</td><td>Female</td><td>+91 5601148700</td><td>India</td><td>Hospet</td><td>683614</td><td>S102</td><td>N</td><td>1988-11-03</td><td>1992-01-21</td></tr><tr><td>SUBID10083</td><td>Bhilangana</td><td>Pandit</td><td>Ramachandran Path</td><td>1995-01-04</td><td>Female</td><td>+91 6653069630</td><td>India</td><td>Fatehpur</td><td>359466</td><td>S109</td><td>Y</td><td>2015-01-04</td><td>2017-10-05</td></tr><tr><td>SUBID10084</td><td>NA</td><td>Thakur</td><td>Raval Zila</td><td>1924-06-07</td><td>Female</td><td>+91 7367059254</td><td>India</td><td>Bhavnagar</td><td>464111</td><td>S107</td><td>Y</td><td>1944-06-07</td><td>1952-05-22</td></tr><tr><td>SUBID10085</td><td>Sukanya</td><td>Sonkar</td><td>Sangha Street</td><td>1942-01-16</td><td>Female</td><td>+91 5689645499</td><td>India</td><td>Vijayanagaram</td><td>226215</td><td>S101</td><td>N</td><td>1962-01-16</td><td>1967-04-10</td></tr><tr><td>SUBID1086</td><td>Banita</td><td>Rao</td><td>Thakur</td><td>1979-01-28</td><td>Male</td><td>+91 4743834161</td><td>India</td><td>Ghaziabad</td><td>907613</td><td>S109</td><td>N</td><td>1999-01-28</td><td>2000-09-05</td></tr><tr><td>SUBID1087</td><td>NA</td><td>Pandit</td><td>Srivastava Path</td><td>1924-12-10</td><td>Female</td><td>+91 9158965227</td><td>India</td><td>Sambhal</td><td>279219</td><td>S103</td><td>N</td><td>1944-12-10</td><td>1951-07-16</td></tr><tr><td>SUBID10088</td><td>NA</td><td>Rajput</td><td>Dua Zila</td><td>1922-07-30</td><td>Female</td><td>+91 9523946101</td><td>India</td><td>Tadipatri</td><td>743449</td><td>S110</td><td>N</td><td>1942-07-30</td><td>1949-06-07</td></tr><tr><td>SUBID10089</td><td>Dhuha</td><td>Tiwari</td><td>Aggarwal Street</td><td>1952-08-21</td><td>Male</td><td>+91 3188519840</td><td>India</td><td>Rampur</td><td>492137</td><td>S104</td><td>NA</td><td>1972-08-21</td><td>1981-05-13</td></tr><tr><td>SUBID10090</td><td>NA</td><td>Mishra</td><td>Chandran Nagar</td><td>1938-06-07</td><td>Female</td><td>+91 6869721169</td><td>India</td><td>Sikar</td><td>564747</td><td>S101</td><td>Y</td><td>1958-06-07</td><td>1967-08-23</td></tr><tr><td>SUBID1091</td><td>NA</td><td>Thakur</td><td>Bala</td><td>1930-12-31</td><td>Male</td><td>+91 9664169480</td><td>India</td><td>Kamarhati</td><td>682652</td><td>S110</td><td>Y</td><td>1950-12-31</td><td>1958-06-21</td></tr><tr><td>SUBID10092</td><td>NA</td><td>Rai</td><td>Karan Street</td><td>1940-08-22</td><td>Others</td><td>+91 7498206646</td><td>India</td><td>Ghaziabad</td><td>79586</td><td>S108</td><td>N</td><td>1960-08-22</td><td>1966-10-06</td></tr><tr><td>SUBID10093</td><td>Chandavarman</td><td>Singh</td><td>Sarkar Circle</td><td>1997-05-10</td><td>Others</td><td>+91 6559031791</td><td>India</td><td>Navi Mumbai</td><td>83240</td><td>S110</td><td>N</td><td>2017-05-10</td><td>2022-08-27</td></tr><tr><td>SUBID10094</td><td>Charanpal</td><td>Yadav</td><td>Sehgal Circle</td><td>1986-10-12</td><td>Male</td><td>+91 2196055115</td><td>India</td><td>Gurgaon</td><td>640326</td><td>S109</td><td>Y</td><td>2006-10-12</td><td>2016-05-13</td></tr><tr><td>SUBID10095</td><td>Ekaaksh</td><td>Rai</td><td>Bansal Ganj</td><td>1933-12-02</td><td>Others</td><td>NA</td><td>India</td><td>Pimpri-Chinchwad</td><td>158186</td><td>S107</td><td>N</td><td>1953-12-02</td><td>1960-07-29</td></tr><tr><td>SUBID10096</td><td>Chanak</td><td>Sonkar</td><td>Kaur</td><td>1959-04-07</td><td>Others</td><td>+91 7284540687</td><td>India</td><td>Raurkela Industrial Township</td><td>899590</td><td>S101</td><td>Y</td><td>1979-04-07</td><td>1986-03-07</td></tr><tr><td>SUBID10097</td><td>NA</td><td>Sonkar</td><td>Rana Ganj</td><td>1940-02-04</td><td>Others</td><td>+91 8908240160</td><td>India</td><td>Mira-Bhayandar</td><td>896586</td><td>S107</td><td>Y</td><td>1960-02-04</td><td>1965-01-12</td></tr><tr><td>SUBID1098</td><td>Pushkar</td><td>Kumar</td><td>Sodhi Zila</td><td>1934-10-05</td><td>Others</td><td>+91 8956368286</td><td>India</td><td>Korba</td><td>910732</td><td>S107</td><td>Y</td><td>1954-10-05</td><td>1961-04-05</td></tr><tr><td>SUBID10099</td><td>Shikha</td><td>Srivastav</td><td>Ahuja Road</td><td>1970-09-06</td><td>Others</td><td>+91 3042509956</td><td>India</td><td>Nanded</td><td>101500</td><td>S109</td><td>Y</td><td>1990-09-06</td><td>1997-11-27</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "SUBID10000",
         "Harbir",
         "Vishwakarma",
         "Baria Marg",
         "1924-06-30",
         "Female",
         "+91 0112009318",
         "India",
         "Rourkela",
         767058,
         "S107",
         "Y",
         "1944-06-30",
         "1954-01-14"
        ],
        [
         "SUBID10001",
         "Brahmdev",
         "Sonkar",
         "Lala Marg",
         "1948-12-20",
         "Female",
         "+91 1727749552",
         "India",
         "Tiruvottiyur",
         34639,
         "S105",
         "Y",
         "1968-12-20",
         "1970-05-16"
        ],
        [
         "SUBID10002",
         "Ujjawal",
         "Devi",
         "Mammen Zila",
         "1980-04-16",
         "Male",
         "+91 8547451606",
         "India",
         "Berhampur",
         914455,
         "S106",
         "N",
         "2000-04-16",
         "2008-05-04"
        ],
        [
         "SUBID10003",
         "Ballari",
         "Mishra",
         "Sahni Zila",
         "1969-09-25",
         "Female",
         "+91 0106026841",
         "India",
         "Bihar Sharif",
         91481,
         "S104",
         "N",
         "1989-09-25",
         "1995-06-05"
        ],
        [
         "SUBID10004",
         "Devnath",
         "Srivastav",
         "Magar Zila",
         "1946-05-01",
         "Female",
         "+91 1868774631",
         "India",
         "Bidhannagar",
         531742,
         "S110",
         "N",
         "1966-05-01",
         "1970-12-09"
        ],
        [
         "SUBID10005",
         "Atasi",
         "Seth",
         "Khatri Nagar",
         "1967-10-02",
         "Male",
         "+91 9747336855",
         "India",
         "Amravati",
         229062,
         "S104",
         "Y",
         "1987-10-02",
         "1995-02-13"
        ],
        [
         "SUBID1006",
         "Manish",
         "Maurya",
         "Swaminathan Chowk",
         "1967-06-06",
         "Male",
         "+91 4354294043",
         "India",
         "Panvel",
         438733,
         "S109",
         "NA",
         "1987-06-06",
         "1995-03-21"
        ],
        [
         "SUBID10007",
         "Aakar",
         "Yadav",
         "Swamy",
         "1925-03-05",
         "Female",
         "+91 2777633911",
         "India",
         "Bihar Sharif",
         535907,
         "S104",
         "N",
         "1945-03-05",
         "1946-11-07"
        ],
        [
         "SUBID10008",
         "Gurudas",
         "Gupta",
         "Sarin Nagar",
         "1945-05-06",
         "Male",
         "+91 1232859381",
         "India",
         "Kamarhati",
         933226,
         "S103",
         "Y",
         "1965-05-06",
         "1970-09-16"
        ],
        [
         "SUBID10009",
         "NA",
         "Gupta",
         "Thakur Circle",
         "1925-06-12",
         "Male",
         "+91 1780763280",
         "India",
         "Bangalore",
         957469,
         "S105",
         "Y",
         "1945-06-12",
         "1953-08-30"
        ],
        [
         "SUBID1010",
         "NA",
         "Divedi",
         "Dhillon",
         "1976-02-03",
         "Male",
         "+91 5586075345",
         "India",
         "Rajkot",
         911319,
         "S102",
         "Y",
         "1996-02-03",
         "2002-01-27"
        ],
        [
         "SUBID10011",
         "NA",
         "Vishwakarma",
         "Rajagopalan",
         "1955-01-22",
         "Female",
         "+91 4146391938",
         "India",
         "Ghaziabad",
         337042,
         "S106",
         "N",
         "1975-01-22",
         "1978-11-02"
        ],
        [
         "SUBID10012",
         "Dharmadaas",
         "Tiwari",
         "Rama",
         "1964-04-29",
         "Male",
         "+91 6345482027",
         "India",
         "Bhalswa Jahangir Pur",
         430793,
         "S103",
         "N",
         "1984-04-29",
         "1988-02-07"
        ],
        [
         "SUBID10013",
         "Brahmvir",
         "Rai",
         "Shah Path",
         "1991-11-11",
         "Male",
         "+91 7316972612",
         "India",
         "Ambala",
         249898,
         "S106",
         "N",
         "2011-11-11",
         "2020-05-23"
        ],
        [
         "SUBID10014",
         "NA",
         "Srivastav",
         "Chandra Path",
         "1981-01-25",
         "Female",
         "+91 2960004518",
         "India",
         "Surendranagar Dudhrej",
         111966,
         "S102",
         "N",
         "2001-01-25",
         "2005-07-13"
        ],
        [
         "SUBID10015",
         "Bhagvan",
         "Srivastav",
         "Edwin",
         "1966-07-24",
         "Female",
         "+91 0297693485",
         "India",
         "Bhimavaram",
         436513,
         "S105",
         "Y",
         "1986-07-24",
         "1988-02-04"
        ],
        [
         "SUBID10016",
         "Amritkala",
         "Srivastav",
         "Guha Path",
         "1933-11-20",
         "Female",
         "+91 0537157280",
         "India",
         "Meerut",
         863467,
         "S106",
         "Y",
         "1953-11-20",
         "1955-07-29"
        ],
        [
         "SUBID10017",
         "Bandhu",
         "Seth",
         "Varughese",
         "1996-10-15",
         "Male",
         "+91 0695289163",
         "India",
         "Chinsurah",
         136713,
         "S108",
         "N",
         "2016-10-15",
         "2018-06-08"
        ],
        [
         "SUBID10018",
         "Bhagavaana",
         "Kumar",
         "Kulkarni Zila",
         "1935-09-16",
         "Female",
         "+91 6071745855",
         "India",
         "Shahjahanpur",
         597276,
         "S101",
         "N",
         "1955-09-16",
         "1958-05-31"
        ],
        [
         "SUBID10019",
         "NA",
         "Maurya",
         "Sharaf Nagar",
         "1924-11-09",
         "Female",
         "+91 8906694405",
         "India",
         "Jabalpur",
         958538,
         "S104",
         "N",
         "1944-11-09",
         "1951-10-14"
        ],
        [
         "SUBID1020",
         "Umang",
         "Srivastav",
         "Balay Chowk",
         "1963-07-14",
         "Female",
         "+91 9485838770",
         "India",
         "Haridwar",
         181692,
         "S109",
         "Y",
         "1983-07-14",
         "1986-01-15"
        ],
        [
         "SUBID1021",
         "Darsana",
         "Yadav",
         "Upadhyay Zila",
         "1932-05-29",
         "Male",
         "+91 7676311811",
         "India",
         "Dibrugarh",
         187414,
         "S109",
         "Y",
         "1952-05-29",
         "1953-10-14"
        ],
        [
         "SUBID10022",
         "Prakash",
         "Rao",
         "Sachar",
         "1923-09-15",
         "Female",
         "+91 9268324471",
         "India",
         "Kottayam",
         180680,
         "NA",
         "N",
         "1943-09-15",
         "1948-10-19"
        ],
        [
         "SUBID10023",
         "Vaijayanti",
         "Pratap",
         "Khalsa Nagar",
         "1920-11-13",
         "Male",
         "+91 9358851649",
         "India",
         "Mira-Bhayandar",
         419190,
         "S102",
         "Y",
         "1940-11-13",
         "1946-03-10"
        ],
        [
         "SUBID10024",
         "Menakshi",
         "Seth",
         "Wable Street",
         "1987-03-06",
         "Male",
         "+91 0531676556",
         "India",
         "Kamarhati",
         882577,
         "S107",
         "N",
         "2007-03-06",
         "2014-02-25"
        ],
        [
         "SUBID10025",
         "NA",
         "Tiwari",
         "Sha Chowk",
         "1955-12-24",
         "Male",
         "+91 2416747182",
         "India",
         "Karimnagar",
         567762,
         "S106",
         "N",
         "1975-12-24",
         "1983-02-03"
        ],
        [
         "SUBID10026",
         "Ekant",
         "Sonkar",
         "Walla Road",
         "1943-08-13",
         "Male",
         "+91 7686951174",
         "India",
         "Berhampore",
         948589,
         "S110",
         "Y",
         "1963-08-13",
         "1967-05-29"
        ],
        [
         "SUBID10027",
         "Chancharik",
         "Pandey",
         "Karan Ganj",
         "1983-09-05",
         "Male",
         "+91 5309364825",
         "India",
         "Chapra",
         154667,
         "S109",
         "N",
         "2003-09-05",
         "2011-06-12"
        ],
        [
         "SUBID10028",
         "Pushti",
         "Pandit",
         "Deol Path",
         "1935-10-15",
         "Female",
         "+91 7093722203",
         "India",
         "Morbi",
         284168,
         "S106",
         "N",
         "1955-10-15",
         "1959-06-04"
        ],
        [
         "SUBID10029",
         "Swati",
         "Seth",
         "Kant Marg",
         "1987-12-11",
         "Female",
         "+91 1028477510",
         "India",
         "Amravati",
         932221,
         "S102",
         "N",
         "2007-12-11",
         "2011-10-17"
        ],
        [
         "SUBID1030",
         "Upasana",
         "Pandey",
         "Seth Chowk",
         "1956-06-01",
         "Male",
         "+91 0548234943",
         "India",
         "Hyderabad",
         234823,
         "S102",
         "N",
         "1976-06-01",
         "1981-02-14"
        ],
        [
         "SUBID10031",
         "Kanhaiya",
         "Lal",
         "Savant Nagar",
         "1954-10-19",
         "Female",
         "+91 0788738026",
         "India",
         "Mysore",
         638433,
         "S104",
         "Y",
         "1974-10-19",
         "1977-01-03"
        ],
        [
         "SUBID1032",
         "NA",
         "Seth",
         "Sandhu Chowk",
         "1968-07-02",
         "Female",
         "+91 2599794460",
         "India",
         "Gwalior",
         611826,
         "S110",
         "N",
         "1988-07-02",
         "1991-03-14"
        ],
        [
         "SUBID10033",
         "Gensho",
         "Srivastav",
         "Korpal Ganj",
         "1992-06-06",
         "Male",
         "+91 4834040556",
         "India",
         "Ludhiana",
         835018,
         "S101",
         "N",
         "2012-06-06",
         "2022-01-09"
        ],
        [
         "SUBID1034",
         "Gopal",
         "Das",
         "Saini",
         "1986-05-14",
         "Male",
         "+91 1181471524",
         "India",
         "Raebareli",
         176221,
         "S101",
         "N",
         "2006-05-14",
         "2011-04-08"
        ],
        [
         "SUBID10035",
         "Dheeman",
         "Tiwari",
         "Dube Marg",
         "1945-05-04",
         "Male",
         "+91 8239321466",
         "India",
         "Mysore",
         811970,
         "S101",
         "Y",
         "1965-05-04",
         "1973-11-13"
        ],
        [
         "SUBID1036",
         "Upasana",
         "Thakur",
         "Vasa Ganj",
         "1927-10-03",
         "Female",
         "NA",
         "India",
         "Ratlam",
         326733,
         "S108",
         "N",
         "1947-10-03",
         "1951-02-20"
        ],
        [
         "SUBID1037",
         "NA",
         "Rajput",
         "Shere Chowk",
         "1948-11-10",
         "Male",
         "+91 8390195092",
         "India",
         "Vadodara",
         877443,
         "S101",
         "Y",
         "1968-11-10",
         "1973-12-25"
        ],
        [
         "SUBID1038",
         "NA",
         "Thakur",
         "Rastogi Street",
         "1955-04-07",
         "Female",
         "+91 7434031446",
         "India",
         "Vijayawada",
         438940,
         "S104",
         "NA",
         "1975-04-07",
         "1982-01-25"
        ],
        [
         "SUBID10039",
         "Madhubala",
         "Yadav",
         "Sangha Marg",
         "1937-01-11",
         "Male",
         "+91 8498685882",
         "India",
         "Jaunpur",
         624102,
         "S104",
         "Y",
         "1957-01-11",
         "1965-10-09"
        ],
        [
         "SUBID10040",
         "Anjushree",
         "Pandey",
         "Vora Ganj",
         "1976-07-04",
         "Male",
         "+91 5322869455",
         "India",
         "Ghaziabad",
         782221,
         "S105",
         "N",
         "1996-07-04",
         "1999-02-17"
        ],
        [
         "SUBID1041",
         "NA",
         "Rajput",
         "Sinha Path",
         "1930-11-25",
         "Female",
         "NA",
         "India",
         "Agartala",
         303503,
         "S110",
         "Y",
         "1950-11-25",
         "1957-09-14"
        ],
        [
         "SUBID10042",
         "Chakrika",
         "Sonkar",
         "Bansal Circle",
         "1964-08-05",
         "Male",
         "+91 8185162879",
         "India",
         "Ranchi",
         503290,
         "S108",
         "Y",
         "1984-08-05",
         "1992-09-09"
        ],
        [
         "SUBID1043",
         "Saroj",
         "Pandit",
         "Sathe Zila",
         "1942-08-26",
         "Female",
         "+91 5690408243",
         "India",
         "Muzaffarpur",
         130486,
         "S103",
         "Y",
         "1962-08-26",
         "1964-08-29"
        ],
        [
         "SUBID1044",
         "Ayushmati",
         "Vishwakarma",
         "Balakrishnan Street",
         "1932-09-20",
         "Male",
         "+91 3683223970",
         "India",
         "Satna",
         131247,
         "S108",
         "N",
         "1952-09-20",
         "1961-01-24"
        ],
        [
         "SUBID1045",
         "Drashti",
         "Divedi",
         "Wadhwa",
         "1926-07-03",
         "Male",
         "+91 9447269993",
         "India",
         "Saharsa",
         581568,
         "S104",
         "Y",
         "1946-07-03",
         "1952-11-27"
        ],
        [
         "SUBID10046",
         "Aayushmaan",
         "Maurya",
         "Johal Nagar",
         "1983-11-14",
         "Female",
         "+91 4464709769",
         "India",
         "Mehsana",
         987281,
         "S104",
         "Y",
         "2003-11-14",
         "2012-10-22"
        ],
        [
         "SUBID1047",
         "NA",
         "Rai",
         "Sagar Chowk",
         "1931-02-04",
         "Male",
         "+91 2973105946",
         "India",
         "Shivpuri",
         794170,
         "S109",
         "Y",
         "1951-02-04",
         "1955-07-14"
        ],
        [
         "SUBID10048",
         "Chitranjan",
         "Mishra",
         "Madan Nagar",
         "1925-09-09",
         "Female",
         "+91 5176024720",
         "India",
         "Morbi",
         945697,
         "S108",
         "N",
         "1945-09-09",
         "1952-06-21"
        ],
        [
         "SUBID10049",
         "Paridhi",
         "Yadav",
         "Sant Path",
         "1959-03-27",
         "Female",
         "+91 2139280879",
         "India",
         "Jabalpur",
         883754,
         "NA",
         "N",
         "1979-03-27",
         "1985-06-01"
        ],
        [
         "SUBID10050",
         "Deependu",
         "Gupta",
         "Banik Ganj",
         "1952-02-13",
         "Female",
         "+91 5674176644",
         "India",
         "Bareilly",
         417855,
         "S102",
         "Y",
         "1972-02-13",
         "1976-08-23"
        ],
        [
         "SUBID10051",
         "NA",
         "Rajput",
         "Chauhan Chowk",
         "1946-10-17",
         "Male",
         "+91 9887324437",
         "India",
         "Baranagar",
         765234,
         "S103",
         "Y",
         "1966-10-17",
         "1969-06-26"
        ],
        [
         "SUBID10052",
         "Laksman",
         "Rao",
         "Sood Marg",
         "1939-05-26",
         "Female",
         "+91 4504120828",
         "India",
         "Ahmednagar",
         117923,
         "S101",
         "Y",
         "1959-05-26",
         "1960-11-07"
        ],
        [
         "SUBID10053",
         "NA",
         "Sonkar",
         "Shetty Marg",
         "1988-06-27",
         "Male",
         "+91 6877897646",
         "India",
         "Pali",
         383290,
         "S102",
         "Y",
         "2008-06-27",
         "2016-10-30"
        ],
        [
         "SUBID10054",
         "Shivakari",
         "Pratap",
         "Dugar Road",
         "1944-11-02",
         "Female",
         "+91 3740484063",
         "India",
         "Hapur",
         28202,
         "S104",
         "N",
         "1964-11-02",
         "1967-06-15"
        ],
        [
         "SUBID10055",
         "Madhu",
         "Thakur",
         "Sule Marg",
         "1984-10-23",
         "Male",
         "+91 8367885507",
         "India",
         "Udaipur",
         565423,
         "S107",
         "N",
         "2004-10-23",
         "2008-07-10"
        ],
        [
         "SUBID10056",
         "Chanak",
         "Gupta",
         "Shetty Nagar",
         "1954-08-27",
         "Male",
         "+91 5093121123",
         "India",
         "Jalandhar",
         602989,
         "S105",
         "N",
         "1974-08-27",
         "1982-06-15"
        ],
        [
         "SUBID10057",
         "Chittesh",
         "Pandey",
         "Mangal Chowk",
         "1949-10-17",
         "Male",
         "+91 1378163498",
         "India",
         "Thoothukudi",
         666415,
         "S109",
         "Y",
         "1969-10-17",
         "1975-10-08"
        ],
        [
         "SUBID1058",
         "Nawal",
         "Rajput",
         "Deol Nagar",
         "1940-01-22",
         "Male",
         "+91 1885105576",
         "India",
         "Bhopal",
         791168,
         "S106",
         "N",
         "1960-01-22",
         "1969-04-18"
        ],
        [
         "SUBID10059",
         "Gajabahu",
         "Singh",
         "Kara",
         "1959-03-15",
         "Male",
         "+91 1207869436",
         "India",
         "Udupi",
         637221,
         "S101",
         "Y",
         "1979-03-15",
         "1986-07-05"
        ],
        [
         "SUBID10060",
         "Jitesh",
         "Vishwakarma",
         "Gopal Path",
         "1983-02-03",
         "Male",
         "+91 6515468035",
         "India",
         "Karimnagar",
         124564,
         "S110",
         "Y",
         "2003-02-03",
         "2008-04-30"
        ],
        [
         "SUBID10061",
         "NA",
         "Rajput",
         "Anand Path",
         "1966-09-25",
         "Female",
         "+91 6477918745",
         "India",
         "Kharagpur",
         934938,
         "S103",
         "NA",
         "1986-09-25",
         "1991-06-03"
        ],
        [
         "SUBID1062",
         "Lalit",
         "Mishra",
         "Comar Street",
         "1924-02-15",
         "Female",
         "+91 4647833992",
         "India",
         "Tinsukia",
         963770,
         "S103",
         "N",
         "1944-02-15",
         "1947-09-28"
        ],
        [
         "SUBID1063",
         "Anshuk",
         "Srivastav",
         "Sridhar Path",
         "1991-06-17",
         "Male",
         "+91 9764690642",
         "India",
         "Uluberia",
         270985,
         "S105",
         "N",
         "2011-06-17",
         "2014-07-11"
        ],
        [
         "SUBID10064",
         "NA",
         "Pandey",
         "Mangat Path",
         "1994-01-13",
         "Male",
         "+91 8444537013",
         "India",
         "Panihati",
         643791,
         "S110",
         "N",
         "2014-01-13",
         "2019-02-24"
        ],
        [
         "SUBID1065",
         "Dipesh",
         "Mishra",
         "Char Path",
         "1949-04-01",
         "Female",
         "+91 5851958964",
         "India",
         "Kochi",
         31269,
         "S103",
         "Y",
         "1969-04-01",
         "1970-06-02"
        ],
        [
         "SUBID10066",
         "NA",
         "Seth",
         "Chaudhuri Marg",
         "1930-09-01",
         "Male",
         "+91 7061843400",
         "India",
         "Kolhapur",
         597470,
         "S102",
         "N",
         "1950-09-01",
         "1957-12-01"
        ],
        [
         "SUBID1067",
         "Kishan",
         "Rao",
         "Badal Nagar",
         "1923-05-12",
         "Male",
         "+91 9067652693",
         "India",
         "Srikakulam",
         703899,
         "S110",
         "Y",
         "1943-05-12",
         "1946-09-20"
        ],
        [
         "SUBID10068",
         "NA",
         "Mishra",
         "Bath Nagar",
         "1927-02-26",
         "Female",
         "+91 4984346995",
         "India",
         "Ambarnath",
         766224,
         "S110",
         "N",
         "1947-02-26",
         "1948-03-30"
        ],
        [
         "SUBID10069",
         "Bhageeratha",
         "Srivastav",
         "Das Ganj",
         "1973-03-21",
         "Male",
         "+91 0590662722",
         "India",
         "Sonipat",
         695316,
         "S103",
         "Y",
         "1993-03-21",
         "1997-08-01"
        ],
        [
         "SUBID10070",
         "Balaaditya",
         "Gupta",
         "Varty Road",
         "1923-11-02",
         "Male",
         "+91 3871269153",
         "India",
         "Hajipur",
         3526,
         "S109",
         "N",
         "1943-11-02",
         "1952-09-24"
        ],
        [
         "SUBID10071",
         "NA",
         "Rai",
         "Choudhury Chowk",
         "1941-12-26",
         "Female",
         "+91 9287216619",
         "India",
         "Vellore",
         239532,
         "S101",
         "N",
         "1961-12-26",
         "1969-02-23"
        ],
        [
         "SUBID10072",
         "Gopal",
         "Srivastav",
         "Desai Street",
         "1936-03-11",
         "Female",
         "+91 3791210190",
         "India",
         "Bidhannagar",
         761800,
         "S103",
         "Y",
         "1956-03-11",
         "1964-07-28"
        ],
        [
         "SUBID1073",
         "Virender",
         "Maurrya",
         "Chakrabarti",
         "1936-10-27",
         "Male",
         "+91 7734026802",
         "India",
         "Bhusawal",
         374302,
         "S104",
         "N",
         "1956-10-27",
         "1961-04-27"
        ],
        [
         "SUBID10074",
         "NA",
         "Singh",
         "Kalla Path",
         "1963-11-21",
         "Male",
         "+91 7881749363",
         "India",
         "Bokaro",
         866319,
         "S105",
         "Y",
         "1983-11-21",
         "1985-09-29"
        ],
        [
         "SUBID10075",
         "NA",
         "Singh",
         "Iyengar Nagar",
         "1956-01-29",
         "Male",
         "+91 6891482136",
         "India",
         "Navi Mumbai",
         836175,
         "S107",
         "N",
         "1976-01-29",
         "1979-05-25"
        ],
        [
         "SUBID10076",
         "Mamta",
         "Tiwari",
         "Batra",
         "1964-12-21",
         "Female",
         "+91 5559521919",
         "India",
         "Secunderabad",
         123181,
         "S104",
         "N",
         "1984-12-21",
         "1987-01-08"
        ],
        [
         "SUBID10077",
         "Girija",
         "Maurrya",
         "Iyengar Road",
         "1933-04-25",
         "Male",
         "+91 1811765039",
         "India",
         "Jaipur",
         204379,
         "S105",
         "N",
         "1953-04-25",
         "1963-04-18"
        ],
        [
         "SUBID10078",
         "Aaraadhana",
         "Rao",
         "Raval Nagar",
         "1980-02-07",
         "Male",
         "+91 2432610572",
         "India",
         "Jhansi",
         429941,
         "S108",
         "N",
         "2000-02-07",
         "2005-02-06"
        ],
        [
         "SUBID10079",
         "Shahnawaz",
         "Mishra",
         "Agate Path",
         "1971-06-24",
         "Female",
         "+91 4117017589",
         "India",
         "Rampur",
         528893,
         "S102",
         "Y",
         "1991-06-24",
         "2000-09-13"
        ],
        [
         "SUBID10080",
         "Tej",
         "Sonkar",
         "Sarraf Chowk",
         "1942-06-11",
         "Male",
         "+91 3450311029",
         "India",
         "Haridwar",
         506221,
         "S105",
         "Y",
         "1962-06-11",
         "1964-10-14"
        ],
        [
         "SUBID10081",
         "Mansi",
         "Divedi",
         "Bhattacharyya Road",
         "1947-03-20",
         "Female",
         "+91 1135113927",
         "India",
         "Hosur",
         995152,
         "S105",
         "Y",
         "1967-03-20",
         "1971-07-25"
        ],
        [
         "SUBID10082",
         "Girika",
         "Thakur",
         "Sinha Zila",
         "1968-11-03",
         "Female",
         "+91 5601148700",
         "India",
         "Hospet",
         683614,
         "S102",
         "N",
         "1988-11-03",
         "1992-01-21"
        ],
        [
         "SUBID10083",
         "Bhilangana",
         "Pandit",
         "Ramachandran Path",
         "1995-01-04",
         "Female",
         "+91 6653069630",
         "India",
         "Fatehpur",
         359466,
         "S109",
         "Y",
         "2015-01-04",
         "2017-10-05"
        ],
        [
         "SUBID10084",
         "NA",
         "Thakur",
         "Raval Zila",
         "1924-06-07",
         "Female",
         "+91 7367059254",
         "India",
         "Bhavnagar",
         464111,
         "S107",
         "Y",
         "1944-06-07",
         "1952-05-22"
        ],
        [
         "SUBID10085",
         "Sukanya",
         "Sonkar",
         "Sangha Street",
         "1942-01-16",
         "Female",
         "+91 5689645499",
         "India",
         "Vijayanagaram",
         226215,
         "S101",
         "N",
         "1962-01-16",
         "1967-04-10"
        ],
        [
         "SUBID1086",
         "Banita",
         "Rao",
         "Thakur",
         "1979-01-28",
         "Male",
         "+91 4743834161",
         "India",
         "Ghaziabad",
         907613,
         "S109",
         "N",
         "1999-01-28",
         "2000-09-05"
        ],
        [
         "SUBID1087",
         "NA",
         "Pandit",
         "Srivastava Path",
         "1924-12-10",
         "Female",
         "+91 9158965227",
         "India",
         "Sambhal",
         279219,
         "S103",
         "N",
         "1944-12-10",
         "1951-07-16"
        ],
        [
         "SUBID10088",
         "NA",
         "Rajput",
         "Dua Zila",
         "1922-07-30",
         "Female",
         "+91 9523946101",
         "India",
         "Tadipatri",
         743449,
         "S110",
         "N",
         "1942-07-30",
         "1949-06-07"
        ],
        [
         "SUBID10089",
         "Dhuha",
         "Tiwari",
         "Aggarwal Street",
         "1952-08-21",
         "Male",
         "+91 3188519840",
         "India",
         "Rampur",
         492137,
         "S104",
         "NA",
         "1972-08-21",
         "1981-05-13"
        ],
        [
         "SUBID10090",
         "NA",
         "Mishra",
         "Chandran Nagar",
         "1938-06-07",
         "Female",
         "+91 6869721169",
         "India",
         "Sikar",
         564747,
         "S101",
         "Y",
         "1958-06-07",
         "1967-08-23"
        ],
        [
         "SUBID1091",
         "NA",
         "Thakur",
         "Bala",
         "1930-12-31",
         "Male",
         "+91 9664169480",
         "India",
         "Kamarhati",
         682652,
         "S110",
         "Y",
         "1950-12-31",
         "1958-06-21"
        ],
        [
         "SUBID10092",
         "NA",
         "Rai",
         "Karan Street",
         "1940-08-22",
         "Others",
         "+91 7498206646",
         "India",
         "Ghaziabad",
         79586,
         "S108",
         "N",
         "1960-08-22",
         "1966-10-06"
        ],
        [
         "SUBID10093",
         "Chandavarman",
         "Singh",
         "Sarkar Circle",
         "1997-05-10",
         "Others",
         "+91 6559031791",
         "India",
         "Navi Mumbai",
         83240,
         "S110",
         "N",
         "2017-05-10",
         "2022-08-27"
        ],
        [
         "SUBID10094",
         "Charanpal",
         "Yadav",
         "Sehgal Circle",
         "1986-10-12",
         "Male",
         "+91 2196055115",
         "India",
         "Gurgaon",
         640326,
         "S109",
         "Y",
         "2006-10-12",
         "2016-05-13"
        ],
        [
         "SUBID10095",
         "Ekaaksh",
         "Rai",
         "Bansal Ganj",
         "1933-12-02",
         "Others",
         "NA",
         "India",
         "Pimpri-Chinchwad",
         158186,
         "S107",
         "N",
         "1953-12-02",
         "1960-07-29"
        ],
        [
         "SUBID10096",
         "Chanak",
         "Sonkar",
         "Kaur",
         "1959-04-07",
         "Others",
         "+91 7284540687",
         "India",
         "Raurkela Industrial Township",
         899590,
         "S101",
         "Y",
         "1979-04-07",
         "1986-03-07"
        ],
        [
         "SUBID10097",
         "NA",
         "Sonkar",
         "Rana Ganj",
         "1940-02-04",
         "Others",
         "+91 8908240160",
         "India",
         "Mira-Bhayandar",
         896586,
         "S107",
         "Y",
         "1960-02-04",
         "1965-01-12"
        ],
        [
         "SUBID1098",
         "Pushkar",
         "Kumar",
         "Sodhi Zila",
         "1934-10-05",
         "Others",
         "+91 8956368286",
         "India",
         "Korba",
         910732,
         "S107",
         "Y",
         "1954-10-05",
         "1961-04-05"
        ],
        [
         "SUBID10099",
         "Shikha",
         "Srivastav",
         "Ahuja Road",
         "1970-09-06",
         "Others",
         "+91 3042509956",
         "India",
         "Nanded",
         101500,
         "S109",
         "Y",
         "1990-09-06",
         "1997-11-27"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 52
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "sub _id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Street",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"yyyy-M-d\"}",
         "name": "Birth_date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Phone",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "City",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Zip Code",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Subgrp_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Elig_ind",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"yyyy-M-d\"}",
         "name": "eff_date",
         "type": "\"date\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"yyyy-M-d\"}",
         "name": "term_date",
         "type": "\"date\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from subscriber_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e185098-ea10-48de-bcdb-bdc4bfc1fdb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>SubGrp_id</th><th>SubGrp_Name</th><th>Monthly_Premium</th></tr></thead><tbody><tr><td>S101</td><td>Deficiency Diseases</td><td>3000</td></tr><tr><td>S102</td><td>Accident</td><td>1000</td></tr><tr><td>S103</td><td>Physiology</td><td>2000</td></tr><tr><td>S104</td><td>Therapy</td><td>1500</td></tr><tr><td>S105</td><td>Allergies</td><td>2300</td></tr><tr><td>S106</td><td>Self inflicted</td><td>1200</td></tr><tr><td>S107</td><td>Cancer</td><td>3200</td></tr><tr><td>S108</td><td>Infectious disease</td><td>1500</td></tr><tr><td>S109</td><td>Hereditary</td><td>2000</td></tr><tr><td>S110</td><td>Viral</td><td>1000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "S101",
         "Deficiency Diseases",
         3000
        ],
        [
         "S102",
         "Accident",
         1000
        ],
        [
         "S103",
         "Physiology",
         2000
        ],
        [
         "S104",
         "Therapy",
         1500
        ],
        [
         "S105",
         "Allergies",
         2300
        ],
        [
         "S106",
         "Self inflicted",
         1200
        ],
        [
         "S107",
         "Cancer",
         3200
        ],
        [
         "S108",
         "Infectious disease",
         1500
        ],
        [
         "S109",
         "Hereditary",
         2000
        ],
        [
         "S110",
         "Viral",
         1000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 53
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "SubGrp_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "SubGrp_Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Monthly_Premium",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from subgrp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa2490cd-7e27-46a9-809d-8feafc25945b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `s`.`sub` cannot be resolved. Did you mean one of the following? [`s`.`City`, `s`.`sub _id`, `s`.`Phone`, `s`.`Country`, `s`.`Gender`]. SQLSTATE: 42703; line 2 pos 4;\n",
       "'Project ['s.sub AS _id#1770, first_name#981, last_name#338, Birth_date#340, Subgrp_id#1039]\n",
       "+- Filter ((cast(datediff(current_date(Some(Etc/UTC)), Birth_date#340) as decimal(10,0)) / 365.25) < cast(cast(30 as decimal(2,0)) as decimal(18,6)))\n",
       "   +- Join Inner, (Subgrp_id#1039 = SubGrp_id#296)\n",
       "      :- SubqueryAlias s\n",
       "      :  +- SubqueryAlias subscriber_table\n",
       "      :     +- View (`subscriber_table`, [sub _id#336, first_name#981, last_name#338, Street#339, Birth_date#340, Gender#341, Phone#1010, Country#343, City#344, Zip Code#345, Subgrp_id#1039, Elig_ind#1068, eff_date#348, term_date#349])\n",
       "      :        +- Project [sub _id#336, first_name#981, last_name#338, Street#339, Birth_date#340, Gender#341, Phone#1010, Country#343, City#344, Zip Code#345, Subgrp_id#1039, coalesce(Elig_ind#347, cast(NA as string)) AS Elig_ind#1068, eff_date#348, term_date#349]\n",
       "      :           +- Project [sub _id#336, first_name#981, last_name#338, Street#339, Birth_date#340, Gender#341, Phone#1010, Country#343, City#344, Zip Code#345, coalesce(Subgrp_id#346, cast(NA as string)) AS Subgrp_id#1039, Elig_ind#347, eff_date#348, term_date#349]\n",
       "      :              +- Project [sub _id#336, first_name#981, last_name#338, Street#339, Birth_date#340, Gender#341, coalesce(Phone#342, cast(NA as string)) AS Phone#1010, Country#343, City#344, Zip Code#345, Subgrp_id#346, Elig_ind#347, eff_date#348, term_date#349]\n",
       "      :                 +- Project [sub _id#336, coalesce(first_name#337, cast(NA as string)) AS first_name#981, last_name#338, Street#339, Birth_date#340, Gender#341, Phone#342, Country#343, City#344, Zip Code#345, Subgrp_id#346, Elig_ind#347, eff_date#348, term_date#349]\n",
       "      :                    +- Relation [sub _id#336,first_name#337,last_name#338,Street#339,Birth_date#340,Gender#341,Phone#342,Country#343,City#344,Zip Code#345,Subgrp_id#346,Elig_ind#347,eff_date#348,term_date#349] csv\n",
       "      +- SubqueryAlias sg\n",
       "         +- SubqueryAlias subgrp_table\n",
       "            +- View (`subgrp_table`, [SubGrp_id#296, SubGrp_Name#297, Monthly_Premium#298])\n",
       "               +- Relation [SubGrp_id#296,SubGrp_Name#297,Monthly_Premium#298] csv\n",
       "\n",
       "\tat org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:328)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:158)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$8(CheckAnalysis.scala:358)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$8$adapted(CheckAnalysis.scala:343)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:259)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:258)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:258)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:258)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:343)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:343)\n",
       "\tat scala.collection.immutable.Stream.foreach(Stream.scala:533)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:343)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:239)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:259)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:239)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:221)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:340)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:209)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:176)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:176)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:340)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$2(Analyzer.scala:394)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:166)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:394)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:384)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:391)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:230)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:394)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:542)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1048)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:542)\n",
       "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:538)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1173)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:538)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:224)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:223)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:205)\n",
       "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:124)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1173)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1180)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:115)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$5(SparkSession.scala:952)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1173)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:941)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:975)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1008)\n",
       "\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:696)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:276)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:362)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:383)\n",
       "\tat scala.collection.immutable.List.map(List.scala:293)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:378)\n",
       "\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.repl(JupyterDriverLocal.scala:953)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$35(DriverLocal.scala:1097)\n",
       "\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:124)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$23(DriverLocal.scala:1080)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:87)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:87)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:1017)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:746)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:738)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:766)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:645)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:690)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:516)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:442)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:284)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `s`.`sub` cannot be resolved. Did you mean one of the following? [`s`.`City`, `s`.`sub _id`, `s`.`Phone`, `s`.`Country`, `s`.`Gender`]. SQLSTATE: 42703"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "UNRESOLVED_COLUMN.WITH_SUGGESTION",
        "sqlState": "42703",
        "startIndex": 11,
        "stopIndex": 15
       },
       "stackFrames": [
        "org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `s`.`sub` cannot be resolved. Did you mean one of the following? [`s`.`City`, `s`.`sub _id`, `s`.`Phone`, `s`.`Country`, `s`.`Gender`]. SQLSTATE: 42703; line 2 pos 4;\n'Project ['s.sub AS _id#1770, first_name#981, last_name#338, Birth_date#340, Subgrp_id#1039]\n+- Filter ((cast(datediff(current_date(Some(Etc/UTC)), Birth_date#340) as decimal(10,0)) / 365.25) < cast(cast(30 as decimal(2,0)) as decimal(18,6)))\n   +- Join Inner, (Subgrp_id#1039 = SubGrp_id#296)\n      :- SubqueryAlias s\n      :  +- SubqueryAlias subscriber_table\n      :     +- View (`subscriber_table`, [sub _id#336, first_name#981, last_name#338, Street#339, Birth_date#340, Gender#341, Phone#1010, Country#343, City#344, Zip Code#345, Subgrp_id#1039, Elig_ind#1068, eff_date#348, term_date#349])\n      :        +- Project [sub _id#336, first_name#981, last_name#338, Street#339, Birth_date#340, Gender#341, Phone#1010, Country#343, City#344, Zip Code#345, Subgrp_id#1039, coalesce(Elig_ind#347, cast(NA as string)) AS Elig_ind#1068, eff_date#348, term_date#349]\n      :           +- Project [sub _id#336, first_name#981, last_name#338, Street#339, Birth_date#340, Gender#341, Phone#1010, Country#343, City#344, Zip Code#345, coalesce(Subgrp_id#346, cast(NA as string)) AS Subgrp_id#1039, Elig_ind#347, eff_date#348, term_date#349]\n      :              +- Project [sub _id#336, first_name#981, last_name#338, Street#339, Birth_date#340, Gender#341, coalesce(Phone#342, cast(NA as string)) AS Phone#1010, Country#343, City#344, Zip Code#345, Subgrp_id#346, Elig_ind#347, eff_date#348, term_date#349]\n      :                 +- Project [sub _id#336, coalesce(first_name#337, cast(NA as string)) AS first_name#981, last_name#338, Street#339, Birth_date#340, Gender#341, Phone#342, Country#343, City#344, Zip Code#345, Subgrp_id#346, Elig_ind#347, eff_date#348, term_date#349]\n      :                    +- Relation [sub _id#336,first_name#337,last_name#338,Street#339,Birth_date#340,Gender#341,Phone#342,Country#343,City#344,Zip Code#345,Subgrp_id#346,Elig_ind#347,eff_date#348,term_date#349] csv\n      +- SubqueryAlias sg\n         +- SubqueryAlias subgrp_table\n            +- View (`subgrp_table`, [SubGrp_id#296, SubGrp_Name#297, Monthly_Premium#298])\n               +- Relation [SubGrp_id#296,SubGrp_Name#297,Monthly_Premium#298] csv\n\n\tat org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:328)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:158)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$8(CheckAnalysis.scala:358)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$8$adapted(CheckAnalysis.scala:343)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:259)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:258)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:258)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:258)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:343)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:343)\n\tat scala.collection.immutable.Stream.foreach(Stream.scala:533)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:343)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:239)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:259)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:239)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:221)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:340)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:209)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:176)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:176)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:340)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$2(Analyzer.scala:394)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:166)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:394)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:384)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:391)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:230)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:394)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:542)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1048)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:542)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:538)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1173)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:538)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:224)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:223)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:205)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:124)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1173)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1180)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1180)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:115)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$5(SparkSession.scala:952)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1173)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:941)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:975)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1008)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:696)\n\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:276)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:362)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:383)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:378)\n\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.repl(JupyterDriverLocal.scala:953)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$35(DriverLocal.scala:1097)\n\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:124)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$23(DriverLocal.scala:1080)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:87)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:87)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:1017)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:746)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:738)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:766)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:645)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:690)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:516)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:442)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:284)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    s.sub _id,\n",
    "    s.first_name,\n",
    "    s.last_name,\n",
    "    s.Birth_date,\n",
    "    s.Subgrp_id\n",
    "FROM\n",
    "    subscriber_table s\n",
    "JOIN\n",
    "    subgrp_table sg\n",
    "ON\n",
    "    s.Subgrp_id = sg.SubGrp_id\n",
    "WHERE\n",
    "    DATEDIFF(current_date(), s.Birth_date) / 365.25 < 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "608b7231-4d07-44a5-a4df-a34bbe5c5819",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+----------+---------+\n|  first_name|last_name|Birth_date|Subgrp_id|\n+------------+---------+----------+---------+\n|      Bandhu|     Seth|1996-10-15|     S108|\n|  Bhilangana|   Pandit|1995-01-04|     S109|\n|Chandavarman|    Singh|1997-05-10|     S110|\n+------------+---------+----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# Run a SQL query to find the disease with the maximum number of claims\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    s.first_name,\n",
    "    s.last_name,\n",
    "    s.Birth_date,\n",
    "    s.Subgrp_id\n",
    "FROM\n",
    "    subscriber_table s\n",
    "JOIN\n",
    "    subgrp_table sg\n",
    "ON\n",
    "    s.Subgrp_id = sg.SubGrp_id\n",
    "WHERE\n",
    "    DATEDIFF(current_date(), s.Birth_date) / 365.25 < 30\n",
    "\"\"\"\n",
    "\n",
    "result2 = spark.sql(query)\n",
    "\n",
    "# Display the result\n",
    "result2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c1264f4-ce52-4e2c-86bd-8db89c3f0b80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+-----------------+----------+------+--------------+-------+--------------------+--------+---------+--------+----------+----------+\n|    sub_id|first_name|  last_name|           Street|Birth_date|Gender|         Phone|Country|                City|Zip Code|Subgrp_id|Elig_ind|  eff_date| term_date|\n+----------+----------+-----------+-----------------+----------+------+--------------+-------+--------------------+--------+---------+--------+----------+----------+\n|SUBID10000|    Harbir|Vishwakarma|       Baria Marg|1924-06-30|Female|+91 0112009318|  India|            Rourkela|  767058|     S107|       Y|1944-06-30|1954-01-14|\n|SUBID10001|  Brahmdev|     Sonkar|        Lala Marg|1948-12-20|Female|+91 1727749552|  India|        Tiruvottiyur|   34639|     S105|       Y|1968-12-20|1970-05-16|\n|SUBID10002|   Ujjawal|       Devi|      Mammen Zila|1980-04-16|  Male|+91 8547451606|  India|           Berhampur|  914455|     S106|       N|2000-04-16|2008-05-04|\n|SUBID10003|   Ballari|     Mishra|       Sahni Zila|1969-09-25|Female|+91 0106026841|  India|        Bihar Sharif|   91481|     S104|       N|1989-09-25|1995-06-05|\n|SUBID10004|   Devnath|  Srivastav|       Magar Zila|1946-05-01|Female|+91 1868774631|  India|         Bidhannagar|  531742|     S110|       N|1966-05-01|1970-12-09|\n|SUBID10005|     Atasi|       Seth|     Khatri Nagar|1967-10-02|  Male|+91 9747336855|  India|            Amravati|  229062|     S104|       Y|1987-10-02|1995-02-13|\n| SUBID1006|    Manish|     Maurya|Swaminathan Chowk|1967-06-06|  Male|+91 4354294043|  India|              Panvel|  438733|     S109|      NA|1987-06-06|1995-03-21|\n|SUBID10007|     Aakar|      Yadav|            Swamy|1925-03-05|Female|+91 2777633911|  India|        Bihar Sharif|  535907|     S104|       N|1945-03-05|1946-11-07|\n|SUBID10008|   Gurudas|      Gupta|      Sarin Nagar|1945-05-06|  Male|+91 1232859381|  India|           Kamarhati|  933226|     S103|       Y|1965-05-06|1970-09-16|\n|SUBID10009|        NA|      Gupta|    Thakur Circle|1925-06-12|  Male|+91 1780763280|  India|           Bangalore|  957469|     S105|       Y|1945-06-12|1953-08-30|\n| SUBID1010|        NA|     Divedi|          Dhillon|1976-02-03|  Male|+91 5586075345|  India|              Rajkot|  911319|     S102|       Y|1996-02-03|2002-01-27|\n|SUBID10011|        NA|Vishwakarma|      Rajagopalan|1955-01-22|Female|+91 4146391938|  India|           Ghaziabad|  337042|     S106|       N|1975-01-22|1978-11-02|\n|SUBID10012|Dharmadaas|     Tiwari|             Rama|1964-04-29|  Male|+91 6345482027|  India|Bhalswa Jahangir Pur|  430793|     S103|       N|1984-04-29|1988-02-07|\n|SUBID10013|  Brahmvir|        Rai|        Shah Path|1991-11-11|  Male|+91 7316972612|  India|              Ambala|  249898|     S106|       N|2011-11-11|2020-05-23|\n|SUBID10014|        NA|  Srivastav|     Chandra Path|1981-01-25|Female|+91 2960004518|  India|Surendranagar Dud...|  111966|     S102|       N|2001-01-25|2005-07-13|\n|SUBID10015|   Bhagvan|  Srivastav|            Edwin|1966-07-24|Female|+91 0297693485|  India|          Bhimavaram|  436513|     S105|       Y|1986-07-24|1988-02-04|\n|SUBID10016| Amritkala|  Srivastav|        Guha Path|1933-11-20|Female|+91 0537157280|  India|              Meerut|  863467|     S106|       Y|1953-11-20|1955-07-29|\n|SUBID10017|    Bandhu|       Seth|        Varughese|1996-10-15|  Male|+91 0695289163|  India|           Chinsurah|  136713|     S108|       N|2016-10-15|2018-06-08|\n|SUBID10018|Bhagavaana|      Kumar|    Kulkarni Zila|1935-09-16|Female|+91 6071745855|  India|        Shahjahanpur|  597276|     S101|       N|1955-09-16|1958-05-31|\n|SUBID10019|        NA|     Maurya|     Sharaf Nagar|1924-11-09|Female|+91 8906694405|  India|            Jabalpur|  958538|     S104|       N|1944-11-09|1951-10-14|\n+----------+----------+-----------+-----------------+----------+------+--------------+-------+--------------------+--------+---------+--------+----------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_sb = df_sb.withColumnRenamed(\"sub _id\", \"sub_id\")\n",
    "\n",
    "df_sb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e58c4050-7431-44cf-b0da-cd34b048fc7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sb.createOrReplaceTempView(\"subscriber_table\")\n",
    "df_sg.createOrReplaceTempView(\"subgrp_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b395a7d-0599-4b27-a288-893e8f864408",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    s.sub_id,\n",
    "    s.first_name,\n",
    "    s.last_name,\n",
    "    s.Birth_date,\n",
    "    s.Subgrp_id\n",
    "FROM\n",
    "    subscriber_table s\n",
    "JOIN\n",
    "    subgrp_table sg\n",
    "ON\n",
    "    s.Subgrp_id = sg.SubGrp_id\n",
    "WHERE\n",
    "    DATEDIFF(current_date(), s.Birth_date) / 365.25 < 30\n",
    "\"\"\"\n",
    "\n",
    "result2 = spark.sql(query)\n",
    "\n",
    "# Display the resul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70b38a5f-ba56-4979-b853-653f9d010155",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+----------+---------+\n|    sub_id|  first_name|last_name|Birth_date|Subgrp_id|\n+----------+------------+---------+----------+---------+\n|SUBID10017|      Bandhu|     Seth|1996-10-15|     S108|\n|SUBID10083|  Bhilangana|   Pandit|1995-01-04|     S109|\n|SUBID10093|Chandavarman|    Singh|1997-05-10|     S110|\n+----------+------------+---------+----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "result2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fe81864-8231-4ca5-bd65-e834ef43571c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_bs= result2.write.format(\"redshift\").option(\"url\", \"_jdbc_connector\").option(\"user\", \"UserID\").option(\"aws_iam_role\", \"_Your_ARN_key-\").option(\"tempdir\",\"s3a://sbdtestbuck/tempdir/\").option(\"password\", \"_Password _ Please_\").save()\n",
    ".option(\"dbtable\", \"capstone.less_than_30_sbgrp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "201c252d-cbea-469e-b774-813784932fdd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_grp.createOrReplaceTempView(\"group_table\")\n",
    "df_gs.createOrReplaceTempView(\"grpsubgrp_table\")\n",
    "\n",
    "\n",
    "df_hp.createOrReplaceTempView(\"hospital_table\")\n",
    "df_pr.createOrReplaceTempView(\"patient_table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75d2ec32-874a-4161-80c9-1f669859587e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#3\tFind out which group has maximum subgroups.\n",
    "Grpsubgrp table, count how many times each grp_Id appears\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec47757b-bd4e-4ebc-8e36-e6edfb93ce86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n|Grp_Id|Subgroup_Count|\n+------+--------------+\n|GRP104|             2|\n|GRP147|             2|\n|GRP143|             2|\n|GRP105|             1|\n|GRP108|             1|\n+------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "query_max_subgrp = \"\"\"\n",
    "select\n",
    "    Grp_Id,\n",
    "    Count(Subgrp_id) AS Subgroup_Count\n",
    "From \n",
    "    grpsubgrp_table\n",
    "GROUP BY\n",
    "    Grp_Id\n",
    "Order BY\n",
    "    Subgroup_Count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "result_max_sbgrp = spark.sql(query_max_subgrp)\n",
    "\n",
    "result_max_sbgrp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a1b3519-cf42-404d-865f-b449ced076b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n|Grp_Id|Subgroup_Count|\n+------+--------------+\n|GRP104|             2|\n|GRP147|             2|\n|GRP143|             2|\n|GRP105|             1|\n|GRP108|             1|\n+------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "result_max_sbgrp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b2fc19f-4790-4fa4-abb3-12bd03d00d62",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#4\tFind out hospital which serve most number of patients.\n",
    "Patient_records table, hospital table. Joins on hospital_id (Hospital_id). First count the sum of Patient_id per hospital_id, then get the name ‘Hospital_name’ associated with ‘Hospital_id’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dbd4975-553d-4dcf-b493-db56f668eccb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------+\n|Hospital_id|       Hospital_name|Total_Patients|\n+-----------+--------------------+--------------+\n|      H1017|   Manipal Hospitals|             9|\n|      H1019|Apollo Hospitals ...|             8|\n|      H1001|Medanta The Medicity|             7|\n|      H1016|Jaslok Hospital a...|             6|\n|      H1009|Indraprastha Apol...|             5|\n|      H1003|PGIMER - Postgrad...|             4|\n+-----------+--------------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "hspt_max_pt = \"\"\"\n",
    "SELECT\n",
    "    h.Hospital_id,\n",
    "    h.Hospital_name,\n",
    "    COUNT(p.Patient_id) AS Total_Patients\n",
    "FROM\n",
    "    patient_table p\n",
    "JOIN\n",
    "    hospital_table h\n",
    "ON\n",
    "    p.hospital_id = h.Hospital_id\n",
    "GROUP BY\n",
    "    h.Hospital_id, h.Hospital_name\n",
    "ORDER BY\n",
    "    Total_Patients DESC\n",
    "LIMIT 6\n",
    "\"\"\"\n",
    "\n",
    "hspt_with_most_pt = spark.sql(hspt_max_pt)\n",
    "\n",
    "hspt_with_most_pt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89212a58-51c3-4ec9-97b6-050c0704910e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|Claim_Or_Rejected|    SUB_ID|claim_amount|claim_date|claim_id|      claim_type|    disease_name|patient_id|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|                N| SUBID1000|       79874|1949-03-14|       0| claims of value|    Galactosemia|    187158|\n|               NA|SUBID10001|      151142|1970-03-16|       1|claims of policy|  Bladder cancer|    112766|\n|               NA|SUBID10002|       59924|2008-02-03|       2| claims of value|   Kidney cancer|    199252|\n|               NA|SUBID10003|      143120|1995-02-08|       3|  claims of fact|         Suicide|    133424|\n|                Y|SUBID10004|      168634|1967-05-23|       4| claims of value|    Food allergy|    172579|\n|               NA|SUBID10005|       64840|1991-10-04|       5|claims of policy|        Whiplash|    171320|\n|                N| SUBID1006|       26800|1991-03-26|       6|  claims of fact|      Sunbathing|    107794|\n|               NA|SUBID10007|      177186|1946-09-05|       7| claims of value|Drug consumption|    130339|\n|                N|SUBID10008|      141123|1966-06-20|       8|  claims of fact|          Dengue|    110377|\n|                N|SUBID10009|       88540|1945-12-29|       9| claims of value|    Head banging|    149367|\n|                N| SUBID1010|       29150|1999-01-25|      10| claims of value| Fanconi anaemia|    156168|\n|                Y|SUBID10011|       40897|1975-02-08|      11| claims of value|   Breast cancer|    114241|\n|               NA|SUBID10012|       75983|1985-02-12|      12| claims of value|         Anthrax|    146382|\n|               NA|SUBID10013|      192340|2014-07-30|      13|  claims of fact| Cystic fibrosis|    132748|\n|                N|SUBID10014|      118628|2003-12-18|      14| claims of value|    Galactosemia|    167340|\n|                Y|SUBID10015|      100224|1986-08-02|      15| claims of value|          Dengue|    135184|\n|                N|SUBID10016|       42860|1955-01-20|      16| claims of value|        Smallpox|    179662|\n|                N|SUBID10017|      161786|2017-06-01|      17|claims of policy|  Pollen allergy|    184479|\n|               NA|SUBID10018|       66129|1956-01-04|      18|  claims of fact|   Breast cancer|    156988|\n|               NA|SUBID10019|      182552|1948-07-26|      19| claims of value|        Glaucoma|    132870|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_cl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15c85ba0-6eb2-4afa-8730-e9aeeea61d0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+\n|SubGrpID| Disease_ID|        Disease_name|\n+--------+-----------+--------------------+\n|    S101|     110001|            Beriberi|\n|    S101|     110002|              Scurvy|\n|    S101|     110003|              Goitre|\n|    S101|     110004|        Osteoporosis|\n|    S101|     110005|             Rickets|\n|    S101|     110006|             Anaemia|\n|    S102|     110007|           Fractures|\n|    S102|     110008|        Heart Attack|\n|    S102|     110009|               Burns|\n|    S102|     110010|             Choking|\n|    S102|     110011|              Stroke|\n|    S102|     110012|      Food Poisoning|\n|    S103|     110013|              Asthma|\n|    S103|     110014|            Glaucoma|\n|    S103|     110015|            Diabetes|\n|    S103|     110016|             Amnesia|\n|    S103|     110017|         Parasomnias|\n|    S103|     110018|Neurocognitive di...|\n|    S104|     110019|             Vertigo|\n|    S104|     110020|          Lymphedema|\n+--------+-----------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"s3://sbdtestbuck/capstone_prj/cleaned_data/disease.parquet/\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13740fdd-4552-46b6-a638-db702dacb9f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print('Hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa7adf58-8d16-4b3b-84d0-02ee22610f18",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#4\tFind out which subgroups subscribe most number of times.\n",
    "subgroup table, subscriber table. Joins on Subgrp_id. Get the subGrp_id, SubGrp_Name, and sub_id, Birth_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e36cfbcf-e4b5-4529-975d-86e2535282f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+----------+----------+------------------+\n|SubGrp_id|        SubGrp_Name|    sub_id|Birth_date|Subscription_Count|\n+---------+-------------------+----------+----------+------------------+\n|     S101|Deficiency Diseases|SUBID10096|1959-04-07|                 1|\n|     S101|Deficiency Diseases|SUBID10035|1945-05-04|                 1|\n|     S101|Deficiency Diseases|SUBID10033|1992-06-06|                 1|\n|     S101|Deficiency Diseases| SUBID1034|1986-05-14|                 1|\n|     S101|Deficiency Diseases| SUBID1037|1948-11-10|                 1|\n|     S101|Deficiency Diseases|SUBID10085|1942-01-16|                 1|\n|     S101|Deficiency Diseases|SUBID10059|1959-03-15|                 1|\n|     S101|Deficiency Diseases|SUBID10018|1935-09-16|                 1|\n|     S101|Deficiency Diseases|SUBID10090|1938-06-07|                 1|\n|     S101|Deficiency Diseases|SUBID10071|1941-12-26|                 1|\n+---------+-------------------+----------+----------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "sb_most = \"\"\"\n",
    "SELECT\n",
    "    sg.SubGrp_id,\n",
    "    sg.SubGrp_Name,\n",
    "    s.sub_id,\n",
    "    s.Birth_date,\n",
    "    COUNT(s.sub_id) AS Subscription_Count\n",
    "FROM\n",
    "    subgrp_table sg\n",
    "JOIN\n",
    "    subscriber_table s\n",
    "ON\n",
    "    sg.SubGrp_id = s.Subgrp_id\n",
    "GROUP BY\n",
    "    sg.SubGrp_id, sg.SubGrp_Name, s.sub_id, s.Birth_date\n",
    "ORDER BY\n",
    "    sg.SubGrp_id, Subscription_Count DESC\n",
    "\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df_123 = spark.sql(sb_most)\n",
    "\n",
    "df_123.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5734b6df-4214-4859-9b98-88a4b559ef17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------------------+\n|SubGrp_id|        SubGrp_Name|Subscription_Count|\n+---------+-------------------+------------------+\n|     S104|            Therapy|                13|\n|     S109|         Hereditary|                11|\n|     S110|              Viral|                11|\n|     S101|Deficiency Diseases|                11|\n|     S105|          Allergies|                10|\n|     S103|         Physiology|                10|\n|     S102|           Accident|                10|\n|     S107|             Cancer|                 8|\n|     S108| Infectious disease|                 7|\n|     S106|     Self inflicted|                 7|\n+---------+-------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "sb_most=\"\"\"\n",
    "SELECT\n",
    "    sg.SubGrp_id,\n",
    "    sg.SubGrp_Name,\n",
    "    COUNT(s.sub_id) AS Subscription_Count\n",
    "FROM\n",
    "    subgrp_table sg\n",
    "JOIN\n",
    "    subscriber_table s\n",
    "ON\n",
    "    sg.SubGrp_id = s.Subgrp_id\n",
    "GROUP BY\n",
    "    sg.SubGrp_id, sg.SubGrp_Name\n",
    "ORDER BY\n",
    "    Subscription_Count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "df123 = spark.sql(sb_most)\n",
    "\n",
    "df123.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3604359f-e20d-4215-bc03-bc8e65188339",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#6\tFind out total number of claims which were rejected\n",
    "claims table; sum of N in ‘Claim_Or_Rejected’ column.\n",
    "claims table; sum of N in ‘Claim_Or_Rejected’ column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6ed2988-075b-4e26-b3f4-18ca17469580",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Total_Rejected_Claims</th></tr></thead><tbody><tr><td>22</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         22
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 107
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Total_Rejected_Claims",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    COUNT(*) AS Total_Rejected_Claims\n",
    "FROM\n",
    "    claims_table\n",
    "WHERE\n",
    "    Claim_Or_Rejected = 'N';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa6e35ae-5ade-45fe-8663-d9d4ef117997",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n|Total_Rejected_Claims|\n+---------------------+\n|                   22|\n+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df234=\"\"\"\n",
    "SELECT\n",
    "    COUNT(*) AS Total_Rejected_Claims\n",
    "FROM\n",
    "    claims_table\n",
    "WHERE\n",
    "    Claim_Or_Rejected = 'N';\n",
    "\n",
    "\"\"\"\n",
    "df987 = spark.sql(df234)\n",
    "\n",
    "df987.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8794fe53-c474-4828-9bb0-c87b052fa840",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 7 ●\tFrom where most claims are coming (city)\n",
    "claims table, subscriber table, joins on SUB_ID(sub_id), get the unique count of city and sum how many times they appear in subscriber table. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1127ad51-153b-4e67-ba75-1f479d563755",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+---------------------------+\n|        city|Subscribers|Total_Appearances_In_Claims|\n+------------+-----------+---------------------------+\n|      Mysore|          2|                          2|\n|Bihar Sharif|          2|                          2|\n|    Amravati|          2|                          2|\n|   Kamarhati|          2|                          2|\n|    Jabalpur|          2|                          2|\n+------------+-----------+---------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df44=\"\"\"\n",
    "\n",
    "SELECT\n",
    "    s.city,\n",
    "    COUNT(s.sub_id) AS Subscribers,\n",
    "    COUNT(s.city) AS Total_Appearances_In_Claims\n",
    "FROM\n",
    "    subscriber_table s\n",
    "JOIN\n",
    "    claims_table c\n",
    "ON\n",
    "    s.sub_id = c.SUB_ID\n",
    "GROUP BY\n",
    "    s.city\n",
    "ORDER BY\n",
    "    Subscribers DESC, Total_Appearances_In_Claims\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "df45 = spark.sql(df44)\n",
    "\n",
    "df45.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "906f7898-7b6e-4c10-b930-83890fccd213",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>city</th><th>City_Appearances</th></tr></thead><tbody><tr><td>Ghaziabad</td><td>4</td></tr><tr><td>Kamarhati</td><td>3</td></tr><tr><td>Amravati</td><td>2</td></tr><tr><td>Navi Mumbai</td><td>2</td></tr><tr><td>Jabalpur</td><td>2</td></tr><tr><td>Mysore</td><td>2</td></tr><tr><td>Haridwar</td><td>2</td></tr><tr><td>Karimnagar</td><td>2</td></tr><tr><td>Bihar Sharif</td><td>2</td></tr><tr><td>Morbi</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Ghaziabad",
         4
        ],
        [
         "Kamarhati",
         3
        ],
        [
         "Amravati",
         2
        ],
        [
         "Navi Mumbai",
         2
        ],
        [
         "Jabalpur",
         2
        ],
        [
         "Mysore",
         2
        ],
        [
         "Haridwar",
         2
        ],
        [
         "Karimnagar",
         2
        ],
        [
         "Bihar Sharif",
         2
        ],
        [
         "Morbi",
         2
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 116
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "City_Appearances",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    city,\n",
    "    COUNT(*) AS City_Appearances\n",
    "FROM\n",
    "    subscriber_table\n",
    "GROUP BY\n",
    "    city\n",
    "ORDER BY\n",
    "    City_Appearances DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc35cd4b-2788-427a-9146-ffb81eb34274",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 8 Which groups of policies subscriber subscribe mostly Government or private (group type)\n",
    "Grp_ID\n",
    "group table, grpsubgrp table, joins on Grp_Id\n",
    "subscriber table, grpsubgrp table, joins on Subgrp_id (SubGrp_ID)\n",
    "find out which sub_id belongs to which SubGrp_ID map those SubGrp_ID to Grp_Id\n",
    "Map the Grp_Id to Grp_Type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94724b45-13f8-42c8-af4b-23a4379e13f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Grp_Id</th><th>Grp_Type</th><th>Unique_Subscribers</th></tr></thead><tbody><tr><td>GRP143</td><td>Private</td><td>24</td></tr><tr><td>GRP147</td><td>Private</td><td>18</td></tr><tr><td>GRP104</td><td>Private</td><td>17</td></tr><tr><td>GRP103</td><td>Private</td><td>13</td></tr><tr><td>GRP133</td><td>Private</td><td>13</td></tr><tr><td>GRP123</td><td>Private</td><td>13</td></tr><tr><td>GRP113</td><td>Private</td><td>13</td></tr><tr><td>GRP142</td><td>Private</td><td>11</td></tr><tr><td>GRP105</td><td>Private</td><td>11</td></tr><tr><td>GRP102</td><td>Private</td><td>11</td></tr><tr><td>GRP126</td><td>Private</td><td>11</td></tr><tr><td>GRP152</td><td>Private</td><td>11</td></tr><tr><td>GRP112</td><td>Private</td><td>11</td></tr><tr><td>GRP132</td><td>Private</td><td>11</td></tr><tr><td>GRP101</td><td>Govt.</td><td>11</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "GRP143",
         "Private",
         24
        ],
        [
         "GRP147",
         "Private",
         18
        ],
        [
         "GRP104",
         "Private",
         17
        ],
        [
         "GRP103",
         "Private",
         13
        ],
        [
         "GRP133",
         "Private",
         13
        ],
        [
         "GRP123",
         "Private",
         13
        ],
        [
         "GRP113",
         "Private",
         13
        ],
        [
         "GRP142",
         "Private",
         11
        ],
        [
         "GRP105",
         "Private",
         11
        ],
        [
         "GRP102",
         "Private",
         11
        ],
        [
         "GRP126",
         "Private",
         11
        ],
        [
         "GRP152",
         "Private",
         11
        ],
        [
         "GRP112",
         "Private",
         11
        ],
        [
         "GRP132",
         "Private",
         11
        ],
        [
         "GRP101",
         "Govt.",
         11
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 123
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Grp_Id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Grp_Type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Unique_Subscribers",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "WITH SubscribersWithGroups AS (\n",
    "    SELECT\n",
    "        s.sub_id,\n",
    "        gsg.SubGrp_ID,\n",
    "        gt.Grp_Id,\n",
    "        gt.Grp_Type\n",
    "    FROM\n",
    "        subscriber_table s\n",
    "    JOIN\n",
    "        grpsubgrp_table gsg\n",
    "    ON\n",
    "        s.Subgrp_id = gsg.SubGrp_ID\n",
    "    JOIN\n",
    "        group_table gt\n",
    "    ON\n",
    "        gsg.Grp_Id = gt.Grp_Id\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    Grp_Id,\n",
    "    Grp_Type,\n",
    "    COUNT(DISTINCT sub_id) AS Unique_Subscribers\n",
    "FROM\n",
    "    SubscribersWithGroups\n",
    "GROUP BY\n",
    "    Grp_Id, Grp_Type\n",
    "ORDER BY\n",
    "    Unique_Subscribers DESC\n",
    "LIMIT 15;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d436f86d-2f05-4b8a-9c09-da48addca073",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------------------+\n|Grp_Id|Grp_Type|Unique_Subscribers|\n+------+--------+------------------+\n|GRP143| Private|                24|\n|GRP147| Private|                18|\n|GRP104| Private|                17|\n|GRP123| Private|                13|\n|GRP133| Private|                13|\n|GRP103| Private|                13|\n|GRP113| Private|                13|\n|GRP105| Private|                11|\n|GRP142| Private|                11|\n|GRP102| Private|                11|\n+------+--------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df56 = \"\"\"\n",
    "WITH SubscribersWithGroups AS (\n",
    "    SELECT\n",
    "        s.sub_id,\n",
    "        gsg.SubGrp_ID,\n",
    "        gt.Grp_Id,\n",
    "        gt.Grp_Type\n",
    "    FROM\n",
    "        subscriber_table s\n",
    "    JOIN\n",
    "        grpsubgrp_table gsg\n",
    "    ON\n",
    "        s.Subgrp_id = gsg.SubGrp_ID\n",
    "    JOIN\n",
    "        group_table gt\n",
    "    ON\n",
    "        gsg.Grp_Id = gt.Grp_Id\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    Grp_Id,\n",
    "    Grp_Type,\n",
    "    COUNT(DISTINCT sub_id) AS Unique_Subscribers\n",
    "FROM\n",
    "    SubscribersWithGroups\n",
    "GROUP BY\n",
    "    Grp_Id, Grp_Type\n",
    "ORDER BY\n",
    "    Unique_Subscribers DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "df78 = spark.sql(df56)\n",
    "\n",
    "df78.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e5019c3-b3e3-43e2-b49b-15d8e7b18e99",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#9 Average monthly premium subscriber pay to insurance company.\n",
    "a.\tsubgroup table, subscriber table, joins on SubGrp_id (Subgrp_id) \n",
    "b.\tsum the count of sub_id \n",
    "c.\tdivide by the total Monthly_Premium \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb3c541e-b914-4eb6-acc8-540f325403d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Average_Monthly_Premium</th></tr></thead><tbody><tr><td>1867.3469387755101</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1867.3469387755101
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 128
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Average_Monthly_Premium",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "WITH SubscribersWithPremium AS (\n",
    "    SELECT\n",
    "        st.Subgrp_id,\n",
    "        st.sub_id,\n",
    "        sg.Monthly_Premium\n",
    "    FROM\n",
    "        subscriber_table st\n",
    "    JOIN\n",
    "        subgrp_table sg\n",
    "    ON\n",
    "        st.Subgrp_id = sg.SubGrp_id\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    AVG(Monthly_Premium) AS Average_Monthly_Premium\n",
    "FROM\n",
    "    SubscribersWithPremium;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbbb0ccb-ef0d-482e-91c3-820797fe8554",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n|Average_Monthly_Premium|\n+-----------------------+\n|     1867.3469387755101|\n+-----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "dfpr =\"\"\"\n",
    "\n",
    "WITH SubscribersWithPremium AS (\n",
    "    SELECT\n",
    "        st.Subgrp_id,\n",
    "        st.sub_id,\n",
    "        sg.Monthly_Premium\n",
    "    FROM\n",
    "        subscriber_table st\n",
    "    JOIN\n",
    "        subgrp_table sg\n",
    "    ON\n",
    "        st.Subgrp_id = sg.SubGrp_id\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    AVG(Monthly_Premium) AS Average_Monthly_Premium\n",
    "FROM\n",
    "    SubscribersWithPremium;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_pr = spark.sql(dfpr)\n",
    "\n",
    "df_pr.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e4fd659-9ed6-4e7d-a1df-0791e933ada4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#10.\tFind out Which group is most profitable\n",
    "a.\tList the SubGrp_id and then sum the Monthly_Premium related to the respective SubGrp_id.\n",
    "b.\tThe SubGrp_id paying the most Monthly_Premium is the most profitable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e258b69-433b-4953-8f62-4d1506ff9a8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>SubGrp_id</th><th>Total_Monthly_Premium</th></tr></thead><tbody><tr><td>S107</td><td>3200</td></tr><tr><td>S101</td><td>3000</td></tr><tr><td>S105</td><td>2300</td></tr><tr><td>S109</td><td>2000</td></tr><tr><td>S103</td><td>2000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "S107",
         3200
        ],
        [
         "S101",
         3000
        ],
        [
         "S105",
         2300
        ],
        [
         "S109",
         2000
        ],
        [
         "S103",
         2000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 134
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "SubGrp_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Total_Monthly_Premium",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    SubGrp_id,\n",
    "    SUM(Monthly_Premium) AS Total_Monthly_Premium\n",
    "FROM\n",
    "    subgrp_table\n",
    "GROUP BY\n",
    "    SubGrp_id\n",
    "ORDER BY\n",
    "    Total_Monthly_Premium DESC\n",
    "LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87bcdb29-22d9-4a18-aefd-07c85e6fd3f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------------+\n|SubGrp_id|Total_Monthly_Premium|\n+---------+---------------------+\n|     S107|                 3200|\n|     S101|                 3000|\n|     S105|                 2300|\n|     S109|                 2000|\n|     S103|                 2000|\n+---------+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_nb = \"\"\"\n",
    "SELECT\n",
    "    SubGrp_id,\n",
    "    SUM(Monthly_Premium) AS Total_Monthly_Premium\n",
    "FROM\n",
    "    subgrp_table\n",
    "GROUP BY\n",
    "    SubGrp_id\n",
    "ORDER BY\n",
    "    Total_Monthly_Premium DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "df235 = spark.sql(df_nb)\n",
    "df235.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80785c66-c102-4f19-8236-d3c8a005ed1a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#10\tList all the patients below age of 18 who admit for cancer.\n",
    "a.\tPatient_records table, calculate age based on birth_date ( age < 18 and disease =’cancer’)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7871ac9-f1cc-43fd-929c-6916d040f58a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Patient_id</th><th>Patient_name</th><th>patient_birth_date</th><th>disease_name</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 141
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Patient_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Patient_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"yyyy-M-d\"}",
         "name": "patient_birth_date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "disease_name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    Patient_id,\n",
    "    Patient_name,\n",
    "    patient_birth_date,\n",
    "    disease_name\n",
    "FROM\n",
    "    patient_table\n",
    "WHERE\n",
    "    DATEDIFF(current_date(), patient_birth_date) / 365.25 < 18\n",
    "    AND disease_name = 'cancer';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "111a9dc1-f8d5-4ac9-847e-dba13489e497",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Patient_id</th><th>Patient_name</th><th>patient_birth_date</th><th>disease_name</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 150
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Patient_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Patient_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"yyyy-M-d\"}",
         "name": "patient_birth_date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "disease_name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    Patient_id,\n",
    "    Patient_name,\n",
    "    patient_birth_date,\n",
    "    disease_name\n",
    "FROM\n",
    "    patient_table\n",
    "WHERE\n",
    "    YEAR(patient_birth_date) BETWEEN 2000 AND YEAR(current_date())\n",
    "    AND disease_name = 'cancer';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f9a9d89-84de-4178-9de5-0923d3fa1c96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Patient_id</th><th>Patient_name</th><th>patient_gender</th><th>patient_birth_date</th><th>patient_phone</th><th>disease_name</th><th>city</th><th>hospital_id</th></tr></thead><tbody><tr><td>187158</td><td>Harbir</td><td>Female</td><td>1924-06-30</td><td>+91 0112009318</td><td>Galactosemia</td><td>Rourkela</td><td>H1001</td></tr><tr><td>112766</td><td>Brahmdev</td><td>Female</td><td>1948-12-20</td><td>+91 1727749552</td><td>Bladder cancer</td><td>Tiruvottiyur</td><td>H1016</td></tr><tr><td>199252</td><td>Ujjawal</td><td>Male</td><td>1980-04-16</td><td>+91 8547451606</td><td>Kidney cancer</td><td>Berhampur</td><td>H1009</td></tr><tr><td>133424</td><td>Ballari</td><td>Female</td><td>1969-09-25</td><td>+91 0106026841</td><td>Suicide</td><td>Bihar Sharif</td><td>H1017</td></tr><tr><td>172579</td><td>Devnath</td><td>Female</td><td>1946-05-01</td><td>+91 1868774631</td><td>Food allergy</td><td>Bidhannagar</td><td>H1019</td></tr><tr><td>171320</td><td>Atasi</td><td>Male</td><td>1967-10-02</td><td>+91 9747336855</td><td>Whiplash</td><td>Amravati</td><td>H1013</td></tr><tr><td>107794</td><td>Manish</td><td>Male</td><td>1967-06-06</td><td>+91 4354294043</td><td>Sunbathing</td><td>Panvel</td><td>H1004</td></tr><tr><td>130339</td><td>Aakar</td><td>Female</td><td>1925-03-05</td><td>+91 2777633911</td><td>Drug consumption</td><td>Bihar Sharif</td><td>H1000</td></tr><tr><td>110377</td><td>Gurudas</td><td>Male</td><td>1945-05-06</td><td>+91 1232859381</td><td>Dengue</td><td>Kamarhati</td><td>H1001</td></tr><tr><td>149367</td><td>NA</td><td>Male</td><td>1925-06-12</td><td>+91 1780763280</td><td>Head banging</td><td>Bangalore</td><td>H1013</td></tr><tr><td>156168</td><td>NA</td><td>Male</td><td>1976-02-03</td><td>+91 5586075345</td><td>Fanconi anaemia</td><td>Rajkot</td><td>H1004</td></tr><tr><td>114241</td><td>NA</td><td>Female</td><td>1955-01-22</td><td>+91 4146391938</td><td>Breast cancer</td><td>Ghaziabad</td><td>H1015</td></tr><tr><td>146382</td><td>Dharmadaas</td><td>Male</td><td>1964-04-29</td><td>+91 6345482027</td><td>Anthrax</td><td>Bhalswa Jahangir Pur</td><td>H1019</td></tr><tr><td>132748</td><td>Brahmvir</td><td>Male</td><td>1991-11-11</td><td>+91 7316972612</td><td>Cystic fibrosis</td><td>Ambala</td><td>H1018</td></tr><tr><td>167340</td><td>NA</td><td>Female</td><td>1981-01-25</td><td>+91 2960004518</td><td>Galactosemia</td><td>Surendranagar Dudhrej</td><td>H1003</td></tr><tr><td>135184</td><td>Bhagvan</td><td>Female</td><td>1966-07-24</td><td>+91 0297693485</td><td>Dengue</td><td>Bhimavaram</td><td>H1018</td></tr><tr><td>179662</td><td>Amritkala</td><td>Female</td><td>1933-11-20</td><td>+91 0537157280</td><td>Smallpox</td><td>Meerut</td><td>H1018</td></tr><tr><td>184479</td><td>Bandhu</td><td>Male</td><td>1996-10-15</td><td>+91 0695289163</td><td>Pollen allergy</td><td>Chinsurah</td><td>H1010</td></tr><tr><td>156988</td><td>Bhagavaana</td><td>Female</td><td>1935-09-16</td><td>+91 6071745855</td><td>Breast cancer</td><td>Shahjahanpur</td><td>H1012</td></tr><tr><td>132870</td><td>NA</td><td>Female</td><td>1924-11-09</td><td>+91 8906694405</td><td>Glaucoma</td><td>Jabalpur</td><td>H1017</td></tr><tr><td>148137</td><td>Umang</td><td>Female</td><td>1963-07-14</td><td>+91 9485838770</td><td>Pet allergy</td><td>Haridwar</td><td>H1002</td></tr><tr><td>113280</td><td>Darsana</td><td>Male</td><td>1932-05-29</td><td>+91 7676311811</td><td>Rett Syndrome</td><td>Dibrugarh</td><td>H1019</td></tr><tr><td>134184</td><td>Prakash</td><td>Female</td><td>1923-09-15</td><td>+91 9268324471</td><td>Flu</td><td>Kottayam</td><td>H1001</td></tr><tr><td>122592</td><td>Vaijayanti</td><td>Male</td><td>1920-11-13</td><td>+91 9358851649</td><td>Cholera</td><td>Mira-Bhayandar</td><td>H1009</td></tr><tr><td>154439</td><td>Menakshi</td><td>Male</td><td>1987-03-06</td><td>+91 0531676556</td><td>Scurvy</td><td>Kamarhati</td><td>H1016</td></tr><tr><td>117945</td><td>NA</td><td>Male</td><td>1955-12-24</td><td>+91 2416747182</td><td>Glaucoma</td><td>Karimnagar</td><td>H1009</td></tr><tr><td>189996</td><td>Ekant</td><td>Male</td><td>1943-08-13</td><td>+91 7686951174</td><td>Measles</td><td>Berhampore</td><td>H1003</td></tr><tr><td>146540</td><td>Chancharik</td><td>Male</td><td>1983-09-05</td><td>+91 5309364825</td><td>Scurvy</td><td>Chapra</td><td>H1012</td></tr><tr><td>156434</td><td>Pushti</td><td>Female</td><td>1935-10-15</td><td>+91 7093722203</td><td>Flu</td><td>Morbi</td><td>H1019</td></tr><tr><td>197352</td><td>Swati</td><td>Female</td><td>1987-12-11</td><td>+91 1028477510</td><td>Pet allergy</td><td>Amravati</td><td>H1019</td></tr><tr><td>138778</td><td>Upasana</td><td>Male</td><td>1956-06-01</td><td>+91 0548234943</td><td>Lymphedema</td><td>Hyderabad</td><td>H1005</td></tr><tr><td>162665</td><td>Kanhaiya</td><td>Female</td><td>1954-10-19</td><td>+91 0788738026</td><td>Alcohol consumption</td><td>Mysore</td><td>H1009</td></tr><tr><td>197503</td><td>NA</td><td>Female</td><td>1968-07-02</td><td>+91 2599794460</td><td>Stroke</td><td>Gwalior</td><td>H1009</td></tr><tr><td>113476</td><td>Gensho</td><td>Male</td><td>1992-06-06</td><td>+91 4834040556</td><td>Galactosemia</td><td>Ludhiana</td><td>H1016</td></tr><tr><td>195876</td><td>Gopal</td><td>Male</td><td>1986-05-14</td><td>+91 1181471524</td><td>Vertigo</td><td>Raebareli</td><td>H1017</td></tr><tr><td>150189</td><td>Dheeman</td><td>Male</td><td>1945-05-04</td><td>+91 8239321466</td><td>Measles</td><td>Mysore</td><td>H1017</td></tr><tr><td>138861</td><td>Upasana</td><td>Female</td><td>1927-10-03</td><td>null</td><td>Heart Attack</td><td>Ratlam</td><td>H1004</td></tr><tr><td>146555</td><td>NA</td><td>Male</td><td>1948-11-10</td><td>+91 8390195092</td><td>Phenylketonuria</td><td>Vadodara</td><td>H1007</td></tr><tr><td>199114</td><td>NA</td><td>Female</td><td>1955-04-07</td><td>+91 7434031446</td><td>Phenylketonuria</td><td>Vijayawada</td><td>H1017</td></tr><tr><td>105758</td><td>Madhubala</td><td>Male</td><td>1937-01-11</td><td>+91 8498685882</td><td>Head banging</td><td>Jaunpur</td><td>H1003</td></tr><tr><td>109251</td><td>Anjushree</td><td>Male</td><td>1976-07-04</td><td>+91 5322869455</td><td>Choking</td><td>Ghaziabad</td><td>H1001</td></tr><tr><td>156223</td><td>NA</td><td>Female</td><td>1930-11-25</td><td>null</td><td>Fanconi anaemia</td><td>Agartala</td><td>H1012</td></tr><tr><td>108576</td><td>Chakrika</td><td>Male</td><td>1964-08-05</td><td>+91 8185162879</td><td>Stroke</td><td>Ranchi</td><td>H1003</td></tr><tr><td>132947</td><td>Saroj</td><td>Female</td><td>1942-08-26</td><td>+91 5690408243</td><td>Anaemia</td><td>Muzaffarpur</td><td>H1016</td></tr><tr><td>148674</td><td>Ayushmati</td><td>Male</td><td>1932-09-20</td><td>+91 3683223970</td><td>Diabetes</td><td>Satna</td><td>H1016</td></tr><tr><td>133107</td><td>Drashti</td><td>Male</td><td>1926-07-03</td><td>+91 9447269993</td><td>Lymphedema</td><td>Saharsa</td><td>H1019</td></tr><tr><td>193137</td><td>Aayushmaan</td><td>Female</td><td>1983-11-14</td><td>+91 4464709769</td><td>Phenylketonuria</td><td>Mehsana</td><td>H1014</td></tr><tr><td>196369</td><td>NA</td><td>Male</td><td>1931-02-04</td><td>+91 2973105946</td><td>Choking</td><td>Shivpuri</td><td>H1017</td></tr><tr><td>109342</td><td>Chitranjan</td><td>Female</td><td>1925-09-09</td><td>+91 5176024720</td><td>Asthma</td><td>Morbi</td><td>H1011</td></tr><tr><td>121783</td><td>Paridhi</td><td>Female</td><td>1959-03-27</td><td>+91 2139280879</td><td>Bladder cancer</td><td>Jabalpur</td><td>H1013</td></tr><tr><td>197441</td><td>Deependu</td><td>Female</td><td>1952-02-13</td><td>+91 5674176644</td><td>Lung cancer</td><td>Bareilly</td><td>H1001</td></tr><tr><td>194166</td><td>NA</td><td>Male</td><td>1946-10-17</td><td>+91 9887324437</td><td>Colorectal cancer</td><td>Baranagar</td><td>H1015</td></tr><tr><td>110690</td><td>Laksman</td><td>Female</td><td>1939-05-26</td><td>+91 4504120828</td><td>Food Poisoning</td><td>Ahmednagar</td><td>H1001</td></tr><tr><td>180709</td><td>NA</td><td>Male</td><td>1988-06-27</td><td>+91 6877897646</td><td>Anthrax</td><td>Pali</td><td>H1017</td></tr><tr><td>119268</td><td>Shivakari</td><td>Female</td><td>1944-11-02</td><td>+91 3740484063</td><td>Mold allergy</td><td>Hapur</td><td>H1008</td></tr><tr><td>163148</td><td>Madhu</td><td>Male</td><td>1984-10-23</td><td>+91 8367885507</td><td>Beriberi</td><td>Udaipur</td><td>H1008</td></tr><tr><td>118913</td><td>Chanak</td><td>Male</td><td>1954-08-27</td><td>+91 5093121123</td><td>Malaria</td><td>Jalandhar</td><td>H1004</td></tr><tr><td>167423</td><td>Chittesh</td><td>Male</td><td>1949-10-17</td><td>+91 1378163498</td><td>Asthma</td><td>Thoothukudi</td><td>H1019</td></tr><tr><td>141703</td><td>Nawal</td><td>Male</td><td>1940-01-22</td><td>+91 1885105576</td><td>Fractures</td><td>Bhopal</td><td>H1006</td></tr><tr><td>173518</td><td>Gajabahu</td><td>Male</td><td>1959-03-15</td><td>+91 1207869436</td><td>Malaria</td><td>Udupi</td><td>H1015</td></tr><tr><td>140394</td><td>Jitesh</td><td>Male</td><td>1983-02-03</td><td>+91 6515468035</td><td>Anthrax</td><td>Karimnagar</td><td>H1010</td></tr><tr><td>164524</td><td>NA</td><td>Female</td><td>1966-09-25</td><td>+91 6477918745</td><td>Mold allergy</td><td>Kharagpur</td><td>H1015</td></tr><tr><td>198182</td><td>Lalit</td><td>Female</td><td>1924-02-15</td><td>+91 4647833992</td><td>Head banging</td><td>Tinsukia</td><td>H1017</td></tr><tr><td>115143</td><td>Anshuk</td><td>Male</td><td>1991-06-17</td><td>+91 9764690642</td><td>Drug consumption</td><td>Uluberia</td><td>H1001</td></tr><tr><td>156364</td><td>NA</td><td>Male</td><td>1994-01-13</td><td>+91 8444537013</td><td>Cholera</td><td>Panihati</td><td>H1019</td></tr><tr><td>191132</td><td>Dipesh</td><td>Female</td><td>1949-04-01</td><td>+91 5851958964</td><td>Glaucoma</td><td>Kochi</td><td>H1016</td></tr><tr><td>105686</td><td>NA</td><td>Male</td><td>1930-09-01</td><td>+91 7061843400</td><td>Hepatitis</td><td>Kolhapur</td><td>H1008</td></tr><tr><td>160140</td><td>Kishan</td><td>Male</td><td>1923-05-12</td><td>+91 9067652693</td><td>Rett Syndrome</td><td>Srikakulam</td><td>H1002</td></tr><tr><td>114252</td><td>NA</td><td>Female</td><td>1927-02-26</td><td>+91 4984346995</td><td>Diabetes</td><td>Ambarnath</td><td>H1014</td></tr><tr><td>188365</td><td>Bhageeratha</td><td>Male</td><td>1973-03-21</td><td>+91 0590662722</td><td>Pet allergy</td><td>Sonipat</td><td>H1017</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         187158,
         "Harbir",
         "Female",
         "1924-06-30",
         "+91 0112009318",
         "Galactosemia",
         "Rourkela",
         "H1001"
        ],
        [
         112766,
         "Brahmdev",
         "Female",
         "1948-12-20",
         "+91 1727749552",
         "Bladder cancer",
         "Tiruvottiyur",
         "H1016"
        ],
        [
         199252,
         "Ujjawal",
         "Male",
         "1980-04-16",
         "+91 8547451606",
         "Kidney cancer",
         "Berhampur",
         "H1009"
        ],
        [
         133424,
         "Ballari",
         "Female",
         "1969-09-25",
         "+91 0106026841",
         "Suicide",
         "Bihar Sharif",
         "H1017"
        ],
        [
         172579,
         "Devnath",
         "Female",
         "1946-05-01",
         "+91 1868774631",
         "Food allergy",
         "Bidhannagar",
         "H1019"
        ],
        [
         171320,
         "Atasi",
         "Male",
         "1967-10-02",
         "+91 9747336855",
         "Whiplash",
         "Amravati",
         "H1013"
        ],
        [
         107794,
         "Manish",
         "Male",
         "1967-06-06",
         "+91 4354294043",
         "Sunbathing",
         "Panvel",
         "H1004"
        ],
        [
         130339,
         "Aakar",
         "Female",
         "1925-03-05",
         "+91 2777633911",
         "Drug consumption",
         "Bihar Sharif",
         "H1000"
        ],
        [
         110377,
         "Gurudas",
         "Male",
         "1945-05-06",
         "+91 1232859381",
         "Dengue",
         "Kamarhati",
         "H1001"
        ],
        [
         149367,
         "NA",
         "Male",
         "1925-06-12",
         "+91 1780763280",
         "Head banging",
         "Bangalore",
         "H1013"
        ],
        [
         156168,
         "NA",
         "Male",
         "1976-02-03",
         "+91 5586075345",
         "Fanconi anaemia",
         "Rajkot",
         "H1004"
        ],
        [
         114241,
         "NA",
         "Female",
         "1955-01-22",
         "+91 4146391938",
         "Breast cancer",
         "Ghaziabad",
         "H1015"
        ],
        [
         146382,
         "Dharmadaas",
         "Male",
         "1964-04-29",
         "+91 6345482027",
         "Anthrax",
         "Bhalswa Jahangir Pur",
         "H1019"
        ],
        [
         132748,
         "Brahmvir",
         "Male",
         "1991-11-11",
         "+91 7316972612",
         "Cystic fibrosis",
         "Ambala",
         "H1018"
        ],
        [
         167340,
         "NA",
         "Female",
         "1981-01-25",
         "+91 2960004518",
         "Galactosemia",
         "Surendranagar Dudhrej",
         "H1003"
        ],
        [
         135184,
         "Bhagvan",
         "Female",
         "1966-07-24",
         "+91 0297693485",
         "Dengue",
         "Bhimavaram",
         "H1018"
        ],
        [
         179662,
         "Amritkala",
         "Female",
         "1933-11-20",
         "+91 0537157280",
         "Smallpox",
         "Meerut",
         "H1018"
        ],
        [
         184479,
         "Bandhu",
         "Male",
         "1996-10-15",
         "+91 0695289163",
         "Pollen allergy",
         "Chinsurah",
         "H1010"
        ],
        [
         156988,
         "Bhagavaana",
         "Female",
         "1935-09-16",
         "+91 6071745855",
         "Breast cancer",
         "Shahjahanpur",
         "H1012"
        ],
        [
         132870,
         "NA",
         "Female",
         "1924-11-09",
         "+91 8906694405",
         "Glaucoma",
         "Jabalpur",
         "H1017"
        ],
        [
         148137,
         "Umang",
         "Female",
         "1963-07-14",
         "+91 9485838770",
         "Pet allergy",
         "Haridwar",
         "H1002"
        ],
        [
         113280,
         "Darsana",
         "Male",
         "1932-05-29",
         "+91 7676311811",
         "Rett Syndrome",
         "Dibrugarh",
         "H1019"
        ],
        [
         134184,
         "Prakash",
         "Female",
         "1923-09-15",
         "+91 9268324471",
         "Flu",
         "Kottayam",
         "H1001"
        ],
        [
         122592,
         "Vaijayanti",
         "Male",
         "1920-11-13",
         "+91 9358851649",
         "Cholera",
         "Mira-Bhayandar",
         "H1009"
        ],
        [
         154439,
         "Menakshi",
         "Male",
         "1987-03-06",
         "+91 0531676556",
         "Scurvy",
         "Kamarhati",
         "H1016"
        ],
        [
         117945,
         "NA",
         "Male",
         "1955-12-24",
         "+91 2416747182",
         "Glaucoma",
         "Karimnagar",
         "H1009"
        ],
        [
         189996,
         "Ekant",
         "Male",
         "1943-08-13",
         "+91 7686951174",
         "Measles",
         "Berhampore",
         "H1003"
        ],
        [
         146540,
         "Chancharik",
         "Male",
         "1983-09-05",
         "+91 5309364825",
         "Scurvy",
         "Chapra",
         "H1012"
        ],
        [
         156434,
         "Pushti",
         "Female",
         "1935-10-15",
         "+91 7093722203",
         "Flu",
         "Morbi",
         "H1019"
        ],
        [
         197352,
         "Swati",
         "Female",
         "1987-12-11",
         "+91 1028477510",
         "Pet allergy",
         "Amravati",
         "H1019"
        ],
        [
         138778,
         "Upasana",
         "Male",
         "1956-06-01",
         "+91 0548234943",
         "Lymphedema",
         "Hyderabad",
         "H1005"
        ],
        [
         162665,
         "Kanhaiya",
         "Female",
         "1954-10-19",
         "+91 0788738026",
         "Alcohol consumption",
         "Mysore",
         "H1009"
        ],
        [
         197503,
         "NA",
         "Female",
         "1968-07-02",
         "+91 2599794460",
         "Stroke",
         "Gwalior",
         "H1009"
        ],
        [
         113476,
         "Gensho",
         "Male",
         "1992-06-06",
         "+91 4834040556",
         "Galactosemia",
         "Ludhiana",
         "H1016"
        ],
        [
         195876,
         "Gopal",
         "Male",
         "1986-05-14",
         "+91 1181471524",
         "Vertigo",
         "Raebareli",
         "H1017"
        ],
        [
         150189,
         "Dheeman",
         "Male",
         "1945-05-04",
         "+91 8239321466",
         "Measles",
         "Mysore",
         "H1017"
        ],
        [
         138861,
         "Upasana",
         "Female",
         "1927-10-03",
         null,
         "Heart Attack",
         "Ratlam",
         "H1004"
        ],
        [
         146555,
         "NA",
         "Male",
         "1948-11-10",
         "+91 8390195092",
         "Phenylketonuria",
         "Vadodara",
         "H1007"
        ],
        [
         199114,
         "NA",
         "Female",
         "1955-04-07",
         "+91 7434031446",
         "Phenylketonuria",
         "Vijayawada",
         "H1017"
        ],
        [
         105758,
         "Madhubala",
         "Male",
         "1937-01-11",
         "+91 8498685882",
         "Head banging",
         "Jaunpur",
         "H1003"
        ],
        [
         109251,
         "Anjushree",
         "Male",
         "1976-07-04",
         "+91 5322869455",
         "Choking",
         "Ghaziabad",
         "H1001"
        ],
        [
         156223,
         "NA",
         "Female",
         "1930-11-25",
         null,
         "Fanconi anaemia",
         "Agartala",
         "H1012"
        ],
        [
         108576,
         "Chakrika",
         "Male",
         "1964-08-05",
         "+91 8185162879",
         "Stroke",
         "Ranchi",
         "H1003"
        ],
        [
         132947,
         "Saroj",
         "Female",
         "1942-08-26",
         "+91 5690408243",
         "Anaemia",
         "Muzaffarpur",
         "H1016"
        ],
        [
         148674,
         "Ayushmati",
         "Male",
         "1932-09-20",
         "+91 3683223970",
         "Diabetes",
         "Satna",
         "H1016"
        ],
        [
         133107,
         "Drashti",
         "Male",
         "1926-07-03",
         "+91 9447269993",
         "Lymphedema",
         "Saharsa",
         "H1019"
        ],
        [
         193137,
         "Aayushmaan",
         "Female",
         "1983-11-14",
         "+91 4464709769",
         "Phenylketonuria",
         "Mehsana",
         "H1014"
        ],
        [
         196369,
         "NA",
         "Male",
         "1931-02-04",
         "+91 2973105946",
         "Choking",
         "Shivpuri",
         "H1017"
        ],
        [
         109342,
         "Chitranjan",
         "Female",
         "1925-09-09",
         "+91 5176024720",
         "Asthma",
         "Morbi",
         "H1011"
        ],
        [
         121783,
         "Paridhi",
         "Female",
         "1959-03-27",
         "+91 2139280879",
         "Bladder cancer",
         "Jabalpur",
         "H1013"
        ],
        [
         197441,
         "Deependu",
         "Female",
         "1952-02-13",
         "+91 5674176644",
         "Lung cancer",
         "Bareilly",
         "H1001"
        ],
        [
         194166,
         "NA",
         "Male",
         "1946-10-17",
         "+91 9887324437",
         "Colorectal cancer",
         "Baranagar",
         "H1015"
        ],
        [
         110690,
         "Laksman",
         "Female",
         "1939-05-26",
         "+91 4504120828",
         "Food Poisoning",
         "Ahmednagar",
         "H1001"
        ],
        [
         180709,
         "NA",
         "Male",
         "1988-06-27",
         "+91 6877897646",
         "Anthrax",
         "Pali",
         "H1017"
        ],
        [
         119268,
         "Shivakari",
         "Female",
         "1944-11-02",
         "+91 3740484063",
         "Mold allergy",
         "Hapur",
         "H1008"
        ],
        [
         163148,
         "Madhu",
         "Male",
         "1984-10-23",
         "+91 8367885507",
         "Beriberi",
         "Udaipur",
         "H1008"
        ],
        [
         118913,
         "Chanak",
         "Male",
         "1954-08-27",
         "+91 5093121123",
         "Malaria",
         "Jalandhar",
         "H1004"
        ],
        [
         167423,
         "Chittesh",
         "Male",
         "1949-10-17",
         "+91 1378163498",
         "Asthma",
         "Thoothukudi",
         "H1019"
        ],
        [
         141703,
         "Nawal",
         "Male",
         "1940-01-22",
         "+91 1885105576",
         "Fractures",
         "Bhopal",
         "H1006"
        ],
        [
         173518,
         "Gajabahu",
         "Male",
         "1959-03-15",
         "+91 1207869436",
         "Malaria",
         "Udupi",
         "H1015"
        ],
        [
         140394,
         "Jitesh",
         "Male",
         "1983-02-03",
         "+91 6515468035",
         "Anthrax",
         "Karimnagar",
         "H1010"
        ],
        [
         164524,
         "NA",
         "Female",
         "1966-09-25",
         "+91 6477918745",
         "Mold allergy",
         "Kharagpur",
         "H1015"
        ],
        [
         198182,
         "Lalit",
         "Female",
         "1924-02-15",
         "+91 4647833992",
         "Head banging",
         "Tinsukia",
         "H1017"
        ],
        [
         115143,
         "Anshuk",
         "Male",
         "1991-06-17",
         "+91 9764690642",
         "Drug consumption",
         "Uluberia",
         "H1001"
        ],
        [
         156364,
         "NA",
         "Male",
         "1994-01-13",
         "+91 8444537013",
         "Cholera",
         "Panihati",
         "H1019"
        ],
        [
         191132,
         "Dipesh",
         "Female",
         "1949-04-01",
         "+91 5851958964",
         "Glaucoma",
         "Kochi",
         "H1016"
        ],
        [
         105686,
         "NA",
         "Male",
         "1930-09-01",
         "+91 7061843400",
         "Hepatitis",
         "Kolhapur",
         "H1008"
        ],
        [
         160140,
         "Kishan",
         "Male",
         "1923-05-12",
         "+91 9067652693",
         "Rett Syndrome",
         "Srikakulam",
         "H1002"
        ],
        [
         114252,
         "NA",
         "Female",
         "1927-02-26",
         "+91 4984346995",
         "Diabetes",
         "Ambarnath",
         "H1014"
        ],
        [
         188365,
         "Bhageeratha",
         "Male",
         "1973-03-21",
         "+91 0590662722",
         "Pet allergy",
         "Sonipat",
         "H1017"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 151
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Patient_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Patient_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "patient_gender",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"yyyy-M-d\"}",
         "name": "patient_birth_date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "patient_phone",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "disease_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "hospital_id",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from patient_table;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1167ab45-a378-47e8-8410-1c56fb7b6293",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Patient_id</th><th>Patient_name</th><th>patient_gender</th><th>patient_birth_date</th><th>patient_phone</th><th>disease_name</th><th>city</th><th>hospital_id</th></tr></thead><tbody><tr><td>112766</td><td>Brahmdev</td><td>Female</td><td>1948-12-20</td><td>+91 1727749552</td><td>Bladder cancer</td><td>Tiruvottiyur</td><td>H1016</td></tr><tr><td>199252</td><td>Ujjawal</td><td>Male</td><td>1980-04-16</td><td>+91 8547451606</td><td>Kidney cancer</td><td>Berhampur</td><td>H1009</td></tr><tr><td>114241</td><td>NA</td><td>Female</td><td>1955-01-22</td><td>+91 4146391938</td><td>Breast cancer</td><td>Ghaziabad</td><td>H1015</td></tr><tr><td>156988</td><td>Bhagavaana</td><td>Female</td><td>1935-09-16</td><td>+91 6071745855</td><td>Breast cancer</td><td>Shahjahanpur</td><td>H1012</td></tr><tr><td>121783</td><td>Paridhi</td><td>Female</td><td>1959-03-27</td><td>+91 2139280879</td><td>Bladder cancer</td><td>Jabalpur</td><td>H1013</td></tr><tr><td>197441</td><td>Deependu</td><td>Female</td><td>1952-02-13</td><td>+91 5674176644</td><td>Lung cancer</td><td>Bareilly</td><td>H1001</td></tr><tr><td>194166</td><td>NA</td><td>Male</td><td>1946-10-17</td><td>+91 9887324437</td><td>Colorectal cancer</td><td>Baranagar</td><td>H1015</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         112766,
         "Brahmdev",
         "Female",
         "1948-12-20",
         "+91 1727749552",
         "Bladder cancer",
         "Tiruvottiyur",
         "H1016"
        ],
        [
         199252,
         "Ujjawal",
         "Male",
         "1980-04-16",
         "+91 8547451606",
         "Kidney cancer",
         "Berhampur",
         "H1009"
        ],
        [
         114241,
         "NA",
         "Female",
         "1955-01-22",
         "+91 4146391938",
         "Breast cancer",
         "Ghaziabad",
         "H1015"
        ],
        [
         156988,
         "Bhagavaana",
         "Female",
         "1935-09-16",
         "+91 6071745855",
         "Breast cancer",
         "Shahjahanpur",
         "H1012"
        ],
        [
         121783,
         "Paridhi",
         "Female",
         "1959-03-27",
         "+91 2139280879",
         "Bladder cancer",
         "Jabalpur",
         "H1013"
        ],
        [
         197441,
         "Deependu",
         "Female",
         "1952-02-13",
         "+91 5674176644",
         "Lung cancer",
         "Bareilly",
         "H1001"
        ],
        [
         194166,
         "NA",
         "Male",
         "1946-10-17",
         "+91 9887324437",
         "Colorectal cancer",
         "Baranagar",
         "H1015"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 158
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Patient_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Patient_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "patient_gender",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"yyyy-M-d\"}",
         "name": "patient_birth_date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "patient_phone",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "disease_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "hospital_id",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    patient_table\n",
    "WHERE\n",
    "    disease_name like '%cancer'\n",
    "LIMIT 50;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b1adc15-c42a-4f1a-bd98-0b7134bb059b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 12.\tList patients who have cashless insurance and have total charges greater than or equal for Rs. 50,000.\n",
    "a.\tClaims table, claim_type\n",
    "b.\tPatient_records table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4fa8079-4bc0-4a7e-8deb-933543bb3fe3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `ct`.`Elig_ind` cannot be resolved. Did you mean one of the following? [`ct`.`claim_id`, `ct`.`SUB_ID`, `pt`.`city`, `ct`.`claim_date`, `ct`.`claim_type`]. SQLSTATE: 42703; line 18 pos 12;\n",
       "'Project ['Patient_id, 'Patient_name, 'Total_Charges]\n",
       "+- 'Filter ('Total_Charges >= 50000)\n",
       "   +- 'SubqueryAlias PatientCharges\n",
       "      +- 'Aggregate ['pt.Patient_id, 'pt.Patient_name], ['pt.Patient_id, 'pt.Patient_name, 'SUM('ct.claim_amount) AS Total_Charges#4326]\n",
       "         +- 'Filter ('ct.Elig_ind = cashless)\n",
       "            +- Join Inner, (cast(Patient_id#221 as bigint) = patient_id#451L)\n",
       "               :- SubqueryAlias pt\n",
       "               :  +- SubqueryAlias patient_table\n",
       "               :     +- View (`patient_table`, [Patient_id#221, Patient_name#591, patient_gender#223, patient_birth_date#224, patient_phone#225, disease_name#226, city#227, hospital_id#228])\n",
       "               :        +- Project [Patient_id#221, coalesce(Patient_name#222, cast(NA as string)) AS Patient_name#591, patient_gender#223, patient_birth_date#224, patient_phone#225, disease_name#226, city#227, hospital_id#228]\n",
       "               :           +- Relation [Patient_id#221,Patient_name#222,patient_gender#223,patient_birth_date#224,patient_phone#225,disease_name#226,city#227,hospital_id#228] csv\n",
       "               +- SubqueryAlias ct\n",
       "                  +- SubqueryAlias claims_table\n",
       "                     +- View (`claims_table`, [Claim_Or_Rejected#1314, SUB_ID#445, claim_amount#446, claim_date#447, claim_id#448L, claim_type#449, disease_name#450, patient_id#451L])\n",
       "                        +- Project [CASE WHEN (Claim_Or_Rejected#444 = NaN) THEN NA ELSE Claim_Or_Rejected#444 END AS Claim_Or_Rejected#1314, SUB_ID#445, claim_amount#446, claim_date#447, claim_id#448L, claim_type#449, disease_name#450, patient_id#451L]\n",
       "                           +- Relation [Claim_Or_Rejected#444,SUB_ID#445,claim_amount#446,claim_date#447,claim_id#448L,claim_type#449,disease_name#450,patient_id#451L] json\n",
       "\n",
       "\tat org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:328)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:158)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$8(CheckAnalysis.scala:358)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$8$adapted(CheckAnalysis.scala:343)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:259)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:258)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:258)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:258)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:343)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:343)\n",
       "\tat scala.collection.immutable.Stream.foreach(Stream.scala:533)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:343)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:239)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:259)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:258)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:258)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:258)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:258)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:258)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:258)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:258)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:258)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:258)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:258)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:258)\n",
       "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
       "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
       "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
       "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
       "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
       "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:258)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:239)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:221)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:340)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:209)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:176)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:176)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:340)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$2(Analyzer.scala:394)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:166)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:394)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:384)\n",
       "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:391)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:230)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:394)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:542)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1048)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:542)\n",
       "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:538)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1173)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:538)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:224)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:223)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:205)\n",
       "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:124)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1173)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1180)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:115)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$5(SparkSession.scala:952)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1173)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:941)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:975)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1008)\n",
       "\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:696)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:276)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:362)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:383)\n",
       "\tat scala.collection.immutable.List.map(List.scala:293)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:378)\n",
       "\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.repl(JupyterDriverLocal.scala:953)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$35(DriverLocal.scala:1097)\n",
       "\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:124)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$23(DriverLocal.scala:1080)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:87)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:87)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:1017)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:746)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:738)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:766)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:645)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:690)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:516)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:442)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:284)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `ct`.`Elig_ind` cannot be resolved. Did you mean one of the following? [`ct`.`claim_id`, `ct`.`SUB_ID`, `pt`.`city`, `ct`.`claim_date`, `ct`.`claim_type`]. SQLSTATE: 42703"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "UNRESOLVED_COLUMN.WITH_SUGGESTION",
        "sqlState": "42703",
        "startIndex": 353,
        "stopIndex": 363
       },
       "stackFrames": [
        "org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `ct`.`Elig_ind` cannot be resolved. Did you mean one of the following? [`ct`.`claim_id`, `ct`.`SUB_ID`, `pt`.`city`, `ct`.`claim_date`, `ct`.`claim_type`]. SQLSTATE: 42703; line 18 pos 12;\n'Project ['Patient_id, 'Patient_name, 'Total_Charges]\n+- 'Filter ('Total_Charges >= 50000)\n   +- 'SubqueryAlias PatientCharges\n      +- 'Aggregate ['pt.Patient_id, 'pt.Patient_name], ['pt.Patient_id, 'pt.Patient_name, 'SUM('ct.claim_amount) AS Total_Charges#4326]\n         +- 'Filter ('ct.Elig_ind = cashless)\n            +- Join Inner, (cast(Patient_id#221 as bigint) = patient_id#451L)\n               :- SubqueryAlias pt\n               :  +- SubqueryAlias patient_table\n               :     +- View (`patient_table`, [Patient_id#221, Patient_name#591, patient_gender#223, patient_birth_date#224, patient_phone#225, disease_name#226, city#227, hospital_id#228])\n               :        +- Project [Patient_id#221, coalesce(Patient_name#222, cast(NA as string)) AS Patient_name#591, patient_gender#223, patient_birth_date#224, patient_phone#225, disease_name#226, city#227, hospital_id#228]\n               :           +- Relation [Patient_id#221,Patient_name#222,patient_gender#223,patient_birth_date#224,patient_phone#225,disease_name#226,city#227,hospital_id#228] csv\n               +- SubqueryAlias ct\n                  +- SubqueryAlias claims_table\n                     +- View (`claims_table`, [Claim_Or_Rejected#1314, SUB_ID#445, claim_amount#446, claim_date#447, claim_id#448L, claim_type#449, disease_name#450, patient_id#451L])\n                        +- Project [CASE WHEN (Claim_Or_Rejected#444 = NaN) THEN NA ELSE Claim_Or_Rejected#444 END AS Claim_Or_Rejected#1314, SUB_ID#445, claim_amount#446, claim_date#447, claim_id#448L, claim_type#449, disease_name#450, patient_id#451L]\n                           +- Relation [Claim_Or_Rejected#444,SUB_ID#445,claim_amount#446,claim_date#447,claim_id#448L,claim_type#449,disease_name#450,patient_id#451L] json\n\n\tat org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:328)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:158)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$8(CheckAnalysis.scala:358)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$8$adapted(CheckAnalysis.scala:343)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:259)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:258)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:258)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:258)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:343)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:343)\n\tat scala.collection.immutable.Stream.foreach(Stream.scala:533)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:343)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:239)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:259)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:258)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:258)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:258)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:258)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:258)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:258)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:258)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:258)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:258)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:258)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:258)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:258)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:239)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:221)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:340)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:209)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:176)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:176)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:340)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$2(Analyzer.scala:394)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:166)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:394)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:384)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:391)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:230)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:394)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:542)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1048)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:542)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:538)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1173)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:538)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:224)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:223)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:205)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:124)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1173)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1180)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1180)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:115)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$5(SparkSession.scala:952)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1173)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:941)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:975)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1008)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:696)\n\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:276)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:362)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:383)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:378)\n\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.repl(JupyterDriverLocal.scala:953)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$35(DriverLocal.scala:1097)\n\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:124)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$23(DriverLocal.scala:1080)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:87)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:87)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:1017)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:746)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:738)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:766)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:645)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:690)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:516)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:442)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:284)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    Patient_id,\n",
    "    Patient_name,\n",
    "    Total_Charges\n",
    "FROM\n",
    "    (\n",
    "        SELECT\n",
    "            pt.Patient_id,\n",
    "            pt.Patient_name,\n",
    "            SUM(ct.claim_amount) AS Total_Charges\n",
    "        FROM\n",
    "            patient_table pt\n",
    "        JOIN\n",
    "            claims_table ct\n",
    "        ON\n",
    "            pt.Patient_id = ct.patient_id\n",
    "        WHERE\n",
    "            ct.Elig_ind = 'cashless'\n",
    "        GROUP BY\n",
    "            pt.Patient_id, pt.Patient_name\n",
    "    ) AS PatientCharges\n",
    "WHERE\n",
    "    Total_Charges >= 50000;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b5bf422-5f83-4941-9981-10abf8ba4e05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|Claim_Or_Rejected|    SUB_ID|claim_amount|claim_date|claim_id|      claim_type|    disease_name|patient_id|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\n|                N| SUBID1000|       79874|1949-03-14|       0| claims of value|    Galactosemia|    187158|\n|               NA|SUBID10001|      151142|1970-03-16|       1|claims of policy|  Bladder cancer|    112766|\n|               NA|SUBID10002|       59924|2008-02-03|       2| claims of value|   Kidney cancer|    199252|\n|               NA|SUBID10003|      143120|1995-02-08|       3|  claims of fact|         Suicide|    133424|\n|                Y|SUBID10004|      168634|1967-05-23|       4| claims of value|    Food allergy|    172579|\n|               NA|SUBID10005|       64840|1991-10-04|       5|claims of policy|        Whiplash|    171320|\n|                N| SUBID1006|       26800|1991-03-26|       6|  claims of fact|      Sunbathing|    107794|\n|               NA|SUBID10007|      177186|1946-09-05|       7| claims of value|Drug consumption|    130339|\n|                N|SUBID10008|      141123|1966-06-20|       8|  claims of fact|          Dengue|    110377|\n|                N|SUBID10009|       88540|1945-12-29|       9| claims of value|    Head banging|    149367|\n|                N| SUBID1010|       29150|1999-01-25|      10| claims of value| Fanconi anaemia|    156168|\n|                Y|SUBID10011|       40897|1975-02-08|      11| claims of value|   Breast cancer|    114241|\n|               NA|SUBID10012|       75983|1985-02-12|      12| claims of value|         Anthrax|    146382|\n|               NA|SUBID10013|      192340|2014-07-30|      13|  claims of fact| Cystic fibrosis|    132748|\n|                N|SUBID10014|      118628|2003-12-18|      14| claims of value|    Galactosemia|    167340|\n|                Y|SUBID10015|      100224|1986-08-02|      15| claims of value|          Dengue|    135184|\n|                N|SUBID10016|       42860|1955-01-20|      16| claims of value|        Smallpox|    179662|\n|                N|SUBID10017|      161786|2017-06-01|      17|claims of policy|  Pollen allergy|    184479|\n|               NA|SUBID10018|       66129|1956-01-04|      18|  claims of fact|   Breast cancer|    156988|\n|               NA|SUBID10019|      182552|1948-07-26|      19| claims of value|        Glaucoma|    132870|\n+-----------------+----------+------------+----------+--------+----------------+----------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_cl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13d2d350-428e-45a7-b385-0ef4c669dd4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>claim_type</th></tr></thead><tbody><tr><td>claims of value</td></tr><tr><td>claims of fact</td></tr><tr><td>claims of policy</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "claims of value"
        ],
        [
         "claims of fact"
        ],
        [
         "claims of policy"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 160
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "claim_type",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT DISTINCT claim_type FROM claims_table;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61b973a8-5283-4891-9efe-f9930feceb95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>sub_id</th><th>first_name</th><th>last_name</th><th>Total_Claim_Amount</th></tr></thead><tbody><tr><td>SUBID10057</td><td>Chittesh</td><td>Pandey</td><td>161497.0</td></tr><tr><td>SUBID1021</td><td>Darsana</td><td>Yadav</td><td>55761.0</td></tr><tr><td>SUBID10015</td><td>Bhagvan</td><td>Srivastav</td><td>100224.0</td></tr><tr><td>SUBID10039</td><td>Madhubala</td><td>Yadav</td><td>108526.0</td></tr><tr><td>SUBID10001</td><td>Brahmdev</td><td>Sonkar</td><td>151142.0</td></tr><tr><td>SUBID1043</td><td>Saroj</td><td>Pandit</td><td>186502.0</td></tr><tr><td>SUBID10005</td><td>Atasi</td><td>Seth</td><td>64840.0</td></tr><tr><td>SUBID10059</td><td>Gajabahu</td><td>Singh</td><td>171729.0</td></tr><tr><td>SUBID10051</td><td>NA</td><td>Rajput</td><td>193801.0</td></tr><tr><td>SUBID10009</td><td>NA</td><td>Gupta</td><td>88540.0</td></tr><tr><td>SUBID1045</td><td>Drashti</td><td>Divedi</td><td>160739.0</td></tr><tr><td>SUBID10050</td><td>Deependu</td><td>Gupta</td><td>156557.0</td></tr><tr><td>SUBID1065</td><td>Dipesh</td><td>Mishra</td><td>81980.0</td></tr><tr><td>SUBID10042</td><td>Chakrika</td><td>Sonkar</td><td>188727.0</td></tr><tr><td>SUBID10069</td><td>Bhageeratha</td><td>Srivastav</td><td>99313.0</td></tr><tr><td>SUBID1041</td><td>NA</td><td>Rajput</td><td>118452.0</td></tr><tr><td>SUBID10053</td><td>NA</td><td>Sonkar</td><td>87588.0</td></tr><tr><td>SUBID10052</td><td>Laksman</td><td>Rao</td><td>130339.0</td></tr><tr><td>SUBID10008</td><td>Gurudas</td><td>Gupta</td><td>141123.0</td></tr><tr><td>SUBID10023</td><td>Vaijayanti</td><td>Pratap</td><td>83642.0</td></tr><tr><td>SUBID10026</td><td>Ekant</td><td>Sonkar</td><td>192381.0</td></tr><tr><td>SUBID1067</td><td>Kishan</td><td>Rao</td><td>109433.0</td></tr><tr><td>SUBID1047</td><td>NA</td><td>Rai</td><td>164159.0</td></tr><tr><td>SUBID1020</td><td>Umang</td><td>Srivastav</td><td>105982.0</td></tr><tr><td>SUBID10060</td><td>Jitesh</td><td>Vishwakarma</td><td>139755.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "SUBID10057",
         "Chittesh",
         "Pandey",
         161497.0
        ],
        [
         "SUBID1021",
         "Darsana",
         "Yadav",
         55761.0
        ],
        [
         "SUBID10015",
         "Bhagvan",
         "Srivastav",
         100224.0
        ],
        [
         "SUBID10039",
         "Madhubala",
         "Yadav",
         108526.0
        ],
        [
         "SUBID10001",
         "Brahmdev",
         "Sonkar",
         151142.0
        ],
        [
         "SUBID1043",
         "Saroj",
         "Pandit",
         186502.0
        ],
        [
         "SUBID10005",
         "Atasi",
         "Seth",
         64840.0
        ],
        [
         "SUBID10059",
         "Gajabahu",
         "Singh",
         171729.0
        ],
        [
         "SUBID10051",
         "NA",
         "Rajput",
         193801.0
        ],
        [
         "SUBID10009",
         "NA",
         "Gupta",
         88540.0
        ],
        [
         "SUBID1045",
         "Drashti",
         "Divedi",
         160739.0
        ],
        [
         "SUBID10050",
         "Deependu",
         "Gupta",
         156557.0
        ],
        [
         "SUBID1065",
         "Dipesh",
         "Mishra",
         81980.0
        ],
        [
         "SUBID10042",
         "Chakrika",
         "Sonkar",
         188727.0
        ],
        [
         "SUBID10069",
         "Bhageeratha",
         "Srivastav",
         99313.0
        ],
        [
         "SUBID1041",
         "NA",
         "Rajput",
         118452.0
        ],
        [
         "SUBID10053",
         "NA",
         "Sonkar",
         87588.0
        ],
        [
         "SUBID10052",
         "Laksman",
         "Rao",
         130339.0
        ],
        [
         "SUBID10008",
         "Gurudas",
         "Gupta",
         141123.0
        ],
        [
         "SUBID10023",
         "Vaijayanti",
         "Pratap",
         83642.0
        ],
        [
         "SUBID10026",
         "Ekant",
         "Sonkar",
         192381.0
        ],
        [
         "SUBID1067",
         "Kishan",
         "Rao",
         109433.0
        ],
        [
         "SUBID1047",
         "NA",
         "Rai",
         164159.0
        ],
        [
         "SUBID1020",
         "Umang",
         "Srivastav",
         105982.0
        ],
        [
         "SUBID10060",
         "Jitesh",
         "Vishwakarma",
         139755.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 161
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "sub_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Total_Claim_Amount",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    s.sub_id,\n",
    "    s.first_name,\n",
    "    s.last_name,\n",
    "    SUM(ct.claim_amount) AS Total_Claim_Amount\n",
    "FROM\n",
    "    subscriber_table s\n",
    "JOIN\n",
    "    claims_table ct\n",
    "ON\n",
    "    s.sub_id = ct.SUB_ID\n",
    "WHERE\n",
    "    s.Elig_ind = 'Y'\n",
    "GROUP BY\n",
    "    s.sub_id, s.first_name, s.last_name\n",
    "HAVING\n",
    "    Total_Claim_Amount >= 50000;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72d0339c-1491-4632-95f7-649676afb684",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>sub_id</th><th>Patient_id</th><th>first_name</th><th>last_name</th><th>Total_Claim_Amount</th></tr></thead><tbody><tr><td>SUBID1021</td><td>113280</td><td>Darsana</td><td>Yadav</td><td>55761.0</td></tr><tr><td>SUBID10005</td><td>171320</td><td>Atasi</td><td>Seth</td><td>64840.0</td></tr><tr><td>SUBID1045</td><td>133107</td><td>Drashti</td><td>Divedi</td><td>160739.0</td></tr><tr><td>SUBID10015</td><td>135184</td><td>Bhagvan</td><td>Srivastav</td><td>100224.0</td></tr><tr><td>SUBID10023</td><td>122592</td><td>Vaijayanti</td><td>Pratap</td><td>83642.0</td></tr><tr><td>SUBID1041</td><td>156223</td><td>NA</td><td>Rajput</td><td>118452.0</td></tr><tr><td>SUBID10059</td><td>173518</td><td>Gajabahu</td><td>Singh</td><td>171729.0</td></tr><tr><td>SUBID10053</td><td>180709</td><td>NA</td><td>Sonkar</td><td>87588.0</td></tr><tr><td>SUBID10039</td><td>105758</td><td>Madhubala</td><td>Yadav</td><td>108526.0</td></tr><tr><td>SUBID10008</td><td>110377</td><td>Gurudas</td><td>Gupta</td><td>141123.0</td></tr><tr><td>SUBID10001</td><td>112766</td><td>Brahmdev</td><td>Sonkar</td><td>151142.0</td></tr><tr><td>SUBID1043</td><td>132947</td><td>Saroj</td><td>Pandit</td><td>186502.0</td></tr><tr><td>SUBID1065</td><td>191132</td><td>Dipesh</td><td>Mishra</td><td>81980.0</td></tr><tr><td>SUBID10057</td><td>167423</td><td>Chittesh</td><td>Pandey</td><td>161497.0</td></tr><tr><td>SUBID10069</td><td>188365</td><td>Bhageeratha</td><td>Srivastav</td><td>99313.0</td></tr><tr><td>SUBID10060</td><td>140394</td><td>Jitesh</td><td>Vishwakarma</td><td>139755.0</td></tr><tr><td>SUBID10051</td><td>194166</td><td>NA</td><td>Rajput</td><td>193801.0</td></tr><tr><td>SUBID10050</td><td>197441</td><td>Deependu</td><td>Gupta</td><td>156557.0</td></tr><tr><td>SUBID1020</td><td>148137</td><td>Umang</td><td>Srivastav</td><td>105982.0</td></tr><tr><td>SUBID10026</td><td>189996</td><td>Ekant</td><td>Sonkar</td><td>192381.0</td></tr><tr><td>SUBID10042</td><td>108576</td><td>Chakrika</td><td>Sonkar</td><td>188727.0</td></tr><tr><td>SUBID1047</td><td>196369</td><td>NA</td><td>Rai</td><td>164159.0</td></tr><tr><td>SUBID1067</td><td>160140</td><td>Kishan</td><td>Rao</td><td>109433.0</td></tr><tr><td>SUBID10052</td><td>110690</td><td>Laksman</td><td>Rao</td><td>130339.0</td></tr><tr><td>SUBID10009</td><td>149367</td><td>NA</td><td>Gupta</td><td>88540.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "SUBID1021",
         113280,
         "Darsana",
         "Yadav",
         55761.0
        ],
        [
         "SUBID10005",
         171320,
         "Atasi",
         "Seth",
         64840.0
        ],
        [
         "SUBID1045",
         133107,
         "Drashti",
         "Divedi",
         160739.0
        ],
        [
         "SUBID10015",
         135184,
         "Bhagvan",
         "Srivastav",
         100224.0
        ],
        [
         "SUBID10023",
         122592,
         "Vaijayanti",
         "Pratap",
         83642.0
        ],
        [
         "SUBID1041",
         156223,
         "NA",
         "Rajput",
         118452.0
        ],
        [
         "SUBID10059",
         173518,
         "Gajabahu",
         "Singh",
         171729.0
        ],
        [
         "SUBID10053",
         180709,
         "NA",
         "Sonkar",
         87588.0
        ],
        [
         "SUBID10039",
         105758,
         "Madhubala",
         "Yadav",
         108526.0
        ],
        [
         "SUBID10008",
         110377,
         "Gurudas",
         "Gupta",
         141123.0
        ],
        [
         "SUBID10001",
         112766,
         "Brahmdev",
         "Sonkar",
         151142.0
        ],
        [
         "SUBID1043",
         132947,
         "Saroj",
         "Pandit",
         186502.0
        ],
        [
         "SUBID1065",
         191132,
         "Dipesh",
         "Mishra",
         81980.0
        ],
        [
         "SUBID10057",
         167423,
         "Chittesh",
         "Pandey",
         161497.0
        ],
        [
         "SUBID10069",
         188365,
         "Bhageeratha",
         "Srivastav",
         99313.0
        ],
        [
         "SUBID10060",
         140394,
         "Jitesh",
         "Vishwakarma",
         139755.0
        ],
        [
         "SUBID10051",
         194166,
         "NA",
         "Rajput",
         193801.0
        ],
        [
         "SUBID10050",
         197441,
         "Deependu",
         "Gupta",
         156557.0
        ],
        [
         "SUBID1020",
         148137,
         "Umang",
         "Srivastav",
         105982.0
        ],
        [
         "SUBID10026",
         189996,
         "Ekant",
         "Sonkar",
         192381.0
        ],
        [
         "SUBID10042",
         108576,
         "Chakrika",
         "Sonkar",
         188727.0
        ],
        [
         "SUBID1047",
         196369,
         "NA",
         "Rai",
         164159.0
        ],
        [
         "SUBID1067",
         160140,
         "Kishan",
         "Rao",
         109433.0
        ],
        [
         "SUBID10052",
         110690,
         "Laksman",
         "Rao",
         130339.0
        ],
        [
         "SUBID10009",
         149367,
         "NA",
         "Gupta",
         88540.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 164
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "sub_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Patient_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Total_Claim_Amount",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "    s.sub_id,\n",
    "    pt.Patient_id,\n",
    "    s.first_name,\n",
    "    s.last_name,\n",
    "    SUM(ct.claim_amount) AS Total_Claim_Amount\n",
    "FROM\n",
    "    subscriber_table s\n",
    "JOIN\n",
    "    claims_table ct\n",
    "ON\n",
    "    s.sub_id = ct.SUB_ID\n",
    "JOIN\n",
    "    patient_table pt\n",
    "ON\n",
    "    ct.patient_id = pt.Patient_id\n",
    "WHERE\n",
    "    s.Elig_ind = 'Y'\n",
    "GROUP BY\n",
    "    s.sub_id, s.first_name, s.last_name, pt.Patient_id\n",
    "HAVING\n",
    "    Total_Claim_Amount >= 50000;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69cf1426-b0bc-43b3-ba14-8a889bacc4f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+-----------+------------------+\n|    sub_id|Patient_id| first_name|  last_name|Total_Claim_Amount|\n+----------+----------+-----------+-----------+------------------+\n| SUBID1021|    113280|    Darsana|      Yadav|           55761.0|\n|SUBID10005|    171320|      Atasi|       Seth|           64840.0|\n| SUBID1045|    133107|    Drashti|     Divedi|          160739.0|\n|SUBID10015|    135184|    Bhagvan|  Srivastav|          100224.0|\n|SUBID10023|    122592| Vaijayanti|     Pratap|           83642.0|\n| SUBID1041|    156223|         NA|     Rajput|          118452.0|\n|SUBID10059|    173518|   Gajabahu|      Singh|          171729.0|\n|SUBID10053|    180709|         NA|     Sonkar|           87588.0|\n|SUBID10039|    105758|  Madhubala|      Yadav|          108526.0|\n|SUBID10008|    110377|    Gurudas|      Gupta|          141123.0|\n|SUBID10001|    112766|   Brahmdev|     Sonkar|          151142.0|\n| SUBID1043|    132947|      Saroj|     Pandit|          186502.0|\n| SUBID1065|    191132|     Dipesh|     Mishra|           81980.0|\n|SUBID10057|    167423|   Chittesh|     Pandey|          161497.0|\n|SUBID10069|    188365|Bhageeratha|  Srivastav|           99313.0|\n|SUBID10060|    140394|     Jitesh|Vishwakarma|          139755.0|\n|SUBID10051|    194166|         NA|     Rajput|          193801.0|\n|SUBID10050|    197441|   Deependu|      Gupta|          156557.0|\n| SUBID1020|    148137|      Umang|  Srivastav|          105982.0|\n|SUBID10026|    189996|      Ekant|     Sonkar|          192381.0|\n+----------+----------+-----------+-----------+------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_50 =\"\"\"\n",
    "SELECT\n",
    "    s.sub_id,\n",
    "    pt.Patient_id,\n",
    "    s.first_name,\n",
    "    s.last_name,\n",
    "    SUM(ct.claim_amount) AS Total_Claim_Amount\n",
    "FROM\n",
    "    subscriber_table s\n",
    "JOIN\n",
    "    claims_table ct\n",
    "ON\n",
    "    s.sub_id = ct.SUB_ID\n",
    "JOIN\n",
    "    patient_table pt\n",
    "ON\n",
    "    ct.patient_id = pt.Patient_id\n",
    "WHERE\n",
    "    s.Elig_ind = 'Y'\n",
    "GROUP BY\n",
    "    s.sub_id, s.first_name, s.last_name, pt.Patient_id\n",
    "HAVING\n",
    "    Total_Claim_Amount >= 50000;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df51 = spark.sql(df_50)\n",
    "\n",
    "df51.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fba4193e-d2c3-4f92-bb8d-9d2ffde092a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "113e1caf-0b4a-48a0-8c75-716e33b935ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9dfe0ff-042e-411d-bb63-b123ac0c7e51",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a440dbc-384b-4439-8588-b31ba984a825",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "deee46cc-9ea4-4f64-9d1d-3d3442ef7437",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7998c14-8bfe-4f02-a3cf-e5797a525e1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1499230506902921,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "cleaning_and_analysis",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
